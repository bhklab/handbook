# Google Cloud Storage (GCS)

GCS is a scalable and secure object storage for data files, datasets, and
ML-ready data.

## Why Use GCS?

- Centralized storage for raw and processed datasets.
- Facilitates data sharing across team members.
- Integration with other GCP services like BigQuery and AI/ML tools.

## Setting Up and Using GCS

!!! warning "Prerequisites"
    Ensure that you have completed [How to Use GCP](introduction.md#how-to-use-gcp)
    before starting this process.

The Google Cloud Documentation provides comprehensive guides to:

- [Creating Buckets](https://cloud.google.com/storage/docs/creating-buckets)
- [Downloading Files](https://cloud.google.com/storage/docs/downloading-objects)
- [Uploading Files](https://cloud.google.com/storage/docs/uploading-objects)

!!! note "Blob storage is not a file system!"
    GCS is not a file system. It is an object storage system.
    [Read this article](https://www.cloudflare.com/learning/cloud/what-is-blob-storage/)
    to understand the difference between file systems and object storage.

## When should BHKLAB Members use GCS?

The main use cases for using Cloud Storage are:

1. Files pertaining to Web Apps
    - These are often large files that are not suitable for Git.
        - For example, images, videos, and other media files.
    - Files for which latency from other storage options (i.e Zenodo)
    is not acceptable.
        - For example, files that are used in a web app and need to be
        served quickly.

2. Files for which you need to share with other BHKLAB members or collaborators

    - For example, large FASTQ files or Imaging Datasets
    that cant be shared via email.
    - However, it is HIGHLY recommended to use Zenodo for sharing
    datasets with collaborators.
        - Zenodo is a more permanent solution for sharing datasets
        and is **FREE**, with a generated DOI and metadata.
        - GCS is **NOT** a permanent solution for sharing datasets
        and is **NOT** free.

3. Files that are used and/or generated by pipeliines.

    - [ORCESTRA](https://orcestra.ca) runs its pipelines in the cloud and stores files
    in GCS buckets.
    - These files are assumed to be temporary and are not
    intended to be relied on for long-term storage.
    - Any input files that are used in a pipeline should be
    stored in Zenodo (either public or private), with appropriate
    metadata and documentation in the Zenodo record.
        - This ensures that the files are permanent and can always
        be accessed by the BHKLAB members and collaborators.
    - Any intermediate files that are generated by a pipeline are
    assumed to be reproducible and may be deleted at any time.
        - These files are not intended to be relied on for long-term
        storage and should not be used as a permanent solution for
        storing datasets.
