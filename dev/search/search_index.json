{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"General/","title":"Home","text":""},{"location":"General/#what-is-the-handbook","title":"What is the handbook?","text":"<p>The handbook is a collection of resources for the BHK Lab. It is intended to be a resource for all BHK Lab members to learn about the lab, its projects, and how to get involved.</p> <p>Insipiration:</p> <ul> <li>Koesterlab Handbook</li> <li>Candice Morey Lab Handbook</li> <li>Baby Lab Handbook</li> <li>Lowe Power Lab Handbook</li> <li>Vortex Lab Handbook</li> </ul>"},{"location":"General/#want-to-contribute","title":"Want to Contribute?","text":"<p>If you're interested in contributing to the BHK Lab Handbook, we encourage you to check out our Contributing Section.</p> <p>Whether you're looking to report an issue, add new content, or suggest an enhancement, the Contributing Section has all the resources you need to get started. Your contributions help make this handbook a valuable tool for the entire lab community!</p> <p>This handbook is under active development and open-source!</p> <p>Visit the GitHub repository to see the latest updates and contribute to the project.</p>"},{"location":"General/lab_mission/","title":"Mission Statement","text":"<p>At BHK Lab, we are on a mission to revolutionize precision oncology by developing cutting-edge computational tools and predictive models. Our goal is to identify new cancer vulnerabilities and improve the delivery of precision medicine to patients.</p>"},{"location":"General/lab_mission/#research-focus","title":"Research Focus","text":"<p>Dive into the world of pharmacogenomics and imaging analysis using the power of machine learning and deep learning. We are all about using innovative approaches to understand cancer better and find new ways to combat it.</p>"},{"location":"General/lab_mission/#our-values","title":"Our Values","text":"<ul> <li> <p>Research Transparency: We believe in open science and transparency in our work.</p> </li> <li> <p>Reproducibility: Our research is solid, reproducible, and ready for peer review.</p> </li> <li> <p>Reusability: We make sure our tools and models can be easily reused by others to advance cancer research.</p> </li> </ul>"},{"location":"General/lab_mission/#inclusion-diversity-equity-and-accessibility-idea","title":"Inclusion, Diversity, Equity, and Accessibility (IDEA)","text":"<p>We are committed to making science accessible to everyone. Inclusion, diversity, equity, and accessibility are not just buzzwords for us; they are the guiding principles of our lab.</p>"},{"location":"General/lab_mission/#lab-culture","title":"Lab Culture","text":"<p>Step into our world of collaboration and creativity! We're a diverse team from various disciplines, coming together to tackle one of the biggest challenges in medicine and we thrive on supporting each other's ideas.</p> <p>Join us in our quest to slay cancer, one line of code at a time! \ud83d\ude80 \ud83e\uddec \ud83d\udcbb</p>"},{"location":"General/Code_Of_Conduct/","title":"BHKLab Code of Conduct","text":"<p>TODO::</p>"},{"location":"General/Communications/bhklab_calendar/","title":"BHKLab Calendar","text":"<p>The BHKLab Calendar is managed by <code>bhklab.research@gmail.com</code> and contains events for </p> <ul> <li>Mandatory lab meetings</li> <li>One-on-one meetings with BHK</li> <li>Any other events the lab should be aware of</li> </ul> <p>Your BHKLab Gmail account will be added to the BHKLab Calendar as part of your Onboarding. Make sure you check this calendar and your BHKLab email regularly so you are aware of any changes to the regular schedule or invitations to your assigned presentation days.</p> <p>Note</p> <p>The BHKLab Calendar will not automatically be added to your Google Calendar. Once you've been added to the BHKLab-Members group, visit the group's Conversations and open the email with subject line \"BHKLAB Research has shared a calendar with you\" </p> <p>You should see an email like the one below including the link to add the calendar to your Google Calendar.</p> <p></p>"},{"location":"General/Communications/bhklab_gmail/","title":"BHKLab Gmail","text":"<p>In the BHKLab, we primarily use Google Drive for document creation, storage, and sharing and Google Calendar for all lab meeting scheduling. To improve collaboration, communication, and security, we require lab members to create a dedicated BHKLab Gmail.</p> <p>This email will be used for</p> <ul> <li>All lab document handling on Google Drive</li> <li>Sharing the BHKLab Google calendar</li> <li>Scheduling presentations for lab meetings and journal club meetings</li> </ul> <p>You are also welcome to use it to create accounts for tools related to your lab work, such as Miro or Paperpile.</p> <p>Note</p> <p>Your specified preferred contact email from your onboarding will be used for the majority of communications, but lab documents and calendar events must be accessed with your BHKLab Gmail account.</p> <p>When your time in the BHKLab is complete, control of the account will be transferred to the lab manager so documents can be accessed and transferred as needed.</p>"},{"location":"General/Communications/bhklab_gmail/#creating-your-bhklab-gmail-account","title":"Creating your BHKLab Gmail account","text":"<p>Creation of this email should be done during your BHKLab Onboarding when you completed the Onboarding Form, but we will describe it again here. If you have created the account already, you can skip to step 2.</p> <ol> <li> <p>Follow the steps described on the Create a Gmail Account page.</p> <p>a. The format of your email address will be </p> <pre><code>bhklab.firstnamelastname@gmail.com\n</code></pre> <p>(ex. bhklab.johnsmith@gmail.com) </p> </li> <li> <p>Once you have created the account, we recommend setting up a dedicated browser profile for it. Here are instructions for setting up a profile in:</p> <ul> <li>Google Chrome</li> <li>Mozilla Firefox</li> <li>Safari</li> </ul> </li> <li> <p>Your BHKLab Gmail will be added to the BHKLab Members Google Group. This will grant you access to lab-wide Google Documents.</p> </li> </ol> <p>Your BHKLab Gmail account is now ready to use!</p>"},{"location":"General/Communications/bhklab_gmail/#integrating-bhklab-gmail-with-other-tools","title":"Integrating BHKLab Gmail with other tools","text":"<p>We recommend adding your BHKLab Gmail account to your regular email app or setting up email forwarding to make it easier to keep on top of shared lab documents and updates to calendar events.</p>"},{"location":"General/Communications/bhklab_gmail/#add-gmail-account-to-your-email-app","title":"Add Gmail account to your email app","text":"<p>Please note, you will need to complete this process for each device you want to receive lab emails on.</p> <ul> <li>Outlook - Quick start: Add an email account to Outlook</li> <li>Gmail - Add another email account to the Gmail app</li> <li>Mail on Mac (Apple) - Add email accounts in Mail on Mac</li> </ul>"},{"location":"General/Communications/bhklab_gmail/#set-up-email-forwarding","title":"Set up email forwarding","text":"<p>Follow the steps described on the Automatically forward Gmail messages to another account page.</p>"},{"location":"General/Communications/bhklab_gmail/#bhklab-google-drive","title":"BHKLab Google Drive","text":"<p>Your BHKLab Google Drive is where you will store all of your lab documents. Any work related to your lab projects must be stored here. In specific instances, documents may be shared with or from the <code>bhklab.research@gmail.com</code> account - this is one of our administrative accounts that allows us to keep track of lab documents. </p> <p>If your document needs to be shared with other lab members, you may use their BHKLab Gmail account OR the BHKLab Google Group to make the document accessible to the entire lab.</p> <p>Warning</p> <p>Personal Gmail accounts should not be used for lab documents unless you are a short-term member of the lab (less than 1 month).</p>"},{"location":"General/Communications/bhklab_gmail/#file-sharing","title":"File Sharing","text":"<p>If your document needs to be shared with other lab members, you may use their BHKLab Gmail account OR the BHKLab Google Group to make the document accessible to the entire lab. If more than three people need access to the document, we recommend sharing it with the BHKLab Members group instead.</p>"},{"location":"General/Communications/bhklab_gmail/#to-share-a-document-with-the-google-group","title":"To share a document with the Google Group:","text":"<ol> <li>Open the document you wish to share from your Google Drive.</li> <li>Click the Share button in the top right corner of the document.</li> <li> <p>In the \"Add people, groups, and calendar events\" text box, enter</p> <pre><code>bhklab-members@googlegroups.com\n</code></pre> </li> <li> <p>Set the permission level as makes sense for the document.</p> </li> <li>Uncheck the Notify people option.</li> <li>Click Share.</li> </ol>"},{"location":"General/Communications/bhklab_gmail/#if-you-need-to-share-multiple-documents-or-folders","title":"If you need to share multiple documents or folders:","text":"<ol> <li>In the directory menu, select all the documents and/or folders you wish to share (<code>Shift + Click</code> to select multiple).</li> <li>Right click on the selected items and select <code>Share</code> and then <code>Share</code> again.</li> <li> <p>In the \"Add people, groups, and calendar events\" text box, enter</p> <pre><code>bhklab-members@googlegroups.com\n</code></pre> </li> <li> <p>Set the permission level as makes sense for each document. These will need to be set for each document or folder.</p> </li> <li>Uncheck the Notify people option.</li> <li>Click Share.</li> </ol> <p>This sharing method is useful for transferring ownership of existing lab documents on your personal Gmail account to your BHKLab Gmail account.</p> <p>Note</p> <p>For documents and folders related to manuscripts or grants, or any other specified instance, ownership still needs to be transferred to <code>bhklab.research@gmail.com</code> in addition to sharing with the BHKLab Members group.</p>"},{"location":"General/Communications/bhklab_gmail/#bhklab-calendar","title":"BHKLab Calendar","text":"<p>The BHKLab Calendar is managed by <code>bhklab.research@gmail.com</code> and contains events for </p> <ul> <li>Mandatory lab meetings</li> <li>One-on-one meetings with BHK</li> <li>Any other events the lab should be aware of</li> </ul> <p>Your BHKLab Gmail account will be added to the BHKLab Calendar as part of your Onboarding. Make sure you check this calendar and your BHKLab email regularly so you are aware of any changes to the regular schedule or invitations to your assigned presentation days.</p> <p>Note</p> <p>The BHKLab Calendar will not automatically be added to your Google Calendar. Once you've been added to the BHKLab-Members group, visit the group's Conversations and open the email with subject line \"BHKLAB Research has shared a calendar with you\" </p> <p>You should see an email like the one below including the link to add the calendar to your Google Calendar.</p> <p></p>"},{"location":"General/Communications/bhklab_gmail/#integrating-your-bhklab-gmail-calendar-with-other-tools","title":"Integrating your BHKLab Gmail Calendar with other tools","text":"<p>Warning</p> <p>You cannot view the BHKLAB calendar with a non-BHKLab Gmail account in the browser version of Google Calendar. Do not add any personal Gmail accounts to the BHKLAB calendar to try to do so.</p> <ul> <li> <p>If you added the email to Outlook on your Desktop, the calendar should be added automatically. Click on the Calendar icon on the far left side of the window, click the dropdown for your BHKLab Gmail account in the left panel, and toggle on the BHKLAB calendar under Other Calendars.</p> </li> <li> <p>If you are using the Google Calendar app on your phone, you can add the BHKLab Gmail account to view the BHKLAB calendar.</p> </li> <li> <p>If you are adding it to the Apple iCal app, open System Settings, add the BHKLab Gmail to your Internet Accounts, and make sure Calendars is toggled on. If it still isn't showing up, go to the Google Sync Settings and make sure BHKLAB is selected.</p> </li> </ul>"},{"location":"General/Manuscripts/","title":"Manuscript Standards","text":"<p>TODO::</p>"},{"location":"General/Meetings/","title":"Meetings","text":"<p>Here\u2019s an overview of mandatory meetings to attend. See lab calendar for locations as this might vary as per room availability. Please check with your supervisor/mentor about additional meetings where you are required to join.</p> Lab-Wide Meetings Frequency Date and time Slack channel Lab meeting Weekly Tuesdays, 10.30-12 p.m. #general #random Journal club Weekly Wednesdays, 12-1 p.m. #general #random <p>The following meetings are specific to disciplines in the lab and are mandatory for only members of that discipline. Other lab members are welcome to attend these meetings.</p> Discipline-specific Meetings Frequency Date and time Slack channel Radiomics team meeting Biweekly Tuesdays, 2-3 p.m. #radiomics PGx team meeting Biweekly Wednesdays, 1-2 p.m. #pharmacogenomics Software Developer team meeting Monthly Mondays, 12-1 p.m. #software-developer <p>We use The Meeting Owl for our meetings so they can be ran hybridly. See the Meeting Owl Basics page to learn more about how to use it.</p>"},{"location":"General/Meetings/Radiomics_meeting/","title":"Radiomics Meeting","text":""},{"location":"General/Meetings/Radiomics_meeting/#time-and-room","title":"Time and Room","text":"<p>Radiomics meeting happens every 2 weeks on Tuesday, 2:00 - 3:00pm at PMCRT 11-710.</p>"},{"location":"General/Meetings/Radiomics_meeting/#agenda","title":"Agenda","text":"<ul> <li>Flash updates: 5-10 minutes/person on what they\u2019re working on.</li> <li>Q&amp;A for project related challenges.</li> <li>Award/presentation updates, if any.</li> <li>Data updates: New ORCESTRA announcements for datasets, dataset suggestions, etc.  </li> <li>Grant updates.</li> </ul>"},{"location":"General/Meetings/Radiomics_meeting/#attendees","title":"Attendees","text":"<p>Attendance is mandatory for Radiomics lab members.</p>"},{"location":"General/Meetings/Radiomics_meeting/#resources","title":"Resources","text":"<p>The meeting notes need to be filled out for every meeting in the Radiomics meeting - coverage document.</p>"},{"location":"General/Meetings/journal_club/","title":"Journal Club","text":"<p>Welcome to Journal Club! </p> <p>Whether you\u2019re new to the lab or looking for a refresher, this guide will help you navigate Journal Club (JC)\u2014our weekly session to explore research papers, exchange ideas, and grow as scientists. Let\u2019s dive in!  </p>"},{"location":"General/Meetings/journal_club/#what-is-journal-club","title":"What Is Journal Club?","text":"<p>Journal Club is a bi-weekly session designed to:</p> <ul> <li>Discuss: Explore research papers relevant to our lab or scientific interests.</li> <li>Analyze: Evaluate the strengths and weaknesses of each study.</li> <li>Collaborate: Share insights on how the paper could impact or inspire our work.</li> <li>Apply: Optionally consider incorporating the findings or methods into your projects.</li> </ul> <p>It\u2019s all about learning, critiquing, and getting inspired.</p>"},{"location":"General/Meetings/journal_club/#when-and-where","title":"When and Where?","text":"<ul> <li>Day: Wednesdays, usually the first and third week of the month  </li> <li>Time: 12:00\u20131:00 PM  </li> <li>Location: PMCRT 11-710  </li> <li>Format: Two presenters (30 minutes each)  </li> </ul>"},{"location":"General/Meetings/journal_club/#how-journal-club-works","title":"How Journal Club Works?","text":"<ul> <li> <p>Presenters:</p> <ul> <li>Option 1: Each presenter discusses a different paper.</li> <li>Option 2: Both presenters focus on the same paper, with one highlighting its strengths and the other critiquing its weaknesses.</li> </ul> </li> <li> <p>Interactive Elements:</p> <ul> <li>Dumb Questioner: A participant is randomly chosen to ask a \u201cdumb\u201d question, encouraging open and fun discussions.</li> <li>Audience Poll: For shared papers, attendees vote on whether the positive or critical perspective was more compelling.</li> </ul> </li> </ul>"},{"location":"General/Meetings/journal_club/#how-to-present-at-journal-club","title":"How to Present at Journal Club?","text":"<ol> <li> <p>Choose a paper:</p> <ul> <li>Select a paper that interests you or aligns with the lab\u2019s focus.</li> <li>Ensure its relevance and potential impact on ongoing projects.</li> </ul> </li> <li> <p>Share the paper:</p> <ul> <li>Upload the paper to Slack at least one week before the meeting for participants to review.</li> </ul> </li> <li> <p>Prepare your slides:</p> <ul> <li>Title Slide: Include the full paper title, complete author list, and what journal the paper was published in. Screenshotting the article webpage is allowed and encouraged!</li> <li>Introduction: Why did you choose this paper?  </li> <li>Methods: How was the study conducted?  </li> <li>Results:  What are the key findings?  </li> <li>Key Takeaways: What are the main insights from the study?  </li> <li>Your Perspective: What worked well? What could be improved?  </li> </ul> </li> <li> <p>Presentation day:</p> <ul> <li>On the day of the meeting, you are responsible for retrieving the Meeting Owl and ensuring that it is set up for the meeting. See the Meeting Owl Basics page to learn more about how to use it.</li> </ul> <p>Warning</p> <p>If you are planning on presenting remotely, please connect with someone onsite to ensure the Meeting Owl is set up for you. </p> </li> </ol>"},{"location":"General/Meetings/journal_club/#audience-role","title":"Audience Role","text":"<p>Even if you\u2019re not presenting, your participation is essential!  </p> <ul> <li>Read the paper beforehand, if possible.  </li> <li>Engage: Ask questions and share your insights.  </li> <li>Be Open: Every perspective adds value.  </li> </ul>"},{"location":"General/Meetings/journal_club/#resources","title":"Resources","text":"<ul> <li>After presenting, upload your slides to the JC Slides List to maintain a shared record for future reference.</li> </ul> <p>Journal Club is a great way to stay curious, collaborate, and learn together. We look forward to seeing you there! </p>"},{"location":"General/Meetings/lab_meeting/","title":"Lab Meeting","text":""},{"location":"General/Meetings/lab_meeting/#details","title":"Details","text":"<p>Time: Every Tuesday from 10:30 AM to 12:00 PM.</p> <p>Venue: PMCRT 4-204.</p> <p>Presenter(s): One.</p>"},{"location":"General/Meetings/lab_meeting/#status-updates","title":"Status Updates","text":"<p>Every lab meeting begins with a 15-20 minute status update. See pre lab meeting catchup slides for a list of status update materials.</p>"},{"location":"General/Meetings/lab_meeting/#meeting-objectives","title":"Meeting Objectives","text":"<p>During lab meetings, you may present the research idea and feasibility, preliminary analyses, progress of your work, or any topics that require feedback from the lab.</p> <p>You will be sent an email notifying you of the date of presentation as per the lab schedule. If you want to (re)schedule a lab meeting, please contact the lab coordinator after finding a person to switch your presentation with.</p> <p>On the day of the meeting, you are responsible for retrieving the Meeting Owl and ensuring that it is set up for the meeting. See the Meeting Owl Basics page to learn more about how to use it.</p> <p>Warning</p> <p>If you are planning on presenting remotely, please connect with someone onsite to ensure the Meeting Owl is set up for you. </p>"},{"location":"General/Meetings/lab_meeting/#slides","title":"Slides","text":"<p>It is best to follow a standard slide format:</p> <ul> <li>Agenda</li> <li>Introduction</li> <li>Methods</li> <li>Results</li> <li>Challenges</li> <li>Key Takeaway/Learning</li> <li>Future Directions</li> </ul> <p>Tip</p> <p>Feel free to use the BHK lab-wide templates for the slide deck:</p> <ul> <li> <p>BHKLab External Presentation Template</p> </li> <li> <p>BHKLab Internal Presentation Template</p> </li> </ul>"},{"location":"General/Meetings/owl_basics/","title":"The Meeting Owl","text":"<p>The Owl is a device that works as video and audio input for all meetings conducted in the BHK lab. It is pivotal to include the Owl in all lab meetings to bridge the gap between the users tuning in remote to the users on site.</p>"},{"location":"General/Meetings/owl_basics/#how-to-findobtain-the-owl","title":"How to find/obtain the Owl","text":"<ol> <li>Go to Jermiah's work station (W-16).</li> <li>Grab the key located on the bottom side of Jermiah's desk.</li> <li>Using the key open the top drawer of the filing cabinet under Jermiah's workstation and grab the key labelled \"Owl key\".</li> <li>Use this new key to open the drawer labelled 'OWL' on the filing cabinet under the right end of the whiteboards and pull out the green Owl duffle bag.</li> </ol>"},{"location":"General/Meetings/owl_basics/#how-to-use-the-owl","title":"How to use the Owl","text":"<p>The Owl has two major setup components. </p> <ol> <li> <p>The Owl must be connected to an electrical outlet and also be connected to your computer via a USB connection. There is a USB-C dongle in the end pocket of the duffle bag for this purpose. Both wires plug into the bottom of the Owl.</p> </li> <li> <p>Once the Owl is connected to power and your computer, set it down in a spot that will be able to easily see/hear everyone participating in the meeting physically. If you're hosting the meeting you also want to verify that the Owl is being used as the audio and video input to the call.</p> </li> </ol> <p>Tip</p> <p>Make sure you are not using a blurred or photo background when using the Owl.</p>"},{"location":"General/Meetings/pgx_meeting/","title":"Pharmacogenomics Meeting","text":""},{"location":"General/Meetings/project_tracking/","title":"Project Tracking","text":""},{"location":"General/Meetings/project_tracking/#for-the-first-10-15-minutes-of-every-lab-meeting-the-lab-discusses-the-progress-of-the-projects","title":"For the first 10-15 minutes of every lab meeting, the lab discusses the progress of the projects.","text":"<p>When it is your turn to present, you must include a copy of this slide at the beginning of your slide deck.  We will be using it to go through the progress of the projects.</p> <p>We use four different spreadsheets to track updates. Each of them will be linked in their subsection below. </p>"},{"location":"General/Meetings/project_tracking/#to-dos-deadlines-for-bhk","title":"To Dos &amp; Deadlines for BHK","text":"<p>If there are any upcoming tasks or deadlines that you need Ben to address, this spreadsheet is where you add your requests. The following are the columns in the spreadsheet:</p> <ul> <li>Task: Add a general descriptive title for the task.</li> <li>Deadline: Add the deadline for this task.</li> <li>BHK review deadline: Add the deadline for when you need Ben to review the task.</li> <li>Lab Members: The lab members involved in this task. (If it's just yourself, only write your name. If it's multiple people, write all their names.)</li> <li>Comments: Add any additional comments that you think are necessary.</li> <li>Relevant links: Add any relevant links that are necessary for this task.</li> </ul>"},{"location":"General/Meetings/project_tracking/#manuscript-progress","title":"Manuscript Progress","text":"<p>If you have any updates on the progress of your manuscript, this spreadsheet is where you add your updates. The following are the columns in the spreadsheet:</p> <ul> <li>Lead Author (Mandatory): Add the name of the lead author of the manuscript. There can be multiple names if there are multiple lead authors working on this manuscript.</li> <li>Paper (Mandatory): Add the title of the manuscript.</li> <li>URL to the Folder (Mandatory): Add the URL to the folder where the manuscript and relevant files, such as figures, are stored.</li> <li>Status: A drop-down menu where you can select the status of the manuscript. For example, if the manuscript has been submitted, you can select 'Submitted to journal'</li> <li>Comments: Add any additional comments that you think are necessary. This will include any updates on the progress of the manuscript, such as if there are experiments being done, any review necessary, etc. This will typically be updated during pre-lab meeting overview.</li> </ul>"},{"location":"General/Meetings/project_tracking/#grants-award-applications","title":"Grants &amp; Award Applications","text":"<p>Information and updates regarding any grants or awards the lab is applying for can be found in this spreadsheet.  The following are the columns in the spreadsheet:</p> <ul> <li>Proposed project/idea: Add a general descriptive title for the project or idea.</li> <li>Name of the funding agency: Add the name of the funding agency you are applying to.</li> <li>Link to funding call: Add the URL to the funding call.</li> <li>Year of Submission: Add the year you are submitting the application.</li> <li>Application Type: Add the type of application you are submitting. For example, if you are submitting a grant, select 'Grant' from the drop-down menu.</li> <li>Applicants: Add the names of the applicants involved in this application. (If it's just yourself, only write your name. If it's multiple people, write all their names.)</li> <li>Name of PI: Add the name of the PI for this application.</li> <li>Name of Co-PIs: Add the names of the Co-PIs for this application.</li> <li>Deadline for Abstract: Add the deadline for the abstract submission.</li> <li>Deadline for LOI: Add the deadline for the Letter of Intent submission.</li> <li>Deadline for Full Application: Add the deadline for the full application submission.</li> <li>Status by Action: Add the current status of the application using the drop-down menu.</li> <li>Link to the Folder: Add the URL to the folder where the application and relevant files are stored.</li> <li>Comments: Add any additional comments that you think are necessary.</li> </ul>"},{"location":"General/Meetings/project_tracking/#data-access-status","title":"Data Access Status","text":"<p>Throughout your time in the lab, you may want to request access to additional datasets. This spreadsheet is where you can track the status of your data access requests. The following are the columns in the spreadsheet:</p> <ul> <li>Dataset Name: Add the name of the dataset you are requesting access to.</li> <li>Request Link: Add the URL to the request form or page, or where you can find more information on how to request access.</li> <li>Data Type: Add the type of data you are requesting access to; for example: RNA-seq, clinical data, etc.</li> <li>Lab Project: Add the lab project that this dataset is relevant to.</li> <li>Model Type: Add the type of model this data is using; for example: mouse model, cell line, patient data, etc.</li> <li>Processed Data: Add whether the data is raw or processed.</li> <li>Name of Requestor: Add the name of the person requesting access to the data.</li> <li>Lab Personnel in Charge: Add the name of the lab personnel in charge of this data request.</li> <li>Priority: Add the priority level of this data request.</li> <li>Submission Status: Add the status of the submission using the drop-down menu; for example, if the request has been approved, you can select 'Approved'.</li> <li>Data Location: Add the location of the data once the request has been approved; for example, if the data is stored in H4H, GCP, etc.</li> <li>Comments: Add any additional comments that you think are necessary.</li> </ul>"},{"location":"General/Presentations/","title":"Presentation Standards","text":""},{"location":"General/Presentations/#talk-standards","title":"Talk Standards","text":""},{"location":"General/Presentations/#key-slides","title":"Key Slides","text":"<ul> <li>Title slide: Include your name, date, affiliation, event/conference, and contact information (e.g. email). Optional: include the BHK Lab logo and others (e.g. UHN, University of Toronto, etc)</li> <li>Acknowledgements slide: Include names of lab members (or can reference 'BHK Lab') and other collaborators along with your institutional affilications/funding sources (e.g. UHN, CIHR, NSERC)</li> </ul>"},{"location":"General/Presentations/#other-slides","title":"Other slides","text":"<ul> <li>All slides should include slide numbers</li> <li>Slide headings should be short (1-2 lines max) and descriptive</li> <li>Use visuals whenever possible (feel free to take from existing presentations in the database)</li> </ul>"},{"location":"General/Presentations/#poster-standards","title":"Poster Standards","text":""},{"location":"General/Presentations/#components","title":"Components","text":"<ul> <li>Heading: Include title, author(s) name, supervisor name (if student poster) across the top border</li> <li>Abstract (optional): Brief paragraph (~250 words) outlining purpose, methods, results, and conclusions</li> <li>Introduction: Background information pertinent to your project to help audience understand motivation. Outline the goal, objective(s), and hypothesis(es) of your research.</li> <li>Materials and Methods: Brief outline of materials and methods used in your work, listed clearly and logically.</li> <li>Results: Present data in photographic, graphical, or tabular form. Include descriptive figure titles and avoid lengthy captions. Be sure to not include abbreviations not explained in the text.</li> <li>Discussion: Address results and describe relevance to objective(s) and hypothesis(es).</li> <li>Conclusions: Stated clearly and concisely, addressing project objectives and stating overall significance.</li> <li>References: All references (publications)</li> <li>Acknowledgements: Any key lab members, collaborators, and funding sources.</li> </ul>"},{"location":"General/Presentations/#text-sizing","title":"Text Sizing","text":"<p>Size of lettering must be large enough to be legible from approximately 2m. Use a clear and simple font between 18 point and 30 point in size. We recommend the following for Arial:</p> <ul> <li>18 point: best viewed at 1m (for figure titles, legends, acknowledgements, etc)</li> <li>24 point: best viewed at 2m (for main text)</li> <li>30 point: best viewed at 3m (for section headings)</li> </ul>"},{"location":"General/Presentations/#suggestions","title":"Suggestions","text":"<ul> <li>Avoid overloading with text, use bullet points where possible</li> <li>Whenever appropriate, use clear diagrams, figures, and tables (e.g. materials and methods)</li> </ul>"},{"location":"General/Presentations/database/","title":"Presentations Database","text":"<p>This page contains links to previously created presentations and is intended to support the creation of future presentations.</p>"},{"location":"General/Presentations/database/#2024-presentations","title":"2024 Presentations","text":"<p>Radiomics and Pharmacogenomics: From Research To Clinic (Slide Deck)</p> <p> Joint Symposium in Cancer Biology and Ecosystem, October 2024</p> <p>Pharmacogenomics Data Analysis (Slide Decks)</p> <p> Canadian Bioinformatics Workshop, October 2024</p> <p>An Open Science Approach to Computational Pharmacogenomics (Slide Deck)</p> <p> RECOMB/ISCB Regulatory &amp; Systems Genomics/DREAM conference, October 2024</p> <p>An Open Science Approach to Drug Response Prediction in Sarcoma (Slide Deck)</p> <p> 2024 NLMSF-SPAGN International LMS Research Roundtable, September 2024</p> <p>Development of Chromatin Accessibility Liquid Biopsy Biomarkers for Breast Cancer Drug Response Prediction (Slide Deck)</p> <p> 2024 Collaborative Breast Research Internal Award, June 2024</p> <p>Hallmarks of Drug Response Models: A Qualitative Framework to Evaluate Multivariable Predictive Biomarkers (Slide Deck)</p> <p> AACR Annual Meeting - San Diego, April 2024</p> <p>AI for Clinical Trials (Slide Deck)</p> <p> Amplitude, April 2024</p>"},{"location":"General/Presentations/database/#previous-presentations","title":"Previous Presentations","text":"<p>For presentations from 2023 and before, please visit the BHKLab website</p>"},{"location":"General/Presentations/database/#other-templates","title":"Other templates","text":"<p>Poster Template for Princess Margaret Cancer Centre (Drive link to template)</p>"},{"location":"General/Presentations/tools/","title":"Presentation Tools","text":"<p>This page describes standards, tools, and resources for creating presentations for the lab.</p> <p>Google Sheets</p> <p>All external presentations (conferences, workshops, external working groups), should be created on Google Sheets directly by or shared to the <code>bhklab.research@gmail.com</code> account.</p> <p>Internal presentations, such as journal clubs, should also be created on Google Sheets. *Link Lab Meeting and Journal Club pages here.</p> <p>Templates</p> <p>Several slide templates have already been developed for the lab: </p> <ul> <li>BHKLab Internal Presentations Template</li> <li>BHKLab External Presentations Template</li> </ul> <p>Miro</p> <p>Miro is a collaborative white board platform that enables simple diagram and multi-figure panel creation for presentations and/or manuscripts. For diagrams that will be used and updated by others in the lab, please request a Miro Board be created via the BHK Lab Miro account.</p> <p>Images and Icons</p> <p>The following are open-source biological imaging databases and platforms. The BHK Lab holds a premium Flaticon account. If Biorender and/or BioArt are used, please remember to add them to the acknowledgements.</p> <ul> <li>Flaticon</li> <li>Biorender</li> <li>BioArt</li> </ul> <p>Slido</p> <p>Slido is an interactive polling platform that can be easily integrated into Google Sheets. We recommend using this platform to improve engagement in presentations, particularly workshops or other relevant use cases.</p>"},{"location":"General/Projects/","title":"Projects","text":""},{"location":"General/Summary_Of_Work/","title":"Summary of Work Tutorial","text":"<p>Every week, you are required to fill out a Summary of Work (SOW) document that will be reviewed by Ben. This is especially important when Ben is away from the lab, so he can stay up to date on your project progress.</p> <p>This tutorial will walk you through how to set up a Google Drive SOW directory and yearly document, and how to write your weekly SOW.</p>"},{"location":"General/Summary_Of_Work/#prerequisites","title":"Prerequisites","text":"<p>Visit the Google Drive website and ensure you are logged into the correct account.</p> Use the Correct Google Account <p>This tutorial will utilize the Google Drive associated with the BHKLab Gmail account that you would have set up during the  BHKLab Onboarding process. Ensure you are logged into the correct account before continuing.</p> <p>If you are a short-term employee (less than one month), you may complete the instructions below with a personal Gmail account.</p>"},{"location":"General/Summary_Of_Work/#setting-up-your-sow-space","title":"Setting Up Your SOW Space","text":"Note <p>This section will need to be repeated in January of each year.</p>"},{"location":"General/Summary_Of_Work/#directory-creation","title":"Directory Creation","text":"<p>In your BHKLab Google Drive, create a folder called <code>SOW</code>. In the sharing menu (1), add <code>bhklab-admin@googlegroups.com</code> as an Editor.</p> <ol> <li><code>right-click</code> on the folder and select <code>Share</code>.</li> </ol> <p>Within this folder, create another folder and name it the current year (e.g. <code>2025</code>).</p>"},{"location":"General/Summary_Of_Work/#document-creation","title":"Document Creation","text":"<p>Next, open the SOW template document. In the File menu, select <code>Make a copy</code>.</p> <ul> <li>Name the copy as <code>&lt;Your Name&gt;-SOW-&lt;Year&gt;</code>. (e.g. <code>John-SOW-2025</code>).</li> <li>Select the year folder you just created as the destination.</li> <li>Check the box for <code>Share it with the same people</code></li> <li>Click <code>Make a copy</code></li> </ul> <p>Once created, make sure the sharing permissions include <code>bhklab-admin@googlegroups.com</code>.</p>"},{"location":"General/Summary_Of_Work/#add-your-page-to-the-main-sow-tracker","title":"Add Your Page to the Main SOW Tracker","text":"<p>In the SOW for BHK document, find your job title. Under this heading, insert a File smart chip (1). To find your SOW file, start typing your name and it should appear as one of the options.</p> <ol> <li>type <code>@</code> and start typing the name of the file you created (i.e. <code>John-SOW-2025</code>). Click on the file when it appears in the dropdown.</li> </ol> <p>This is where Ben will access your SOW from weekly.</p>"},{"location":"General/Summary_Of_Work/#creating-your-sow-page","title":"Creating Your SOW Page","text":""},{"location":"General/Summary_Of_Work/#set-up-this-weeks-tab","title":"Set up this week's tab","text":"<p>Open your SOW document you copied in the Document Creation section.</p> <ol> <li>In the document tab menu on the left hand side, duplicate an existing SOW page.</li> <li>Drag the duplicated tab to the top of the list.</li> <li>Rename the tab to be the current week's dates.</li> </ol>"},{"location":"General/Summary_Of_Work/#writing-your-sow","title":"Writing Your SOW","text":"<p>Date: Set the dates at the top of the page to the first and last day of the current week (usually Monday and Friday).</p> <p>Win: Detail work done on projects during the week.</p> <p>Needs Input: Any questions or concerns for BHK. BHK will respond to these on Slack.</p> <p>Focus: What you plan to work on next week.</p> <p>Important links: Links to anything you mentioned in the above sections.</p> <p>BHK Read Marker: For BHK use only.</p> <p>Note</p> <p>If you copied the previous week\u2019s SOW, make that this is set to unchecked. Unchecked:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Checked:\u00a0\u00a0\u00a0</p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/","title":"Confluence SOW Tutorial (outdated)","text":"<p>Outdated Warning</p> <p>This tutorial is outdated and no longer in use. Please refer to the Google Drive SOW Tutorial for the most up-to-date instructions.</p> <p>This tutorial will walk you through how to access Confluence, set up your Page Tree, and to write your weekly Summary of Work (SOW). </p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#logging-on-to-confluence","title":"Logging on to Confluence","text":"<p>Make sure you are connected to either  </p> <ol> <li>the UHN-wireless-corporate wifi if you are on-site  </li> <li>the UHN VPN via GlobalProtect or otherwise if you are off-site or the UHN-wireless-corporate wifi is unavailable</li> </ol> <p>Note</p> <p>You cannot connect to the VPN if you are connected to the UHN-wireless corporate wifi </p> <p>Head to this link: BHKLab SOW Confluence Space. You should see a page like this:  </p> <p>Log in using your UHN username (usually your TID) and your UHN password.</p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#navigating-to-the-bhklab-sow-space","title":"Navigating to the BHKLab-SOW Space","text":"<p>The link from step 2 should take you directly to the BHKLab-SOW space once you\u2019re logged in that looks like this: </p> <p>If you end up on a different page, navigate to the Spaces dropdown and select BHKLab-SOW: </p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#finding-your-section-in-the-page-tree","title":"Finding your section in the Page Tree","text":"<p> On the left side of the BHKLab-SOW page, find the PAGE TREE section and find the position name that you fall under. </p> <p>This will likely be the only one with an arrow (&gt;) next to it. </p> <p>Click this to list the files under this page, which should be a page with your first and last name.</p> <p>Note</p> <p>If your name does not exist under the position you can open, stop here and contact a lab manager. They will set up the page appropriately for you.</p> <p>Click the page with your name on it. </p> <p>You should now see a page like this with your name as the title.</p> <p></p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#setting-up-the-year-page-for-your-sows","title":"Setting up the year page for your SOWs","text":"<p>While on the page with Your Name on it, click the blue Create button at the top of the screen.</p> <p>You should now see a blank page that you can edit.  </p> <p>Complete the following:</p> <ol> <li> <p>In the Page title section, enter the year and your initials in the format YYYY - YN</p> </li> <li> <p>Click on the red lock icon next to the DRAFT label. This will open a Restrictions menu. Click on the inherited view restrictions link (it will be blue). </p> </li> <li> <p>Under Your Name, confirm that BHK and a lab manager\u2019s names are listed along with your own. This ensures that no one else can view your SOWs besides them. </p> <p>Warning</p> <p>If BHK and Sisira are not listed, contact a lab manager to have them set up the permissions properly.</p> </li> <li> <p>Click the blue Publish button at the bottom right of the screen.</p> </li> </ol> <p>You should now see the page you just published listed under Your Name on the Page Tree. This is where you will navigate to to create your SOWs each week. When a new year starts, you will neeed to repeat this section to create a new year page. </p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#creating-your-sow-page","title":"Creating your SOW Page","text":"<p>Navigate to the page under your name with the current year and your initials. There are two options to create this week\u2019s SOW:    </p> <p>Note</p> <p>If this is your first ever SOW, follow From Create template</p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#from-create-template","title":"From Create template","text":"<ol> <li> <p>Click on the blue ellipses (...) button next to Create at the top of the page.</p> </li> <li> <p>From the Create pop-up menu, scroll down and find the template labeled BHKLab-SOW.</p> <p>a. Select this and click Create on the bottom right of the pop-up. </p> </li> </ol>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#from-previous-weeks-sow","title":"From previous week\u2019s SOW","text":"<ol> <li> <p>In the page tree, click on your last published SOW</p> </li> <li> <p>In the top right, click on the ellipses (...) and select Copy from the dropdown menu </p> </li> <li> <p>In the Copy page menu, make sure the parent page is set to the right year and click the blue Copy button </p> </li> </ol>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#writing-your-sow","title":"Writing your SOW","text":"<p>Date: Set the dates in the yellow box to the first and last day of the current week (usually Monday and Friday)</p> <p>Page Title: Write the dates exactly as shown in the yellow Date box and your initials</p> <p>Note</p> <p>Note: the initials must be included in the title as Confluence won\u2019t accept pages with the exact same name (e.g. you and another labmate post an SOW without initials)**  </p> <p>Win: Detail work done on projects during the week</p> <p>Needs Input: Any questions or concerns for BHK. BHK will respond to these on Slack.</p> <p>Focus: What you plan to work on next week</p> <p>Important links: Links to anything you mentioned in the above sections.</p> <p>BHK Read Marker: For BHK use only. </p> <p>Note</p> <p>If you copied the previous week\u2019s SOW, make that this is set to unchecked. Unchecked:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Checked:\u00a0\u00a0\u00a0</p> <p>Once completed, hit the blue Publish button in the bottom right or use <code>Ctrl + S</code> or <code>Cmd + S</code>. Your SOW should now be located under the year - your initials page in the Page Tree at the bottom of your SOW list. THIS NEEDS TO BE MOVED TO THE TOP. </p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#reordering-your-sow-pages","title":"Reordering your SOW pages","text":"<p>Navigate to Space Tools by either: </p> <ol> <li> <p>Clicking on the ellipses (...) menu at the top right of the SOW page and selecting View in Hierarchy</p> </li> <li> <p>Clicking Space tools at the bottom of the PAGE TREE section and selecting Reorder pages</p> </li> </ol> <p>On the Space Tools page, click and drag your most recent SOW and move it so it is directly below the year - initials page:     Before:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0After:  </p> <p>Click on the latest SOW to confirm it\u2019s been properly moved.</p> <p>You have now completed your SOW for the week!</p>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#draft-sow","title":"Draft SOW","text":"<p>If your SOW page is not showing up in the PAGE TREE, it has likely been saved to your page drafts.</p> <ol> <li> <p>Click the Confluence logo in the top left of the site.</p> </li> <li> <p>You should now be on the homepage with Recently worked on files listed. Your draft SOW will be listed here if it was saved. </p> </li> <li> <p>Click on it to continue editing and make sure to hit the Publish button in the bottom right. </p> </li> </ol>"},{"location":"General/Summary_Of_Work/old_confluence_instructions/#turning-off-notifications","title":"Turning off Notifications","text":"<p>If you want to turn off email notifications from Confluence: </p> <ol> <li> <p>Click on your profile photo in the top right and select Settings.</p> </li> <li> <p>Select Email under the left panel labeled Your Settings.</p> </li> <li> <p>Select Edit at the bottom of the page, and uncheck Recommended Updates and/or Daily Updates.</p> </li> </ol>"},{"location":"contributing/","title":"Contributing to the Lab Handbook","text":"<p>Thank you for your interest in contributing to the Lab Handbook!</p> <p>This section will guide you through the process of setting up your development environment, installing dependencies, and building the documentation.</p>"},{"location":"contributing/#contributing-principles","title":"Contributing Principles","text":"<p>The Lab Handbook is a community-driven effort, and we welcome contributions from everyone. Here are some principles we follow when reviewing and approving contributions:</p>"},{"location":"contributing/#by-the-lab-for-the-lab","title":"By the lab, for the lab","text":"<ul> <li>Pages can be created, edited, and reviewed by anyone in the lab</li> <li>Every page is understandable by anyone in the lab</li> <li>Maintenance and upkeep is a responsibility shared by everyone in the lab</li> </ul>"},{"location":"contributing/#kiss-keep-it-simple-stupid","title":"KISS - Keep It Simple, Stupid","text":"<p>(or Keep It Short and Simple)</p> <ul> <li>We strive to keep the handbook focused and concise to make it easy for anyone to understand</li> <li>We avoid unnecessary complexity</li> </ul>"},{"location":"contributing/#dry-dont-repeat-yourself","title":"DRY - Don't Repeat Yourself","text":"<ul> <li>Saves time and energy</li> <li>If details already exist on another page or website, link to it, don\u2019t copy paste</li> <li>When making a page, remember it might get referred to somewhere else!</li> </ul>"},{"location":"contributing/#for-contributors","title":"For Contributors","text":"<p>Below are some common questions to help you find the right guidance for specific contributing tasks.</p>"},{"location":"contributing/#where-should-i-start-if-i-want-to-contribute","title":"Where should I start if I want to contribute?","text":"<p>If you\u2019re new to contributing, start with the Prerequisites page to set up your environment and install necessary dependencies.</p>"},{"location":"contributing/#how-do-i-submit-an-issue-for-a-problem-i-found","title":"How do I submit an issue for a problem I found?","text":"<p>If you\u2019ve identified an issue, refer to the Submitting Issues page.  It provides details on how to use our issue templates and submit effective bug reports or feature requests.</p>"},{"location":"contributing/#how-can-i-add-new-content-to-the-handbook","title":"How can I add new content to the handbook?","text":"<p>To learn about adding or editing content, check out the Adding Content page.  This guide explains how to structure and format your additions to fit seamlessly into the handbook.</p>"},{"location":"contributing/#what-steps-are-involved-in-the-review-process","title":"What steps are involved in the review process?","text":"<p>The Reviewing a Contribution page outlines the review process, including best practices for constructive feedback and steps for both reviewers and contributors.</p>"},{"location":"contributing/#where-can-i-view-all-the-changes-made-to-the-handbook","title":"Where can I view all the changes made to the handbook?","text":"<p>To see recent updates and changes to the documentation, visit the Changelog page for a record of all documented changes.</p> <p>By following these resources, you'll have everything you need to contribute effectively to the Lab Handbook. If you have additional questions, feel free to reach out to the maintainers or submit a question through the Submitting Issues page.</p>"},{"location":"contributing/#for-maintainers","title":"For Maintainers","text":""},{"location":"contributing/#what-should-i-know-about-merging-pull-requests","title":"What should I know about merging pull requests?","text":"<p>For guidance on merging contributions, visit the Merging PR page.  It explains our review process, how to address review comments, and merge a PR successfully.</p>"},{"location":"contributing/#how-do-i-prepare-for-releasing-and-deploying-changes","title":"How do I prepare for releasing and deploying changes?","text":"<p>Check out the Release &amp; Deployment page to learn about our release procedures, automated workflows, and deployment to GitHub Pages.</p>"},{"location":"contributing/adding_content/","title":"Adding Content","text":""},{"location":"contributing/adding_content/#introduction","title":"Introduction","text":"<p>This document will guide you through the process of adding a new page to the handbook.</p> <p>Tip</p> <p>The handbook is built using MkDocs and Material for MkDocs. These tools also have extensive documentation and guides for contributing to a Mkdocs project.</p> <p>Please refer to their respective documentation first for any questions you might have.</p>"},{"location":"contributing/adding_content/#adding-content-to-the-documentation","title":"Adding Content to the Documentation","text":"<p>The documentation is written in Markdown and can be found in the <code>docs</code> directory.</p> <p>Here are the steps to add new content to the documentation:</p>"},{"location":"contributing/adding_content/#1-create-a-branch-for-your-changes","title":"1. Create a branch for your changes","text":"Note: Naming your branch <p>A branch is a way to work on a new feature or bug fix without affecting the main branch. The standard for this project is to use the following format:</p> <p><pre><code>$ &lt;author-ID&gt;/&lt;purpose-of-branch&gt;\nOR\n$ &lt;author-ID&gt;/&lt;issue-reference&gt;\n</code></pre> Where <code>&lt;author-ID&gt;</code> can be a GitHub username or an alias.</p> <p><code>&lt;purpose-of-branch&gt;</code> is a short description of the changes you are making. <code>&lt;issue-reference&gt;</code> is the number of the issue you are working on.</p> <p>For example:</p> <pre><code>$ jjjermiah/adding-getting-started-page\nOR\n$ jjjermiah/13-docs-finish-tutorial-for-page-review\n</code></pre> <p>To create a new branch and switch to it, run the following command:</p> <pre><code>git checkout -b &lt;branch-name&gt;\n$ git checkout -b jjjermiah/adding-getting-started-page\n</code></pre> <p>If you already have a named branch, you can switch to it with the following command:</p> <pre><code>git switch &lt;branch-name&gt;\n$ git switch jjjermiah/adding-getting-started-page\n</code></pre>"},{"location":"contributing/adding_content/#2-add-your-new-content-to-the-docs-directory","title":"2. Add your new content to the <code>docs</code> directory","text":"How do I know where to create my file? <p>The command below will create an empty Markdown file called <code>my_new_page.md</code> in the <code>docs/onboarding_offboarding</code> directory. The relative path to the <code>docs</code> directory, will be the link to your new page.  i.e the link to your new page will be <code>&lt;website-url&gt;/handbook/onboarding_offboarding/my_new_page/</code></p> <p>Let's say you want to add a new page to the <code>Onboarding/Offboarding</code> section. You would add a new file to the <code>docs/onboarding_offboarding</code> directory.</p> <pre><code>$ touch docs/onboarding_offboarding/my_new_page.md\nYou should now see a new file at `docs/onboarding_offboarding/my_new_page.md`.\n</code></pre> <p>You may need to add your page to the <code>.pages</code> file</p> <p>If you are adding a new page to the handbook, you may need to add the new page to the <code>.pages</code> file that lives in the same directory in which your new page is located. This file is used to generate the navigation menu for the handbook.</p> <p>To add your new page to the <code>.pages</code> file, open the file and add the relative path to your new page. For example, if you added a new page to the <code>onboarding_offboarding</code> directory, you would add the following line (highlighted in green) to the <code>onboarding_offboarding/.pages</code> file:</p> <pre><code>title: Onboarding / Offboarding\n\nnav:\n    - Onboarding\n    - Offboarding\n+   - onboarding_offboarding/my_new_page.md\n</code></pre> <p>This will add a link to your new page in the navigation menu.</p> <p>To learn more about how to actually write content, see the Handbook MkDocs Page and Handbook Markdown page.</p>"},{"location":"contributing/adding_content/#3-preview-your-changes","title":"3. Preview your changes","text":"<p>The following is a <code>pixi task</code> that will start a local server and preview the documentation at <code>http://localhost:8001</code> (aka <code>http://127.0.0.1:8001</code>).</p> <pre><code>$ pixi run serve\nINFO    -  Building documentation...\nINFO    -  Cleaning site directory\n...\nINFO    -  [08:55:05] Serving on http://127.0.0.1:8001/handbook/\n</code></pre> <p>You should see your changes appear at <code>http://127.0.0.1:8001/handbook/onboarding/my_new_page/</code></p> <p>Tip</p> <p>You can set the handbook website to automatically open in your default browser by using the <code>-o</code> flag:</p> <pre><code>pixi run serve -o\n</code></pre> <p>About the port number</p> <p>By default, we host the local site on port <code>8001</code> because it is more likely to be unused and available for the local server to use. In the case that you would like to manually specify a different port (e.g. if it's in use by something else), you can use the <code>-a</code> flag after <code>pixi run serve</code>.</p> <p>For example, to run on port <code>1234</code>: <pre><code>pixi run serve -a localhost:1234\n</code></pre></p>"},{"location":"contributing/adding_content/#4-commit-and-push-your-changes-to-your-branch","title":"4. Commit and push your changes to your branch","text":"<pre><code>git add .\ngit commit -m \"Add new getting started page\"\ngit push --set-upstream origin jjjermiah/adding-getting-started-page\n</code></pre>"},{"location":"contributing/adding_content/#5-create-a-pr","title":"5. Create a PR","text":"<p>Create a pull request (PR) to merge your changes into the main branch. Request a review from a maintainer.</p> <p>See the section on Reviewing a Contribution for more information.</p>"},{"location":"contributing/changelog/","title":"Handbook Changes Over Time","text":""},{"location":"contributing/changelog/#changelog","title":"Changelog","text":""},{"location":"contributing/changelog/#070-2025-02-14","title":"0.7.0 (2025-02-14)","text":""},{"location":"contributing/changelog/#features","title":"Features","text":"<ul> <li>Add \"What is Machine Learning\" page to the handbook (#84) (34b3fab)</li> <li>Add Communications section and BHKLab Gmail page (#131) (648743d)</li> <li>add Introduction to git slides to version control docs and fix up quick git tips (#123) (8eb99fa)</li> <li>add lab server page to Remote_Development (#136) (142eaec)</li> <li>Add new lab expertise page (#145) (bd3be40)</li> <li>added note about adding the BHKLab calendar to your BHKLab Gmail with the email (aa72aa8)</li> <li>Adding a new page for STAR alignment (#93) (ed2e6de)</li> <li>Google Cloud Platform page added (#92) (b2fea5c)</li> <li>make all tables sortable (#147) (a89b5ae)</li> <li>migrate information from the Employee Onboarding Policy (#127) (def834d)</li> <li>update BHKLAB calendar setup (#143) (35d1dff)</li> <li>update BHKLab Gmail page (#135) (0f2dddd)</li> <li>update-SOW-instructions (#138) (b4cee1f)</li> <li>updated BHKLab Calendar instructions (#142) (aa72aa8)</li> <li>updates to the journal club page (#139) (de22192)</li> </ul>"},{"location":"contributing/changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>PGx meetings are biweekly (#133) (4777bcd)</li> <li>update BHKLab Google group to be Members instead of Google Accou\u2026 (#134) (51a7ec2)</li> <li>update BHKLab Google group to be Members instead of Google Accounts and update hyperlink (51a7ec2)</li> </ul>"},{"location":"contributing/changelog/#060-2024-11-27","title":"0.6.0 (2024-11-27)","text":""},{"location":"contributing/changelog/#features_1","title":"Features","text":"<ul> <li>add a page for DESeq (#91) (73d51b6)</li> <li>add angular commit description to contributing (#100) (cd6ee02)</li> <li>add concurrency settings to GitHub workflows to prevent workflows pushing to gh-pages at the same time from failing (6735fd5)</li> <li>add documentation on code-reviews, and embed the presented slides  (#111) (e03e6ef)</li> <li>add presentation tools and database (#108) (9c81b17)</li> <li>add QIPCM image retrieval guide (#102) (55cebe5)</li> <li>add table of contents to Confluence SOW tutorial page (#99) (d73f29b)</li> <li>added \"basics of RNAseq\" under Disciplines/Bioinformatics/Data_Types (#88) (c6390aa)</li> <li>added journal club md (#89) (1f9557f)</li> <li>Added Owl page under General/Meetings/ (#90) (3982918)</li> <li>added page on BHKlab meeting under General/Meetings/ (#85) (f534b03)</li> <li>added project tracking  (#94) (a1f250e)</li> <li>added radiomics-meeting-page under General/Meetings (#83) (680f1d4)</li> <li>added sow tutorial page under General (#82) (b8ce45c)</li> <li>Added tidyverse page under <code>software_development/languages/R</code> (#87) (1a9c2a1)</li> <li>cgeady add slicer info (#109) (8779235)</li> <li>Creating vpn page (#95) (d5c9d8a)</li> <li>migrate Clinical Trial Curation page from BHKLab Confluence (#105) (fe2386b)</li> <li>update directory structure with all section heading pages for assigned pages for tutorial (#58) (72f314a)</li> <li>updates to RNA-Seq information (#122) (92607f3)</li> </ul>"},{"location":"contributing/changelog/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>add ... to all .pages (b0d375f)</li> <li>fix <code>pixi run serve</code> warnings (#107) (40c23c6)</li> <li>incremented default port to 8001 (#120) (b086865)</li> <li>Rename Hackathon Page Request to hackathon_page_request (#66) (a37262f)</li> <li>Rename hackathon_page_request to hackathon_page_request.md (0f3f821)</li> <li>update information in Contributing section (#121) (c623418)</li> </ul>"},{"location":"contributing/changelog/#050-2024-11-06","title":"0.5.0 (2024-11-06)","text":""},{"location":"contributing/changelog/#features_2","title":"Features","text":"<ul> <li>add footnotes support and enhance social links in MkDocs configuration (1a4dd35)</li> <li>add guiding principles for contributing to the handbook (#52) (31e196e)</li> <li>add header autohide feature, reorganize markdown extensions (fc994d8)</li> <li>add markdownlint configuration and ignore rules for improved linting (0fe0d8a)</li> <li>enhance contributing documentation with clearer instructions and new examples (6d7cc6b)</li> <li>link hpc4health site under software development (#51) (f7361aa)</li> <li>update onboarding / offboarding section (#53) (3c86b05)</li> </ul>"},{"location":"contributing/changelog/#040-2024-11-04","title":"0.4.0 (2024-11-04)","text":""},{"location":"contributing/changelog/#features_3","title":"Features","text":"<ul> <li>add Markdown and MkDocs documentation sections for improved clarity and guidance (90d0e7e)</li> <li>add repository name to mkdocs configuration and update icon reference (6bc7cd1)</li> <li>improve clarity in contributing guide by refining section headings and adding notes (f8b37f1)</li> <li>refactor software development documentation structure with new sections on development environment and related tools (05eb33b)</li> </ul>"},{"location":"contributing/changelog/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>formatting (5c25c0e)</li> <li>formatting (5c25c0e)</li> <li>git config --local only if we checkout (f819f89)</li> <li>lint files (2c958fb)</li> <li>revise handbook introduction and contribute guidelines for clarity and better onboarding experience (2c958fb)</li> </ul>"},{"location":"contributing/changelog/#031-2024-10-29","title":"0.3.1 (2024-10-29)","text":""},{"location":"contributing/changelog/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>use github action for deployment (f48ce66)</li> </ul>"},{"location":"contributing/changelog/#030-2024-10-29","title":"0.3.0 (2024-10-29)","text":""},{"location":"contributing/changelog/#features_4","title":"Features","text":"<ul> <li>enhance release workflow to publish version of docs using mike after PR release (72345a7)</li> <li>use mike (ec14831)</li> </ul>"},{"location":"contributing/changelog/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>rename redirect (252f3e2)</li> <li>update docs to explain mike (72345a7)</li> </ul>"},{"location":"contributing/changelog/#020-2024-10-29","title":"0.2.0 (2024-10-29)","text":""},{"location":"contributing/changelog/#features_5","title":"Features","text":"<ul> <li>Add issue templates (#28) (0a2c861)</li> <li>Add release and deployment documentation; update pixi.lock for dependencies and versions (27bd2fd)</li> <li>Create detailed guide for submitting issues, including templates and tips for effective reporting (ac69542)</li> <li>replace discipline temp files with index.md pages, organize disciplines (ae1bb27)</li> <li>Update issue templates for bug reports, content updates, documentation questions, and enhancements (30ee8d5)</li> </ul>"},{"location":"contributing/changelog/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>broken links in disciplines home tab (9393314)</li> <li>CI to fetch from depth 0 (dbcae75)</li> <li>remove deploy task so users dont mess it up (92fb375)</li> <li>update git push command in adding_content.md to set upstream for new branch; fixes #30 (df76944)</li> </ul>"},{"location":"contributing/changelog/#010-2024-10-25","title":"0.1.0 (2024-10-25)","text":""},{"location":"contributing/changelog/#features_6","title":"Features","text":"<ul> <li>add Conventional PR name check (#22) (beb1149)</li> <li>add documentation on Contributing (156c47e)</li> <li>add new documentation for code reviews and merging process, improving contributing guidelines for maintainers (#23) (156c47e)</li> <li>major updates (76ce766)</li> <li>Set up project structure with MkDocs, added configuration, documentation files, and specified dependencies in pixi.toml (0c17072)</li> <li>update structure (ceb66dd)</li> </ul>"},{"location":"contributing/changelog/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>add more info on merging PRs #24 (5307eda)</li> <li>format admonition (beb5d11)</li> </ul>"},{"location":"contributing/changelog/#miscellaneous-chores","title":"Miscellaneous Chores","text":"<ul> <li>release 0.1.0 (8102126)</li> </ul>"},{"location":"contributing/conventional_commits/","title":"Conventional Commits","text":"<p>We follow the Conventional Commits specification for commit messages. This helps us automate our release process and keep our commit history clean.</p> <p>This style is mandatory for merging pull requests on the handbook, but are recommended for all commits.</p> <p>The main points are summarized below, but you can read the full spec here.</p>"},{"location":"contributing/conventional_commits/#commit-message-format","title":"Commit Message Format","text":"<p>Each commit message consists of a header, a body and a footer. The header has a special format that includes a <code>&lt;type&gt;</code>, a <code>&lt;scope&gt;</code> and a <code>&lt;summary&gt;</code>:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;short summary in present tense&gt;\n\n[optional body: explains motivation for the change]\n\n[optional footer(s): note BREAKING CHANGES here, and issues to be closed]\n</code></pre> <p>The <code>&lt;scope&gt;</code> of the header is optional and provides context for where the change was made. It can be anything relevant to your package or development workflow (e.g., it could be the module or function - name affected by the change).</p> <p><code>&lt;type&gt;</code> refers to the kind of change made and is usually one of:</p> <ul> <li><code>feat</code>: A new feature.</li> <li><code>fix</code>: A bug fix.</li> <li><code>docs</code>: Documentation changes.</li> <li><code>style</code>: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc).</li> <li><code>refactor</code>: A code change that neither fixes a bug nor adds a feature.</li> <li><code>perf</code>: A code change that improves performance.</li> <li><code>test</code>: Changes to the test framework.</li> <li><code>build</code>: Changes to the build process or tools.</li> <li><code>ci</code>: Changes to CI configuration files and scripts (example scopes: Travis, Circle, BrowserStack, SauceLabs).</li> <li><code>chore</code>: Other changes that don't modify src or test files.</li> </ul> <p>Other types may be defined per project, but these are the most common.</p>"},{"location":"contributing/conventional_commits/#sources","title":"Sources","text":"<ol> <li>Angular Commit Format Reference Sheet - Brian Clements</li> <li>Origin of Angular Commit Style - AngularJS Git Commit Guidelines</li> <li>Py-Pkgs tutorial - Automatic version bumping using Angular Commit Style</li> </ol>"},{"location":"contributing/merging_pr/","title":"Merging Pull Requests","text":"<p>For Maintainers</p> <p>Only a subset of members of the BHK Lab organization can merge pull requests. If you are a maintainer, you can merge a pull request by following the steps below.</p>"},{"location":"contributing/merging_pr/#validating-the-pull-request","title":"Validating the Pull Request","text":"<p>Before merging a pull request, it is important to validate the following:</p> <ol> <li>Does the pull request have a title that is descriptive and concise?</li> <li>Do all the Github Actions pass?</li> <li>Has the pull request been reviewed by at least one member of the lab?</li> <li>Are there any merge conflicts?</li> <li>Does the PR add files that should not be added or mistakes? (i.e <code>.DS_Store</code>)</li> </ol>"},{"location":"contributing/merging_pr/#merge-strategy","title":"Merge Strategy","text":"<p>Traditionally, when merging a pull request, all the commits from the pull request are added to the main branch as individual commits along with a merge commit (usually like <code>Merge pull request #123 from user/branch</code>).</p> <p>This is called a Merge Commit.</p> Merge commit example <p>We use the Squash Merge strategy for merging pull requests to the lab handbook.</p> <p>Squash merges are a way to combine multiple commits into a single commit. Instead of seeing all the author's individual commits in the main branch's commit history, you can see a single commit summarizing all the changes.</p> Squash merge example <p>More information on squash merges can be found in the GitHub Docs on Squash Merges</p> <p>This has a few benefits:</p> <ol> <li>It keeps the commit history clean and organized.</li> <li>It reduces the number of commits in the main branch, making it easier to manage.</li> <li>Avoids the <code>Merge branch 'main' into main</code> commit that is created when merging    a pull request in favor of using the <code>PR</code> title as the commit message.</li> </ol>"},{"location":"contributing/merging_pr/#merging-a-pull-request","title":"Merging a Pull Request","text":"<p>To merge a pull request, follow these steps:</p>"},{"location":"contributing/merging_pr/#click-on-the-squash-and-merge-button","title":"Click on the \"Squash and merge\" button","text":""},{"location":"contributing/merging_pr/#modify-the-commit-message-as-needed","title":"Modify the commit message as needed","text":"<p>By default, the commit message will be the title of the pull request. The body of the commit message will include all the commits from the pull request.</p> <p></p> <p>As you can see, there may be some commits that are not relevant to the pull request.</p> <p>Feel free to modify the body of the commit message to include only the relevant commits.</p> <p>Note</p> <p>Only the PR Title needs to follow the Conventional Commits specification. The commit message body can be modified to include any relevant commits.</p> <p></p>"},{"location":"contributing/merging_pr/#verify-github-pages-deployment","title":"Verify GitHub Pages Deployment","text":"<p>After merging the pull request, the changes will be deployed to GitHub Pages. Check the website at <code>https://bhklab.github.io/handbook/</code> to verify that the changes are correct.</p> <p>Note</p> <p>To view the latest merged PR changes, ensure you are on the <code>dev</code> version of the site. The version dropdown selector is located next to the site title.</p>"},{"location":"contributing/merging_pr/#delete-the-branch","title":"Delete the branch","text":"<p>Once the pull request is merged, delete the branch.</p>"},{"location":"contributing/prerequisites/","title":"Prerequisites","text":""},{"location":"contributing/prerequisites/#installing-pixi","title":"Installing Pixi","text":"<p>Pixi is a tool for managing conda environments and dependencies. To install Pixi, visit the Pixi website and follow the instructions specific to your operating system. The Pixi documentation is an extensive resource for learning how to use Pixi.</p> <p>Running the following command in your terminal should verify installation.</p> <pre><code>$pixi --version\npixi 0.34.0\n</code></pre>"},{"location":"contributing/prerequisites/#cloning-the-repository","title":"Cloning the Repository","text":"<p>To begin, clone the repository to your local machine using the following command:</p> <pre><code>$ git clone https://github.com/bhklab/handbook.git\nCloning into 'handbook'...\n....\n....\n....\n...\n$ cd handbook\n</code></pre>"},{"location":"contributing/prerequisites/#installing-dependencies","title":"Installing Dependencies","text":"<p>Once you have cloned the repository, navigate to the project directory and install the dependencies:</p> <pre><code>$ pixi install\n\u2714 The default environment has been installed.\n</code></pre> <p>This will install the dependencies specified in the <code>pixi.toml</code> file.</p> <p>To add content to the handbook, see the Adding Content section.</p>"},{"location":"contributing/release_deployment/","title":"Release and Deployment","text":""},{"location":"contributing/release_deployment/#introduction","title":"Introduction","text":"<p>The handbook website is hosted on GitHub Pages. This document provides a detailed overview of how the deployment and release processes work, ensuring a smooth and automated workflow.</p>"},{"location":"contributing/release_deployment/#github-pages","title":"GitHub Pages","text":"<p>GitHub Pages is a service that allows you to host static websites directly from your GitHub repository.</p>"},{"location":"contributing/release_deployment/#how-it-works","title":"How It Works","text":"<p>Whenever changes are pushed to the <code>main</code> branch, a GitHub Action is triggered to automatically build and deploy the website.</p> <p>You can view the build and deployment action at this link.</p> <p>The automated workflow includes the following steps:</p> <ol> <li>Check Out the Repository: The GitHub Action checks out the latest code    from the <code>main</code> branch.</li> <li>Install Dependencies: Dependencies specified in the <code>pixi.toml</code> file    are installed.</li> <li>Build the Documentation: The action builds the site using MkDocs and    the configurations defined in your project.</li> <li>Deploy to GitHub Pages: The compiled site is deployed to the <code>gh-pages</code>    branch.</li> </ol> <p>Once the <code>gh-pages</code> branch is updated, GitHub Pages will automatically publish the latest version of the website.</p>"},{"location":"contributing/release_deployment/#releases-and-versioned-documentation","title":"Releases and Versioned Documentation","text":"<p>We leverage both <code>release-please</code> and <code>mike</code> to automate the release process and manage versioned documentation, making it easier to maintain version control, changelogs, and multiple documentation versions.</p>"},{"location":"contributing/release_deployment/#how-releases-work","title":"How Releases Work","text":"<p>When a pull request is merged into the <code>main</code> branch, a GitHub Action triggers the release process.</p> <p>You can view the release automation action at this link.</p> <p>Key aspects of this combined approach include:</p> <ul> <li>Automated Release Creation with <code>release-please</code>: The tool automatically    generates a release with changelogs and updates the version number based    on the changes merged into <code>main</code>.</li> <li>Dynamic Pull Request Updates: If additional changes are pushed to the   <code>main</code> branch after a pull request is created, the release PR will update to   include those changes, ensuring that the release captures all intended   updates.</li> <li>Controlled Release Process: Maintainers can merge changes into the   release PR only when they are ready to publish a new version, giving them   full control over the timing of each release.</li> <li>Versioned Documentation with <code>mike</code>: Once a new release is prepared,   <code>mike</code> is used to manage and deploy versioned documentation. This allows us   to provide a separate set of documentation for each release, maintaining   historical versions accessible on the website.</li> </ul> <p>This automated approach ensures consistency, reduces manual effort, and allows users to access documentation relevant to any specific version of the project.</p>"},{"location":"contributing/release_deployment/#manual-release-process","title":"Manual Release Process","text":"<p>If you need to release a new version of the documentation manually, you can follow these steps:</p> <ol> <li>Pull either the <code>main</code> branch or a specific release branch (e.g., <code>v0.1.0</code>) to your local machine.</li> </ol> Releasing a <code>main</code> branch as <code>dev</code>Release a specific version branch <pre><code>$ git pull origin main\nFrom https://github.com/bhklab/handbook\n* branch            main       -&gt; FETCH_HEAD\nAlready up to date.\n</code></pre> <pre><code>$ VERSION=v0.1.0\n$ git pull origin v$VERSION\nFrom https://github.com/bhklab/handbook\n* branch            v0.1.0     -&gt; FETCH_HEAD\nAlready up to date.\n</code></pre> <ol> <li>Use the <code>mike</code> command to deploy the documentation to the <code>gh-pages</code> branch.</li> </ol> Releasing a <code>main</code> branch as <code>dev</code>Release a specific version branch <pre><code>$ pixi run mike deploy --push dev devel\n</code></pre> <pre><code>$ pixi run mike deploy --push --update-aliases $VERSION latest\n</code></pre>"},{"location":"contributing/reviews/","title":"Reviewing a Contribution","text":"<p>Note</p> <p>This document provides an overview of the review process for contributions to the BHK Lab repositories. See the Code Review section for more information on code reviews.</p> <p>For more details, see the GitHub Docs on Pull Requests with Required Reviews.</p>"},{"location":"contributing/reviews/#introduction","title":"Introduction","text":"<p>Once a contribution is submitted, a Pull Request (PR) must be created. Before merging into the main branch, the PR must undergo a review process.</p>"},{"location":"contributing/reviews/#terminology","title":"Terminology","text":"<ul> <li>Author: The individual who submitted the contribution.</li> <li>Reviewer: The individual reviewing the contribution.</li> <li>Maintainer: The person responsible for merging the contribution after review.</li> </ul>"},{"location":"contributing/reviews/#understanding-a-review","title":"Understanding a Review","text":"<p>Reviews are discussions around the changes proposed in a PR. They allow for collaborative feedback, ensuring code quality and alignment with project standards.</p> <p>Tip</p> <p>Anyone can review a PR, including those who are not maintainers! If you see a PR from another author, and have suggestions for improvement, feel free to leave a review.</p> <p>For further reading, refer to the Official GitHub Documentation on PR Reviews.</p>"},{"location":"contributing/reviews/#review-statuses","title":"Review Statuses","text":"<p>When submitting a review, you can select from three statuses:</p> <ol> <li>Comment: Provide general feedback without explicitly approving or requesting changes.</li> <li>Approve: Indicate that the changes are acceptable, and approve merging the PR.</li> <li>Request Changes: Highlight issues that need to be addressed before the PR can be merged.</li> </ol>"},{"location":"contributing/reviews/#requesting-a-review-for-a-pull-request","title":"Requesting a Review for a Pull Request","text":"<p>After creating a PR, you can request specific individuals or teams to review it.</p> <ul> <li>Only members of the BHK Lab organization can request reviews from other members.</li> </ul> <p>For more information, check the Official GitHub Documentation on Requesting a Pull Request Review.</p>"},{"location":"contributing/reviews/#adding-to-an-existing-document","title":"Adding to an Existing Document","text":"<p>If a document already exists, you can add to it. Check the bottom of the page for information on current authors.</p>"},{"location":"contributing/reviews/#conclusion","title":"Conclusion","text":"<p>Effective reviews help ensure that contributions meet project standards, improve code quality, and facilitate knowledge sharing within the team. Whether you're an author, reviewer, or maintainer, understanding the review process is essential to contributing successfully.</p>"},{"location":"contributing/submitting_issues/","title":"Submitting Issues","text":""},{"location":"contributing/submitting_issues/#introduction","title":"Introduction","text":"<p>If you encounter any issues, have suggestions, or need clarifications about the documentation, you can submit an issue directly on our GitHub repository. We have a set of pre-defined issue templates to help categorize and address your concerns efficiently.</p> <p>Link: Submit and view issues</p>"},{"location":"contributing/submitting_issues/#available-issue-templates","title":"Available Issue Templates","text":"<p>When creating a new issue, you will be presented with the following options:</p> <p></p> <ol> <li> <p>Documentation Bug Report</p> <p>Use this template to report any errors or inconsistencies in the existing documentation. This could include typos, broken links, incorrect information, or anything that does not match the expected content.</p> </li> <li> <p>Content Update Request</p> <p>Choose this template if you need to request updates to existing content.  For example, if information is outdated or requires clarification,  use this template to suggest the necessary changes.</p> </li> <li> <p>Documentation Question</p> <p>Select this option to ask questions or seek clarification about specific  parts of the documentation. This is useful if you are unsure about how  certain sections apply to your work or if you need additional details  on a topic.</p> </li> <li> <p>Documentation Enhancement Request</p> <p>This template is for suggesting new content or improvements to existing  sections. If you think the documentation can be expanded or restructured  to better serve the users, please use this option.</p> </li> </ol>"},{"location":"contributing/submitting_issues/#how-to-submit-an-issue","title":"How to Submit an Issue","text":"<ol> <li>Go to the GitHub repository and navigate to the \"Issues\" tab.</li> <li>Click on the \"New Issue\" button.</li> <li>Select the appropriate issue template from the list.</li> <li>Fill out the template, providing as much detail as possible to help us    understand and address your issue.</li> <li>Submit the issue.</li> </ol> <p>For any issues that do not fit the existing templates, you can also select Open a blank issue to describe your concern freely.</p>"},{"location":"contributing/submitting_issues/#tips-for-submitting-effective-issues","title":"Tips for Submitting Effective Issues","text":"<ul> <li>Be Clear and Concise: Provide a detailed description but be direct.   Clear and specific information helps us address your issue faster.</li> <li>Include Links and Screenshots: If the issue relates to a specific   section, page, or example, include links and screenshots to provide context.</li> <li>Suggest Solutions: If you have an idea on how to fix or improve the   issue, let us know! Your suggestions can help expedite the process.</li> </ul>"},{"location":"disciplines/","title":"Disciplines","text":""},{"location":"disciplines/#data-science","title":"Data Science","text":"<p>Data Science focuses on extracting insights and knowledge from data using statistical, computational, and machine learning methods. This discipline enables informed decision-making in various fields, including research and industry.</p>"},{"location":"disciplines/#machine-learning","title":"Machine Learning","text":"<p>Machine Learning is a subfield of artificial intelligence to learn and improve from data without explicit programming. It is widely used in predictive modeling, pattern recognition, and automating complex processes.</p>"},{"location":"disciplines/#bioinformatics","title":"Bioinformatics","text":"<p>Bioinformatics is the application of computational methods to analyze, and interpret biological data. It plays a crucial role in genomics, proteomics, and other fields where large datasets are prevalent.</p>"},{"location":"disciplines/#pharmacogenomics","title":"Pharmacogenomics","text":"<p>Pharmacogenomics is the study of how genetic variations to tailor medications to individual genetic profiles. This approach enhances treatment efficacy and minimizes adverse effects.</p>"},{"location":"disciplines/#imaging","title":"Imaging","text":"<p>Imaging is the science of capturing and representing visual information for medical and scientific purposes. This discipline supports diagnostics, research, and data visualization through advanced imaging technologies.</p>"},{"location":"disciplines/Bioinformatics/","title":"Introduction","text":"<p>TODO:: Add a short description here</p>"},{"location":"disciplines/Bioinformatics/STAR/","title":"STAR Alignment Guide","text":""},{"location":"disciplines/Bioinformatics/STAR/#introduction","title":"Introduction","text":"<p>STAR (Spliced Transcripts Alignment to a Reference) is a high-performance RNA-seq read aligner, widely used for mapping RNA sequencing data to reference genomes. It is optimized for speed and accuracy, especially for aligning spliced reads across exon-exon junctions.</p> <p>This guide explains how to set up and use STAR for RNA-seq read alignment.</p>"},{"location":"disciplines/Bioinformatics/STAR/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"disciplines/Bioinformatics/STAR/#loading-star-on-the-h4h-cluster","title":"Loading STAR on the H4H Cluster","text":"<p>To use STAR on the H4H cluster, load the module:</p> <pre><code>module load STAR\n</code></pre>"},{"location":"disciplines/Bioinformatics/STAR/#verifying-installation","title":"Verifying Installation","text":"<p>After loading STAR, check the version to ensure compatibility with your pipeline:</p> <p><pre><code>STAR --version\n</code></pre> The output should display the version number, for example: <pre><code>STAR\\2.7.9a\n</code></pre></p>"},{"location":"disciplines/Bioinformatics/STAR/#preparing-for-star-alignment","title":"Preparing for STAR Alignment","text":"<p>Before using STAR, ensure you have the following files:</p>"},{"location":"disciplines/Bioinformatics/STAR/#reference-genome-fasta-file","title":"Reference Genome FASTA File","text":"<ul> <li>Contains the DNA sequences of your reference genome.</li> <li>Example for GRCh38:</li> <li>Here: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/   <code>GCF_000001405.40_GRCh38.p14_genomic.fna.gz</code></li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#gene-annotation-file-gtf","title":"Gene Annotation File (GTF)","text":"<ul> <li>Includes gene structure (exons, introns, splice junctions).</li> <li>Example for GRCh38:</li> <li>Here: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/   <code>GCF_000001405.40_GRCh38.p14_genomic.gtf.gz</code></li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#rna-seq-fastq-files","title":"RNA-seq FASTQ Files","text":"<ul> <li>Paired-end or single-end sequencing data.</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#index","title":"Index","text":""},{"location":"disciplines/Bioinformatics/STAR/#2-generating-a-genome-index","title":"2. Generating a Genome Index","text":"<p>STAR requires a genome index to efficiently align reads. Submit the following command in your SLURM script to generate it:</p> <pre><code>module load STAR/&lt;version_number&gt;\n# Replace &lt;version_number&gt; with the desired version, e.g., module load STAR/2.7.9a\n\nSTAR --runThreadN 8 \\\n     --runMode genomeGenerate \\\n     --genomeDir /path/to/genomeDir \\\n     --genomeFastaFiles genome.fa \\\n     --sjdbGTFfile annotations.gtf \\\n     --sjdbOverhang 100\n</code></pre>"},{"location":"disciplines/Bioinformatics/STAR/#explanation-of-parameters","title":"Explanation of Parameters","text":"<ul> <li><code>--runThreadN</code>: Number of threads (adjust to available cores for faster processing).</li> <li><code>--genomeDir</code>: Directory where the genome indices will be stored.</li> <li><code>--genomeFastaFiles</code>: Path to the reference genome FASTA file(s). For multiple FASTA files, list them separated by spaces.</li> <li><code>--sjdbGTFfile</code>: Path to the GTF annotation file for splice junction information.</li> <li><code>--sjdbOverhang</code>: Read length minus 1 (e.g., for 101 bp reads, use 100).</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#3-aligning-rna-seq-reads","title":"3. Aligning RNA-seq Reads","text":"<p>After generating the genome index, you can align RNA-seq reads using STAR.</p>"},{"location":"disciplines/Bioinformatics/STAR/#single-end-reads-example","title":"Single-End Reads Example:","text":"<pre><code>module load STAR/&lt;version_number&gt;\n# Replace &lt;version_number&gt; with the desired version, e.g., module load STAR/2.7.9a\n\nSTAR --runThreadN 8 \\\n     --genomeDir /path/to/genomeDir \\\n     --readFilesCommand gunzip \\\n     --readFilesIn sample_R1.fastq \\\n     --outFileNamePrefix sample \\\n     --quantMode GeneCounts \\\n     --outReadsUnmapped Fastx \\\n     --chimSegmentMin 10 \\\n     --outSAMtype BAM SortedByCoordinate\n</code></pre>"},{"location":"disciplines/Bioinformatics/STAR/#paired-end-reads-example","title":"Paired-End Reads Example:","text":"<pre><code># Replace &lt;version_number&gt; with the desired version, e.g., module load STAR/2.7.9a\n\nSTAR --runThreadN 8 \\\n     --genomeDir /path/to/genomeDir \\\n     --readFilesCommand gunzip \\\n     --readFilesIn sample_R1.fastq sample_R2.fastq \\\n     --outFileNamePrefix sample \\\n     --quantMode GeneCounts \\\n     --outReadsUnmapped Fastx \\\n     --chimSegmentMin 10 \\\n     --outSAMtype BAM SortedByCoordinate\n</code></pre>"},{"location":"disciplines/Bioinformatics/STAR/#explanation-of-parameters_1","title":"Explanation of Parameters","text":"<ul> <li> <p>----readFilesIn:  Input FASTQ files (single or paired-end).</p> </li> <li> <p>--outFileNamePrefix:  Prefix for output files.</p> </li> <li> <p>--outSAMtype:  Specifies output format (e.g., sorted BAM file).</p> </li> <li> <p>--runThreadN: Number of CPU threads to use. Adjust this based on the computational resources available on your cluster. Using more threads speeds up the process but requires more cores.</p> </li> <li> <p>--genomeDir: Path to the directory containing the pre-generated STAR genome index. This directory is created using the --runMode genomeGenerate command (see the section on generating the genome index).</p> </li> <li> <p>--readFilesCommand: Command used to preprocess the input FASTQ files. In this example, gunzip is specified, indicating that the input FASTQ files are compressed (.gz). For uncompressed files, this parameter is not needed.</p> </li> <li> <p>--readFilesIn: Specifies the input FASTQ file(s) for alignment. For single-end reads, provide one file; for paired-end reads, provide both files separated by a space (e.g., sample_R1.fastq sample_R2.fastq).</p> </li> <li> <p>--outFileNamePrefix: Specifies the prefix for all output files. STAR will append specific suffixes to this prefix to generate different output files (e.g., BAM files, logs).</p> </li> <li> <p>--quantMode: Enables quantification of reads at the gene level. Using GeneCounts generates a file (ReadsPerGene.out.tab) that provides read counts for each gene, useful for downstream expression analysis.</p> </li> <li>Output includes three columns for each gene:</li> <li>Uniquely mapped reads.</li> <li>Reads mapped to both strands.</li> <li> <p>Reads mapped to the opposite strand.</p> </li> <li> <p>--outSAMtype: Specifies the format of the output alignment file: </p> </li> <li>BAM Unsorted: Produces an unsorted BAM file.</li> <li> <p>BAM SortedByCoordinate: </p> <ul> <li>Produces a sorted BAM file based on genomic coordinates, which is typically required for downstream tools like featureCounts or visualization in genome browsers.</li> </ul> </li> <li> <p>--outReadsUnmapped: Specify whether to output unmapped reads. Options include Fastx to write unmapped reads in FASTQ format, which can be useful for troubleshooting or further analysis.</p> </li> <li> <p>chimSegmentMin: Minimum length of chimeric alignments (e.g., for detecting fusion transcripts). Defaults to 0, but setting a value like 10 can help identify chimeric reads.</p> </li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#star-output","title":"STAR Output","text":"<p>STAR generates several output files. Key files include:</p>"},{"location":"disciplines/Bioinformatics/STAR/#log-files","title":"Log Files","text":"<ul> <li><code>Log.out</code>: General log with alignment summary.</li> <li><code>Log.final.out</code>: Detailed alignment statistics.</li> <li><code>Log.progress.out</code>: Progress of the alignment process, including percentage completion.</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#alignment-files","title":"Alignment Files","text":"<ul> <li><code>Aligned.sortedByCoord.out.bam</code>: BAM file containing reads aligned to the reference genome, sorted by genomic coordinates.</li> <li><code>Aligned.out.bam</code>: BAM file containing reads aligned to the reference genome (unsorted).</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#gene-counts","title":"Gene Counts","text":"<ul> <li><code>ReadsPerGene.out.tab</code>: File containing gene-level read counts, with three columns for each gene:</li> <li>Uniquely mapped reads.</li> <li>Reads mapped to both strands.</li> <li>Reads mapped to the opposite strand.</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#unmapped-reads","title":"Unmapped Reads","text":"<ul> <li><code>Unmapped.out.mate1</code>: FASTQ file containing unmapped reads from the first mate (if specified).</li> <li><code>Unmapped.out.mate2</code>: FASTQ file containing unmapped reads from the second mate (if specified).</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#splice-junctions","title":"Splice Junctions","text":"<ul> <li><code>SJ.out.tab</code>: File listing detected splice junctions, including information about their genomic coordinates and supporting read counts.</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#chimeric-reads","title":"Chimeric Reads","text":"<ul> <li><code>Chimeric.out.sam</code>: SAM file containing chimeric (fusion) alignments, useful for identifying fusion transcripts.</li> </ul> <p>Several of these parameters are optional, for more details see: - https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf </p>"},{"location":"disciplines/Bioinformatics/STAR/#running-star-alignments-in-parallel-using-sbatch-array","title":"Running STAR Alignments in Parallel Using <code>sbatch --array</code>","text":"<p>When processing multiple RNA-seq samples, you can use SLURM's <code>--array</code> option to run jobs in parallel. This approach is efficient for handling batch alignment tasks.</p>"},{"location":"disciplines/Bioinformatics/STAR/#1-preparing-input-files","title":"1. Preparing Input Files","text":"<p>Create a text file listing all your sample FASTQ file pairs, with one sample per line. For paired-end data, include both files separated by a space, like this:</p> <p><code>samples.txt</code>: <pre><code>sample1_R1.fastq.gz sample1_R2.fastq.gz sample2_R1.fastq.gz sample2_R2.fastq.gz sample3_R1.fastq.gz sample3_R2.fastq.gz\n</code></pre></p>"},{"location":"disciplines/Bioinformatics/STAR/#2-writing-the-sbatch-script","title":"2. Writing the <code>sbatch</code> Script","text":"<p>Here's an example <code>sbatch</code> script to run STAR for each sample in the list using an array job:</p> <p><code>run_star.sh</code>: <pre><code>#!/bin/bash\n#SBATCH --job-name=STAR_array\n#SBATCH --array=0-2                 # Set the range of job indices (adjust based on the number of samples)\n#SBATCH --ntasks=1                  # Number of tasks per job\n#SBATCH --cpus-per-task=8           # Number of CPUs per task\n#SBATCH --mem=61440M                # Memory allocation per job\n#SBATCH --p himem                   # Partition\n#SBATCH -t 07:00:00                 # Max runtime \n#SBATCH --output=logs/star_%A_%a.log # Log file for each task\n\n# Load STAR module\nmodule load STAR\n\n# Read the samples file to get the corresponding FASTQ files for this array task\nSAMPLES_FILE=\"samples.txt\"\nLINE=$(sed -n \"${SLURM_ARRAY_TASK_ID}p\" $SAMPLES_FILE)\nFASTQ1=$(echo $LINE | cut -d ' ' -f 1)\nFASTQ2=$(echo $LINE | cut -d ' ' -f 2)\n\n# Specify the genome directory and output directory\nGENOME_DIR=\"/path/to/genomeDir\"\nOUTPUT_DIR=\"/path/to/output\"\n\n# Run STAR\nSTAR --runThreadN 8 \\\n     --genomeDir $GENOME_DIR \\\n     --readFilesCommand gunzip \\\n     --readFilesIn $FASTQ1 $FASTQ2 \\\n     --outFileNamePrefix $OUTPUT_DIR/sample_${SLURM_ARRAY_TASK_ID}_ \\\n     --outSAMtype BAM SortedByCoordinate\n</code></pre></p>"},{"location":"disciplines/Bioinformatics/STAR/#2-submitting-the-job","title":"2. Submitting the Job","text":"<p>Submit the job array with the following command:</p> <pre><code>sbatch run_star.sh\n</code></pre>"},{"location":"disciplines/Bioinformatics/STAR/#explanation-of-parameters_2","title":"Explanation of Parameters","text":"<ul> <li><code>--array=0-2</code>: Specifies the range of indices for the job array. Adjust based on the number of lines in <code>samples.txt</code>. For example, if you have 10 samples, use <code>--array=0-9</code>.</li> <li><code>SLURM_ARRAY_TASK_ID</code>: A unique identifier for each array task, corresponding to the line in <code>samples.txt</code>.</li> <li><code>sed -n \"${SLURM_ARRAY_TASK_ID}p\"</code>: Extracts the line from <code>samples.txt</code> corresponding to the current array task.</li> </ul>"},{"location":"disciplines/Bioinformatics/STAR/#4-logs-and-output","title":"4. Logs and Output","text":"<ul> <li>Logs: Logs for each task will be saved in the <code>logs/</code> directory with filenames like <code>star_JOBID_TASKID.log</code>.</li> <li>Output: Aligned BAM files and other outputs will be saved in the specified <code>OUTPUT_DIR</code>.</li> </ul>"},{"location":"disciplines/Bioinformatics/deseq/","title":"DESeq2","text":"<p>DESeq2 is a popular R package used for analyzing RNA count data - transcriptomics. It is widely used for differentially expressed analysis (DE) between different conditions (e.g. WT vs. mutant). The package also integrates many powerful data processing and analysis tools.</p>"},{"location":"disciplines/Bioinformatics/deseq/#features","title":"Features:","text":"<p>Normalization: DESeq2 normalizes the count data to account for differences in sequencing depth and RNA composition. Statistical Modeling: It uses a negative binomial distribution to model the count data, which is appropriate for overdispersed count data. Differential Expression Analysis: DESeq2 provides statistical tests to identify genes that are differentially expressed between conditions. Visualization: The package includes functions for visualizing results, such as MA plots and heatmaps.  </p>"},{"location":"disciplines/Bioinformatics/deseq/#example","title":"Example","text":"<p>One may follow the workflow template from below (data preprocessing and further analysis are needed, and they vary between different analyses): <pre><code># Create DESeqDataSet object\ndds &lt;- DESeqDataSetFromMatrix(countData = countData, ## your raw count\n                              colData = colData, ## your column metadata (i.e. sample/cell data)\n                              design = ~ condition) ## specifies the experimental design (e.g. conditions, treatments, etc.)\n\n# Run the DESeq2 pipeline\ndds &lt;- DESeq(dds)\nDEresults = results(dds)\nDEresults &lt;- DEresults[order(DEresults$padj),]\n\n# Extract results\nres &lt;- results(dds)\n\n## MA plot to check how well normalization works\nplotMA(dds)\n</code></pre> One can perform QC through PCA plot: <pre><code>rld &lt;- rlog(dds)\nDESeq2::plotPCA(rld, ntop = 500, intgroup = 'group') +\n  ylim(-50, 50) + theme_bw()\n</code></pre></p>"},{"location":"disciplines/Bioinformatics/deseq/#visually-de-result-with-volcano-plot","title":"Visually DE result with volcano plot","text":"<pre><code>dds &lt;- DESeq(dds)\nDEresults = results(dds)\nlibrary(EnhancedVolcano)\n# DEseq object is S4 object - we need to convert it to a data frame (S3)\nDEresults &lt;- as.data.frame(DEresults)\n\nEnhancedVolcano(DEresults,\n                lab = row.names(DEresults),\n                x = 'log2FoldChange',\n                y = 'padj',\n                pCutoff = 5e-2,\n                FCcutoff = 1,\n                labSize = 2.5,\n                legendLabels=c('Not sig.',expression(paste('Log'[2],'FC')),'padj', expression(paste('padj &amp; Log'[2],'FC'))),\n                ylab = \"padj\")\n</code></pre>"},{"location":"disciplines/Bioinformatics/Data_Types/rnaseq/","title":"RNA-seq","text":""},{"location":"disciplines/Bioinformatics/Data_Types/rnaseq/#what-is-rna-sequencing-rna-seq","title":"What is RNA Sequencing (RNA-seq)?","text":"<p>RNA sequencing (RNA-seq) is a high-throughput sequencing technology that allows scientists to map and quantify the transcriptome - essentially studying RNA molecules within cells. The transcriptome, or the RNA space, is comprised of messenger RNA (mRNA) and other non-coding RNAs (ncRNAs).</p> <p>Central Dogma of Molecular Biology: DNA \u2192 RNA \u2192 Protein </p> <p>While all RNAs are transcribed from RNA, only the mRNAs are further translated into protein, hence they are oftend referred to as the \"messengers\" that carries instructions from DNA to create proteins, or the functional units within the cells. ncRNAs have several roles relating to the regulation of gene expression and other cellular activities. By sequencing RNA, we get a snapshot of the transcriptome, including active genes, allowing us to understand how cells function and respond to different conditions.</p>"},{"location":"disciplines/Bioinformatics/Data_Types/rnaseq/#purpose-of-rna-seq-in-bioinformaticstranscriptomics","title":"Purpose of RNA-seq in Bioinformatics/Transcriptomics","text":"<p>Bioinformatics is the use of computational approaches to study biology, and transcriptomics focuses on studying RNA. Some purposes of RNA-seq in bioinformatic analysis include:</p> <p>1. Gene expression and activity</p> <p>Identifies the genes actively transcribed into mRNA in a given condition or cell type, giving an indication of which genes are \"switched on\". By quantifying the abundance of mRNA molecules, we can measure the activity levels of specific genes. RNA-Seq also allowed for examining post-transcriptional modifications such as alternative splicing, where RNA segments are rearranged or removed, influencing the diversity of proteins produced.</p> <p>2. ncRNA expression and activity</p> <p>Beyond mRNAs, several ncRNAs are of interest for cancer research. RNA-Seq also profiles the expression levels of these transcripts such that similar analyses can be performed as with mRNA.</p> <p>3. Differential RNA Expression</p> <p>Differential expression analysis can identify differences in RNA expression between different conditions (e.g. healthy vs diseased states, before and after treatment, etc). </p> <p>4. Biomarker Analysis</p> <p>RNA transcript expression can be associted with the response to different drugs, hence are often used as input features to identify biomarkers for cancer treatment.</p> <p>5. Subtype Identification</p> <p>Patterns of RNA transcript expression can be used to identify distinct clusters or subgroups within a given population. This approach is often used to identify cancer subtypes.</p> <p>6. Functional Enrichment</p> <p>Using databases such as Gene Ontology (GO), KEGG, Reactome, mSigDB, etc, sets of RNA transcripts (e.g. from differential expression analysis) can be linked to downstream effects on biological processes, signaling pathways, and overallc cellular function. </p>"},{"location":"disciplines/Bioinformatics/Data_Types/rnaseq/#how-is-rna-seq-data-obtained","title":"How is RNA-seq Data Obtained?","text":"<p>Here\u2019s a simplified process:</p> <ol> <li>RNA extraction: Scientists first isolate and collect RNA from cells or tissue samples.</li> <li>Synthesize cDNA: Due to the fragile nature of RNA, these transcripts are converted into complementary DNA (cDNA), which is more stable.</li> <li>Fragmentation: The cDNA is broken into smaller fragments that enable them to be sequenced.</li> <li>Sequencing of Fragments: Machines called sequencers read the fragments and identify the order of RNA nucleotides (A, U, G, C).</li> <li>Alignment: Sequenced fragments are aligned to a reference genome or transcriptome to get position-based mapping information, such as mapping mRNA transcripts to their respective genes.</li> <li>Quantification: With aligned fragments, transcript expression can be quantified.</li> </ol>"},{"location":"disciplines/Bioinformatics/Data_Types/rnaseq/#how-is-rna-seq-different-from-dna-sequencing","title":"How is RNA-seq Different from DNA Sequencing?","text":"Feature DNA Sequencing RNA Sequencing What is studied? DNA, the cell\u2019s blueprint. RNA, transcribed from DNA. Purpose Understand the structure of genes, mutations, and inheritance. Study gene and transcript activity Stable or Changing? DNA is mostly stable and the same in all cells. RNA levels vary depending on the cell\u2019s activity. Building Blocks A, T, G, C (Adenine, Thymine, Guanine, Cytosine). A, U, G, C (Uracil replaces Thymine in RNA). Output The sequence of an organism's entire genome (WGS) or specific parts (WES). A snapshot of all active RNA molecules."},{"location":"disciplines/Bioinformatics/Data_Types/rnaseq/#summary","title":"Summary","text":"<p>RNA-seq fits into the Central Dogma by focusing on RNA, the \"middle step\" between DNA and proteins. It provides a dynamic snapshot of gene and transcript activity, offering crucial insights into how cells work, respond to the environment, and contribute to diseases. By analyzing RNA, scientists can better understand the processes that sustain life and develop treatments for various conditions.</p>"},{"location":"disciplines/Data_Science/","title":"Introduction","text":"<p>TODO:: Add a short description here</p>"},{"location":"disciplines/Data_Science/Data_Curation/","title":"Data Curation","text":""},{"location":"disciplines/Data_Science/Data_Curation/#overview","title":"Overview","text":"<p>Data curation is the process of preparing data for analysis. It involves identifying, cleaning, and transforming data to ensure its quality and usability. Data curation is an essential step in the data analysis process, as it helps to ensure that the data is accurate, complete, and relevant for the analysis.</p> <p>DataRaven has established standard operating procedures (SOPs) for different data types.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/","title":"Clinical Trial Curation","text":""},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#immunotherapy-datasets","title":"Immunotherapy datasets","text":""},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#introduction","title":"Introduction","text":"<p>This documentation goes over the clinical trial data curation process in detail, using immunotherapy data.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#objective","title":"Objective","text":"<p>The objective is to curate a clinical dataset into R's MultiAssayExperiment object. An example of a clinical data MultiAssayExperiment (MAE) object can be found in ORCESTRA. </p> <p>Currently, a clinical data object contains the following data parts:</p> <ol> <li>Clinical metadata: Contains patient/sample metadata.</li> <li>Molecular profiles: Molecular assay data (Currently RNA-seq, SNV or CNA) which is formatted in either RangedSummarizedExperiment or regular SummarizedExperiment object.</li> </ol>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#data-access","title":"Data Access","text":""},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#public-data","title":"Public data","text":"<p>If the source is Pubmed, the raw omics files and clinical response metadata are available from Supplementary or external repository links in Data Availability section of the paper.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#private-data","title":"Private data","text":"<p>Private data such as PHI, clinical response might be available only upon request. Please contact the author(s) or whoever is responsible for requesting such data.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#data-processing-overview","title":"Data Processing Overview","text":"<p>An example of clinical data processing pipeline can be found here as a Snakemake pipeline. </p> <p>Generally, an overall process of the curation follows the steps outlined below:</p> <ol> <li>Download source data: Download data from publications or data repositories. The source data can be in various formats such as an Excel file, CSV or TXT. </li> <li>Process raw molecular data, if available: The RNA-seq processing from raw FASTQ is outlined on the RNAseq raw processing page.</li> <li>Add annotations: Ensure that genes, tissues and treatments are annotated with metadata available from external source and lab standardized columns.</li> <li>Create RangedSummarizedExperiment or SummarizedExperiment (SE) object: For the molecular data, we prefer RangedSummarizedExperiment as it is compatible with GenomicRanges R package.</li> <li>Create MAE object: Format downloaded data to the layout and structure that is favourable to creating a MAE object. Through this process, the source data is extracted from the source data format and formatted into a CSV or TSV file. Integrate molecular data to MAE. </li> </ol>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#processing-clinical-metadata","title":"Processing Clinical Metadata","text":"<p>The clinical data should be formatted into patient/sample ids as rows and attributes as column data. This will be added as <code>colData</code> of the SE or MAE object.</p> <p>The following columns are mandatory and should be filled with NA if the data is not available to maintain consistency across ICB and non-ICB datasets:</p> Column name Description Patientid This column contains unique patient identifiers treatmentid This column contains the treatment regimen of each patient. Individual drug names are separated by \":\" and standardized based on the lab's nomenclature. For example, the drug combo \"FAC\" is represented as \"5-fluorouracil:Doxorubicin:Cyclophosphamide\" response This column contains the response status of the patients to the given treatment - Responders (R) and Non-responders (NR) tissueid Cancer type standardized based on the lab's nomenclature from Oncotree. Example:  \u201cBreast\u201d survival_time_pfs/survival_time_os The time starting from taking the treatment to the occurrence of the event of interest. The event name like \"pfs\", \"os\" must be appended to survival_time to differentiate the survival measure. Example for data in this column: \u201c2.6\u201d survival_unit The unit in which the survival time is measured. If the event is measured in other units such as \u201cday\u201d, or \u201cyear\u201d, it must be converted to \"month\" for consistency event_occurred_pfs/event_occurred_os Binary measurement showing whether the event of interest occurred (1) or not (0).  The event name like \"pfs\", \"os\" must be appended to event_occurred to differentiate the survival measure <p>Note</p> <p>Common columns have to be the first set of columns appearing in the metadata followed by the rest of the columns. You could add other columns with the name in the source data, but the standard columns with the above mentioned names should be present.</p> <p>If you are adding new columns based on restructured data from existing columns, please assign the lucid, self-explanatory column names.</p> <p>The table below shows the other common columns across the 19 ICB datasets curated.</p> Column name Description type age Age source AMP Sum of total AMP/coverage; calculated from CNA values in-lab curation cancer_type Type of cancer tissue source CIN Calculated from CNA values in-lab curation CNA_tot Sum of total CNA/coverage; calculated from CNA values in-lab curation DEL Sum of total DEL/coverage; calculated from CNA values in-lab curation dna DNA sequencing type. eg: whole exome sequencing source histo Histological info such as subtype source indel_nsTMB_perMb - in-lab curation indel_nsTMB_raw - in-lab curation indel_TMB_perMb - in-lab curation indel_TMB_raw - in-lab curation nsTMB_perMb - in-lab curation nsTMB_raw - in-lab curation recist Annotated using RECIST. The most commonly used responses are CR,PR,SD, PD. source response.other.info Same data as Responders (R) and Non-responders (NR) source rna Type of rna processed data. eg: TPM source sex Sex of the patient - Male or Female source stage Cancer stage source survival_type PFS or OS or both (denoted by '/'). If both, added by in-lab curation in-lab curation TMB_perMb TMB per megabase (Mb) was performed as defined: TMB = mutns/target. With mutns = number of non-synonymous mutations; and target = target size of the sequencing See Supplementary Table S2 of https://pubmed.ncbi.nlm.nih.gov/36055464/ in-lab curation TMB_raw Tumor Mutation Burden raw values in-lab curation treatment Drug target or drug name source"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#processing-molecular-data","title":"Processing Molecular Data","text":"<p>The raw omics data files are obtained and processed in the lab. If the raw files are not available, processed data is used. Exceptions are Mutation data where only processed data is used to avoid ambiguity around matched normals.</p> <p>In general, all molecular data should be formatted into genes (eg: transcript IDs for RNA profiling) as rows and patient/sample IDs as columns. </p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#rna-seq-data","title":"RNA-seq data","text":"<p>First and foremost, the RNA-seq data should be at gene-level and in TPM. The TPM value should be log transformed with log2(TPM) + 0.001.</p> <p>If the TPM values are not available, but counts values are available, you could use the following formula to convert counts value to TPM:     <pre><code>GetTPM &lt;- function(counts, gene_size) {\n    x &lt;- counts/gene_size\n    return(t(t(x)*1e6/colSums(x)))\n}\n</code></pre></p> <p>If available, counts and transcript-level data (isoforms) should also be included.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#summarizedexperiment-object","title":"SummarizedExperiment Object","text":"<p>Each molecular data needs to be formatted into a SummarizedExperiment (or RangedSummarizedExperiment) object. </p> <p>At minimum, SummarizedExperiment requires:</p> <ol> <li>colData (the patient metadata) formatted in patient/sample IDs as rows and attribute data as columns.</li> <li>assay (expression values) formatted in gene/transcript IDs as rows and patient/sample IDs as columns.</li> <li>rowData (gene metadata) is gene metadata for the genes that exist in the assay, formatted as gene/transcript IDs as rows and attributes as columns. More details on the gene metadata below.</li> </ol>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#annotation","title":"Annotation","text":"<p>Lab standardized annotation data are stored in BHKLab-Pachyderm's Annotation repository.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#gene-annotations","title":"Gene Annotations","text":"<p>Gene metadata is obtained from Gencode annotations. We have a few versions of Gencode annotation data available in .RData files. An .RData file includes data frames that contains gene and transcript information such as features_gene, features_transcript and tx2gene. Some of the available gene annotations include:</p> <ul> <li>Gencode v19</li> <li>Gencode v40</li> </ul> <p>Note</p> <p>Please use the most recent version for your gene annotations from this repository. The version of Gencode must be decided after checking the reference genome. Follow Gene curation SOP for detailed steps</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#drug-annotations","title":"Drug Annotations","text":"<p>For clinical data, drug annotations are performed in case-by-case basis. For immunotherapy treatments, both instances such as anti-\"target\" (eg: anti-CTLA4) and monoclonal antibody brand names can be present. Please follow the Drug curation SOP to correctly annotate such cases using the standard lab files in the Annotation repository.</p>"},{"location":"disciplines/Data_Science/Data_Curation/Clinical_Trial_Curation/#tissue-annotations","title":"Tissue Annotations","text":"<p>For tissue annotations that cannot be mapped using Tissue curation SOP to the standard lab files in the Annotation repository, manual review needs to be performed in case-by-case basis.</p>"},{"location":"disciplines/Imaging/","title":"Medical Image Formats","text":""},{"location":"disciplines/Imaging/#introduction","title":"Introduction","text":"<p>A medical image is a digital representation of the internal structure or function of an anatomic region, typically presented as an array of picture elements called pixels (2D) or voxels (volume pixels, 3D). This representation is a discrete mapping of numerical values to positions in space.</p> <p></p> <p>Image of Abraham Lincoln as a matrix of pixel values. (Source)</p> <p></p> <p>Section of abdominal computed tomography (CT) scan with a matrix of Hounsfield units (HU). (Source: Caryn Geady)</p> <p>The numerical values, known as intensity values, vary based on:</p> <ul> <li>Image type: MRI, CT, PET, etc.</li> <li>Acquisition method</li> <li>Reconstruction and post-processing</li> </ul>"},{"location":"disciplines/Imaging/#medical-image-metadata","title":"Medical Image Metadata","text":"<p>Medical images often come with metadata, which provides additional information about the image. This metadata is usually stored at the beginning of the image file as a \"header.\"</p>"},{"location":"disciplines/Imaging/#common-metadata-fields","title":"Common Metadata Fields","text":"<ul> <li>Image dimensions: Width, height, depth</li> <li>Voxel size: Spacing between voxels</li> <li>Origin: Location of the first voxel</li> <li>Orientation: Direction of x, y, and z axes</li> <li>Pixel depth: Bytes used to represent each voxel intensity</li> <li>Data type: Integer, floating-point, etc.</li> </ul> DICOM <pre><code>(0018,0015) CS BodyPartExamined = LUNG\n(0018,0050) DS SliceThickness = 3\n(0020,0037) DS ImageOrientationPatient = 1\\0\\0\\0\\1\\0\n(0020,1002) IS ImagesInAcquisition = 99\n(0028,0010) US Rows = 512\n(0028,0011) US Columns = 512\n(0028,0030) DS PixelSpacing = 0.9766\\0.9766\n(0028,0100) US BitsAllocated = 16\n(0028,0101) US BitsStored = 16\n(0028,0102) US HighBit = 15\n(0028,0103) US PixelRepresentation = 0\n</code></pre>"},{"location":"disciplines/Imaging/#pixel-data","title":"Pixel Data","text":"<p>The pixel data in a medical image file represents the actual image values, stored in a format specific to the image file.</p> <ul> <li>In fixed-size header formats, pixel data follows the header directly.</li> <li>In other formats, a marker or tag indicates the start of pixel data.</li> </ul>"},{"location":"disciplines/Imaging/#pixel-data-size","title":"Pixel Data Size","text":"\\[ Pixel Data Size = \\text{Rows} \\times \\text{Columns} \\times \\text{Pixel Depth (Bytes)} \\times \\text{Number of Frames} \\]"},{"location":"disciplines/Imaging/#image-file-size","title":"Image File Size","text":"\\[ Image File Size = \\text{Header Size} + \\text{Pixel Data Size} \\] Example Calculation: <p>For a DICOM image with the following parameters:</p> Parameter Value Rows 512 Columns 512 Pixel Depth 2 bytes (16-bit image) Number of Frames 32 (32 slices) \\[ \\text{Pixel Data Size} = 512 \\times 512 \\times 2 \\times 32 = 16,777,216 \\text{ bytes (or 16 MB)} \\] <p>Assuming the header size for this DICOM file is 1,024 bytes:</p> \\[ \\text{Image File Size} = 1,024 \\text{ bytes} + 16,777,216 \\text{ bytes} = 16,778,240 \\text{ bytes (or 16.01 MB)} \\]"},{"location":"disciplines/Imaging/#medical-image-file-formats","title":"Medical Image File Formats","text":""},{"location":"disciplines/Imaging/#categories-of-medical-image-formats","title":"Categories of Medical Image Formats","text":"<ol> <li> <p>Standardization Formats: Standardize images from diagnostic modalities.</p> <ul> <li>Example: DICOM</li> </ul> </li> <li> <p>Post-Processing Formats: Facilitate and strengthen post-processing analysis.</p> <ul> <li>Examples: Analyze, NIfTI, MINC</li> </ul> </li> </ol>"},{"location":"disciplines/Imaging/#configurations-for-storing-medical-images","title":"Configurations for Storing Medical Images","text":"<ul> <li> <p>Single File: Contains both metadata and image data, with metadata stored   at the beginning.</p> <ul> <li>Examples: DICOM, MINC, NIfTI</li> </ul> </li> <li> <p>Two Files: Metadata and image data stored separately.</p> <ul> <li>Example: Analyze (.hdr and .img)</li> </ul> </li> </ul>"},{"location":"disciplines/Imaging/Data_Sources/","title":"Data Sources","text":"<p>List of data sources for imaging data. Retrieved from publications, websites, and other sources.</p>"},{"location":"disciplines/Imaging/Data_Sources/#source-list","title":"Source List","text":"Source Name Source URL Data Type Description The Cancer Imaging Archive (TCIA) https://www.cancerimagingarchive.net/ CR, CT, DX, Histopathology, MG, MR, NM, PET, REG, RTSTRUCT, SEG, SR, US, The Cancer Imaging Archive (TCIA) is a service which de-identifies and hosts a large archive of medical images of cancer accessible for public download. Grand Challenge https://grand-challenge.org/challenges/ CT, Dermoscopy, Endoscopy, Fundus Photograph, Histology, IR, MG, MR, OCT, PET, US, XR A platform for end-to-end development of machine learning solutions in biomedical imaging. RAD IMAGE NET https://www.radimagenet.com/ CT, MR, US, XR RadImageNet is a large database of annotated medical images from multiple modalities and of multiple pathologies. The data can be licensed for commercial use. EUCAIM https://dashboard.eucaim.cancerimage.eu/ CR, CT, DX, PET, MG, MR, NM, SEG, US Cancer Image Europe provides a robust, trustworthy platform for researchers, clinicians, and innovators to access diverse cancer images enabling the benchmarking, testing, and piloting of AI-driven technologies."},{"location":"disciplines/Imaging/Data_Sources/#legend","title":"Legend","text":"Acronym Name CR Computed Radiography CT Computed Tomography Dermoscopy Dermoscopy DX Digital Radiography Endoscopy Endoscopy Fundus Photograph Fundus Photograph Histology Histology IR Infrared MG Mammography MR Magnetic Resonance NM Nuclear Medicine OCT Optical Coherence Tomography PET Positron Emission Tomography REG Registration RTSTRUCT Radiotherapy Structure SEG Segmentation SR Structured Report US Ultrasound XR X-Ray"},{"location":"disciplines/Imaging/Data_Types/DICOM/","title":"DICOM (Digital Imaging and Communications in Medicine)","text":"<p>TODO: add introduction to DICOM</p> <p>TODO: Add references if using images from online </p> <p></p> <p></p>"},{"location":"disciplines/Imaging/Data_Types/DICOM/#dicom-header-resources","title":"DICOM Header Resources","text":"<ul> <li>DICOM Standard Browser - Find meaning of specific DICOM tags</li> <li>Understanding DICOM</li> <li></li> </ul>"},{"location":"disciplines/Imaging/Data_Types/nifti/","title":"NIfTi Format","text":""},{"location":"disciplines/Imaging/Data_Types/nifti/#introduction-to-nifti","title":"Introduction to NIfTI","text":"<p>The NIfTI (Neuroimaging Informatics Technology Initiative) format is a derivative of the ANALYZE format, which was originally developed for medical imaging.</p>"},{"location":"disciplines/Imaging/Data_Types/nifti/#why-nifti","title":"Why NIfTI?","text":"<p>Before NIfTI, medical imaging data was stored in a variety of formats,  including ANALYZE, MINC, and DICOM [1].</p> <ul> <li>ANALYZE<ul> <li>ANALYZE is a proprietary format developed by the Mayo Clinic.</li> <li>ANALYZE files are not widely supported and are often difficult to work with.</li> </ul> </li> <li>MINC<ul> <li>MINC (Medical Image NetCDF) is a newer format developed by the National  Institutes of Health (NIH).</li> <li>MINC files are widely supported and can be easily shared and distributed.</li> </ul> </li> <li>DICOM<ul> <li>DICOM (Digital Imaging and Communications in Medicine) is a standardized  format for medical imaging data.</li> <li>DICOM files are widely supported and can be easily shared and distributed.</li> </ul> </li> </ul>"},{"location":"disciplines/Imaging/Data_Types/nifti/#general-information","title":"General Information","text":"<ul> <li>NIfTI files will typically be stored in a single file, with the extension <code>.nii</code> or <code>.nii.gz</code>.</li> <li>NIfTI files are typically used for medical imaging data, such as MRI, CT, PET, and fMRI.</li> <li>NIfTI files are widely supported and can be easily shared and distributed.</li> </ul>"},{"location":"disciplines/Imaging/Data_Types/nifti/#diagrams","title":"Diagrams","text":"<p>NIfTI-1: https://nifti.nimh.nih.gov/nifti-1/documentation/hbm_nifti_2004.pdf</p> <p>NIfTI structure diagram: https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1diagrams_v2.pdf</p>"},{"location":"disciplines/Imaging/Data_Types/nifti/#references-and-resources","title":"References and Resources","text":"<ol> <li>Medical Image File Formats, Michele Larobina, 2014. https://doi.org/10.1007/s10278-013-9657-9</li> <li>The NIFTI file format</li> <li>NIfTI-2</li> <li>NiBabel - NIfTI images</li> <li>NiBabel - Coordinate Systems</li> <li>NIFTI plain and simple</li> <li>NIfTI NIH site</li> </ol>"},{"location":"disciplines/Imaging/Radiomics/","title":"Radiomics","text":"<p>Radiomics is the study of the interaction between radiation and support diagnosis, prognosis, and treatment planning. It bridges radiology and data science, allowing for a more detailed understanding of disease characteristics.</p>"},{"location":"disciplines/Imaging/Tools/","title":"Image Processing Tools","text":""},{"location":"disciplines/Imaging/Tools/#med-imagetools","title":"Med-ImageTools","text":"<p>Med-Imagetools is a free, open-source image processing tool for medical images developed by the BHK Lab.</p> <ul> <li>Publication: Med-ImageTools: An open-source Python package for robust data processing pipelines and curating medical imaging data</li> <li> Source code</li> <li> Documentation</li> </ul>"},{"location":"disciplines/Imaging/Tools/#3d-slicer","title":"3D Slicer","text":"<ul> <li>Slicer is an open-source platform with many built-in (and optional) plug-ins for image viewing and processing</li> <li>To install, visit: https://download.slicer.org/</li> <li>[Slicer.org](https://www.slicer.org/) is the site for 3D Slicer, offering downloads, training, and documentation.</li> </ul>"},{"location":"disciplines/Imaging/Tools/QIPCM/","title":"QIPCM","text":"<p>The Quantiative Imaging for Personalized Cancer Medicine (QIPCM) program provides end-to-end testing and analysis support for clinical trials to improve consistency and reliability in clinical trial data.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/","title":"Querying Data from the QIPCM PACS","text":"<p>Once you've been added to a project's delegation log, the team at QIPCM will grant you access to the data. At this time of this writing, QIPCM cannot directly upload the data to H4H for us, so you will need to use the tools below to query the data and then upload it to HPC4Health.</p> <p>There are three tools you will need to access the data:</p> <ol> <li>The QIPCM Toolbox (requires UHN Login)</li> <li>MongoDB Compass</li> <li>Horos</li> </ol> <p>Warning</p> <p>You need to be connected to either UHN-wireless-corporate wifi OR the UHN VPN to access the QIPCM Toolbox for this entire process as the setup requires your IP address to be consistent. If you expect to be working from multiple locations, you will need to set up different Horos listeners for each location with your QIPCM team member.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#setting-up-the-tools","title":"Setting up the Tools","text":"<p>The first time you access this database, you will need to work with a member of the QIPCM team to configure the tools.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#mongodb-compass","title":"MongoDB Compass","text":"<p>MongoDB Compass is used to query the QIPCM PACS database to extract metadata for the images you want to download. A QIPCM team member will provide you with details on how to connect to the database.</p> <p>After you have downloaded, installed, and launched MongoDB Compass, under the Connections tab, click the + symbol.</p> <p></p> <p>In the URL field, enter the connection string sent to you by the QIPCM team with the password. Set the name of the connection to QIPCM and click \"Save &amp; Connect\".</p> <p>You should now see your QIPCM database under Connections on the left side:</p> <p></p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#horos","title":"Horos","text":"<p>Horos is a DICOM viewer where the data from QIPCM will be sent to on your local machine.</p> <p>After you have downloaded, installed, and launched Horos, you will need to configure it to connect to QIPCM's database. Navigate to the Preferences menu (on a Mac, this is found in the Horos menu bar, then Settings...). You need to setup Locations and Listener(#horos-listener-menu) configurations.</p> <p></p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#horos-locations-menu","title":"The Locations Menu","text":"<p>Click the \"Add new node\" button to create a node for QIPCM data.</p> <p></p> <p>Set the following values for the new node:</p> <ul> <li>Address: qipcm-pacs.uhn.ca</li> <li>AETitle: QIPCM_OCTANE</li> <li>Port: 11112</li> <li>Q&amp;R: Check box / Yes</li> <li>Retrieve: C-MOVE</li> <li>Send: Uncheck box / No</li> <li>TLS: Uncheck box / No</li> <li>Name: QIPCM {Project or Dataset Name}</li> </ul> <p>Make sure you have checked the lefthand box so the location is active.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#horos-listener-menu","title":"The Listener Menu","text":"<p>From Listener menu, copy the values for:</p> <ul> <li>AETitle</li> <li>Port Number</li> <li>Address</li> <li>Host Name</li> </ul> <p>and send these to the QIPCM team member setting up your access. You will also need the AETitle when you download the images from the QIPCM PACS.</p> <p>Note</p> <p>Ensure the \"Activate DICOM listener when Horos is running\" box is checked.</p> <p>You can now close the Preferences window, but need to leave Horos open and running for the remainder of this process.</p> <p>Note</p> <p>Horos needs to be open for the duration of the data transfer from the QIPCM PACS to your local machine.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#querying-the-image-metadata","title":"Querying the Image Metadata","text":"<p>This next step will get the metadata from MongoDB Compass to identify which images you want to download from QIPCM.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#connecting-to-the-qipcm-database","title":"Connecting to the QIPCM Database","text":"<p>Open MongoDB Compass. Hover over the QIPCM connection on the left side of the window and click on the \"CONNECT\" button to access to your project's database. Navigate to scrapeDb on left hand side panel and select the collection you want to query.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#query-the-metadata","title":"Query the metadata","text":"<p>Now that you're connected, you can query the available image metadata to determine which specific images you want to download.</p> <p>On the right side of the window, next to the page navigation arrow, there is a hamburger menu, curly braces, and a table icon. Click the table icon to view the data in a table. At this point, you can query a subset of the data (e.g. by modality, patient ID, etc.) or you may export the entire collection.</p> <p>Once you have the data you want, click the EXPORT DATA button just above the table. Either export the query results or the full collection.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#exporting-the-metadata","title":"Exporting the metadata","text":"<p>This step will produce the CSV file you need to search the QIPCM database in the Toolbox.</p> <p>In the popup Export menu, under Fields to export, choose \"Select fields in table\". Then click \"Next\".</p> <p>In the next window, select the following fields:</p> <ul> <li>PatientID</li> <li>Modality</li> <li>SeriesInstanceUid</li> <li>StudyInstanceUid</li> </ul> <p>then click \"Next\".</p> <p>Select CSV as the Export File Type, then click \"Export\". Select where in your local file system you want to save the file and click \"Save\".</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#downloading-the-images","title":"Downloading the Images","text":"<p>Now that you have the desired image metadata, you can download the images from the QIPCM PACS using the QIPCM Toolbox. Make sure that Horos is still open and running!</p> <p>Navigate to The QIPCM Dashboard and login with your UHN credentials.</p> <p>On the main page, select the Portal option from the top menu to get to the Image Search page.</p> <p></p> <p>Select the following options:</p> <ul> <li>\"Select a PACS\", set it to QIPCM-PACS.</li> <li>\"Select a Trial\", set it to whichever study you want to download.</li> <li>\"Select a Reason\", set it to Trial Close Out.</li> </ul> <p>In the next section, click the Query with a CSV File tab. Click Load CSV and select the file you exported from MongoDB Compass.</p> <p>Click on the red \"Search PACS\" button and wait for the results to load.</p> <p>Once the results have loaded, select those you wish to download. You can filter by any of the headings in the table and use the Select All button at the bottom of the table.</p> <p>Under \"Select destination Trial\", find your AETitle from the Horos listener setup. Click the red \"Add to queue\" button and the download to Horos should begin.</p> <p>Warning</p> <p>If your download does not appear to be working, check the following:</p> <ol> <li>Make sure Horos is still open and running.</li> <li>Make sure you have the correct AETitle from the Horos listener setup in the \"Select destination Trial\" field.</li> <li> <p>Confirm that your IP address matches the Address field in the Horos listener setup. </p> Linux &amp; macOSWindows <p>In a terminal, run: <pre><code>ipconfig getifaddr en0\n</code></pre></p> <p>Open Command Prompt and run: <pre><code>ipconfig/all \n</code></pre></p> </li> </ol> <p>If all of these are correct, reach out to your QIPCM team member for further help.</p>"},{"location":"disciplines/Imaging/Tools/QIPCM/querying_data/#exporting-the-images","title":"Exporting the Images","text":"<p>To export from Horos, select the patient(s) you wish to export, and click the Export button at the top of the window.</p> <p>Select the directory you want to save the images to and click the \"Choose\" button.</p> <p>Your images should now be in the directory you selected, organized by patient.</p>"},{"location":"disciplines/Machine_Learning/","title":"What is Machine Learning?","text":"<p>Machine Learning (ML) is an approach of using computers to find patterns in data and make predictions or decisions without being explicitly programmed for specific tasks. It uses algorithms to analyze and learn from data to improve performance over time.</p>"},{"location":"disciplines/Machine_Learning/#why-do-we-use-machine-learning","title":"Why Do We Use Machine Learning?","text":"<p>Machine Learning is used because traditional programming methods, which rely on explicitly defining rules for every scenario, are often inefficient or impossible for complex problems. For example, recognizing faces, predicting stock prices, or diagnosing diseases involves patterns too intricate for manual rule-based systems.</p> <p>Before ML, we relied on statistical methods, manual rule-based algorithms, or human judgment, which had limited scalability and adaptability.</p>"},{"location":"disciplines/Machine_Learning/#advantages-of-machine-learning","title":"Advantages of Machine Learning","text":"<ul> <li>Scalability: ML handles large and complex datasets better than manual methods.</li> <li>Adaptability: Models improve automatically as they process more data.</li> <li>Automation: ML can automate repetitive tasks, saving time and resources.</li> </ul>"},{"location":"disciplines/Machine_Learning/#limitations-of-machine-learning","title":"Limitations of Machine Learning","text":"<ul> <li>Data Dependency: Requires large amounts of quality data to perform well.</li> <li>Black Box Models: Some ML models lack interpretability, making them hard to trust.</li> <li>Bias and Errors: ML can amplify biases present in the data.</li> <li>High Costs: Requires computational resources and expertise.</li> </ul>"},{"location":"disciplines/Machine_Learning/#where-does-machine-learning-fit-in-science","title":"Where Does Machine Learning Fit in Science?","text":"<p>Machine Learning is an interdisciplinary field at the intersection of:</p> <ul> <li>Computer Science: Provides algorithms and computational power.</li> <li>Statistics: Forms the mathematical foundation for analyzing and interpreting data.</li> <li>Artificial Intelligence (AI): ML is a subset of AI focused on learning from data.</li> <li>Deep Learning (DL): A specialized branch of ML that uses neural networks to process large amounts of data.</li> </ul> <p>ML integrates concepts from these fields to solve diverse problems in areas like biology, finance, healthcare, and engineering.</p>"},{"location":"disciplines/Machine_Learning/#when-should-we-use-machine-learning","title":"When Should We Use Machine Learning?","text":""},{"location":"disciplines/Machine_Learning/#appropriate-use-cases","title":"Appropriate Use Cases","text":"<ul> <li>When there's a need to analyze large datasets for complex patterns.</li> <li>When the problem requires automation or decision-making without explicit programming.</li> </ul>"},{"location":"disciplines/Machine_Learning/#when-we-should-avoid-machine-learning","title":"When We Should Avoid Machine Learning","text":"<ul> <li>When data is insufficient or of poor quality.</li> <li>When simpler, rule-based systems can solve the problem more effectively.</li> <li>When interpretability is critical, and black-box methods aren't acceptable.</li> </ul>"},{"location":"disciplines/Machine_Learning/#categories-and-branches-of-machine-learning","title":"Categories and Branches of Machine Learning","text":"<p>ML is broadly divided into three main categories:</p> <ol> <li> <p>Supervised Learning:</p> <ul> <li>Models are trained on labeled data (input-output pairs).</li> <li>Examples: Linear regression, support vector machines (SVMs).</li> </ul> </li> <li> <p>Unsupervised Learning:</p> <ul> <li>Models learn patterns from unlabeled data.</li> <li>Examples: Clustering (e.g., k-means), dimensionality reduction (e.g., PCA).</li> </ul> </li> <li> <p>Reinforcement Learning:</p> <ul> <li>Models learn by interacting with an environment and receiving rewards or penalties.</li> <li>Examples: Markov decision process (MDP), Deep Q Networks (DQN).</li> </ul> </li> </ol>"},{"location":"disciplines/Pharmacogenomics/","title":"Introduction","text":"<p>TODO:: Add a short description here</p>"},{"location":"grants/","title":"Grant Submission Handbook: Tools, Guides &amp; References","text":"<p>This handbook is a guide to navigating the grant submission process efficiently. It includes a curated list of grants to consider, step-by-step instructions on how to apply, pre-submission checklists, and reusable templates to streamline the process.</p> <p>Please note that each grant agency is unique in certain areas. We suggest verifying the information directly from grant websites.</p> <p>Point of contact for BHK Lab grant applications - Sisira Kadambat Nair @ sisira.nair@uhn.ca</p>"},{"location":"grants/Identifying_Suitable_Grants/","title":"Identifying Suitable Grants","text":""},{"location":"grants/Identifying_Suitable_Grants/#grant-databases-websites","title":"Grant Databases &amp; WebsitesCanadian funding opportunities","text":""},{"location":"grants/Identifying_Suitable_Grants/#canadian-institutes-of-health-research-cihr","title":"Canadian Institutes of Health Research (CIHR)","text":"<p>CIHR has several funding programs.  Read more </p> <ul> <li>New Frontiers in Research Fund</li> <li>Training award programs</li> <li>Project Grant Program</li> <li>Foundation Grant Program</li> <li>Initiatives</li> <li>Prizes</li> </ul> <p>Note: Check with your PI if you are unsure of which program to apply for. If you have access to UHN email, you can also track emails from research-community-news-bounces@uhnresearch.ca.</p> <p>Applying for funding - List of current funding opportunities</p> <p>Note</p> <p>Benjamin will have an account on ResearchNet. Your PI can add you as delegate on the application. Final submission can be done only by the NPI. Please reach out directly to Benjamin or contact Sisira at sisira.nair@uhn.ca for questions regarding submission portal for the lab.</p>"},{"location":"grants/Identifying_Suitable_Grants/#genome-canada-gapp","title":"Genome Canada (GAPP)","text":"<p>Funding guidelines and policies</p> <p>Funding opportunities</p>"},{"location":"grants/Identifying_Suitable_Grants/#terry-fox-research-institute-tfri","title":"Terry Fox Research Institute (TFRI)","text":"<p>Programs for Funding Research</p>"},{"location":"grants/Identifying_Suitable_Grants/#cancer-research-society-crs","title":"Cancer Research Society (CRS)","text":"<p>Funding Programs</p>"},{"location":"grants/Identifying_Suitable_Grants/#natural-sciences-and-engineering-research-council-of-canada-nserc","title":"Natural Sciences and Engineering Research Council of Canada (NSERC)","text":"<p>NSERC has several programs for both Professors and Students/Fellows. Please check sub-sections within the below links.</p> <p>Discover grants Innovate grants</p>"},{"location":"grants/Identifying_Suitable_Grants/#canadian-cancer-society-ccs","title":"Canadian Cancer Society (CCS)","text":"<p>Open funding opportunities for Researchers</p> <p>Application portal</p> <p>Note</p> <p>Benjamin will have an account on EGrAMS. Please reach out directly or contact Sisira at sisira.nair@uhn.ca for questions regarding submission portal for the lab.</p>"},{"location":"grants/Identifying_Suitable_Grants/#university-of-toronto-data-sciences-institute-dsi","title":"University of Toronto Data Sciences Institute (DSI)","text":"<p>Funding Opportunities</p> <p>Programs include, not limited to: Catalyst Grant program, competitive seed funding program Data Access Grant Research Software Development Support Program</p>"},{"location":"grants/Identifying_Suitable_Grants/#digital-research-alliance-of-canada-dra","title":"Digital Research Alliance of Canada (DRA)","text":"<p>Funding Opportunities</p>"},{"location":"grants/Identifying_Suitable_Grants/#ontario-institute-for-cancer-research-oicr","title":"Ontario Institute for Cancer Research (OICR)","text":"<p>Funding Opportunities</p>"},{"location":"grants/Identifying_Suitable_Grants/#princess-margaret-cancer-centre-pmpmcc","title":"Princess Margaret Cancer Centre (PM/PMCC)","text":"<p>PM offers a variety of seed funding to support researchers. Please check UHN emails for funding announcement.</p>"},{"location":"grants/Identifying_Suitable_Grants/#the-temerty-centre-for-artificial-intelligence-research-and-education-in-medicine-t-cairem-at-the-university-of-toronto","title":"The Temerty Centre for Artificial Intelligence Research and Education in Medicine (T-CAIREM) at the University of Toronto","text":"<p>Past TCAIREM grants include T-CAIREM/DSI Catalyst Grants, T-CAIREM Health Data Nexus Dataset Grants, AI for Population Health and Health Systems Implementation Grant, Vector Institute-Temerty Clinical AI Integration Grant etc.</p> <p>Grant Opportunities</p>"},{"location":"grants/Identifying_Suitable_Grants/#canadian-institute-for-advanced-research-cifar","title":"Canadian Institute for Advanced Research (CIFAR)","text":"<p>Current research programs</p> Corporate funding opportunities"},{"location":"grants/Identifying_Suitable_Grants/#roche","title":"Roche","text":"<p>Roche Canada Funding Request Tool</p> International funding opportunities"},{"location":"grants/Identifying_Suitable_Grants/#us-department-of-defense-dod","title":"U.S. DEPARTMENT OF DEFENSE (DOD)","text":"<p>This is an extensive process. Please request the help of Research Grants months ahead for advice and document requirements.</p> <p>Grant Programs</p>"},{"location":"grants/Identifying_Suitable_Grants/#the-dataworks-prize-faseb-nih","title":"The DataWorks! Prize (FASEB &amp; NIH)","text":"<p>Federation of American Societies for Experimental Biology (FASEB) and the National Institutes of Health (NIH) hosts an annual challenge that showcases the benefits of research data management while recognizing and rewarding teams whose research demonstrates the power of data sharing or reuse practices. Webpage only</p>"},{"location":"grants/Identifying_Suitable_Grants/#eu-funding","title":"EU funding","text":"<p>European Commission: Horizon Europe has Pillar I and II funding programs. </p> <ul> <li> <p>Pillar I - Investigator-driven initiatives in all research areas that give the scientific community a strong role in determining the avenues of research to be pursued:</p> </li> <li> <p>Pillar II - Collaborative research and innovation projects responding to thematically specific calls for proposals within the following six clusters that address key societal challenges.</p> </li> </ul> <p>Read more</p> <p>Check here for active funding calls using filter view</p> Cloud credits opportunities"},{"location":"grants/Identifying_Suitable_Grants/#google-cloud-platform-gcp","title":"Google Cloud Platform (GCP)","text":"<p>Apply for Google Cloud research credits</p>"},{"location":"grants/Identifying_Suitable_Grants/#amazon-web-services-aws","title":"Amazon Web Services (AWS)","text":"<p>AWS Cloud Credit for Research</p> <p>You can also check Azure Research credits</p>"},{"location":"grants/Submission_Process/","title":"Submission Process","text":"<p>Each funding agency has different submission portals and requirements. </p> <p>Ensure you:</p> <ul> <li> <p>Create an account on the required submission portal (e.g., ResearchNet, EGrAMS)</p> </li> <li> <p>Format the application according to guidelines (PDF, Word, online forms)</p> </li> <li> <p>IMPORTANT -Check for word limits, font, and spacing requirements</p> </li> <li> <p>Validate the submission using any built-in tools provided by the portal</p> </li> <li> <p>Ensure all attachments are correctly labeled and uploaded in the correct sections</p> </li> <li> <p>Confirm that all required fields are completed and sections marked as \"complete\"</p> </li> <li> <p>Print or save a copy of the submission confirmation/receipt for your records. Add it to the bhklab manage drive folder</p> </li> <li> <p>If the system allows, generate and download a compiled copy of the full application as submitted</p> </li> </ul>"},{"location":"grants/Templates_%26_Resources/","title":"Templates &amp; Resources","text":"<ol> <li> <p>UHN Sharepoint for  finding Research Grants - Dashboard</p> </li> <li> <p>Submit here for grant budget review  by UHN Research Grants team BusinessHub</p> </li> <li> <p>Use this for creating figures - BHK lab Miro</p> </li> <li> <p>General Gantt chart, created on Feb 2025 CIHR template</p> </li> <li> <p>Budget calculations made easy, created on Feb 2025 CIHR template</p> </li> <li> <p>Research Data management template RDM</p> </li> </ol>"},{"location":"grants/Writing_a_Strong_Grant_Proposal/","title":"Writing a Strong Grant Proposal","text":"<p>This is intended as a guide to the general sections of a full grant proposal. Please refer to the funding guidelines for specific requirements.</p> <p>Pro Tip</p> <p>Export your proposal to Microsoft Word to check the spelling and grammar errors, you can choose to display information about the reading level of the document. This will include readability scores according to the Flesch-Kincaid Grade Level test and Flesch Reading Ease test. </p> <p>Understand readability scores</p>"},{"location":"grants/Writing_a_Strong_Grant_Proposal/#scientific-part-of-the-proposal","title":"Scientific part of the proposal","text":"<p>Lay title and Summary/Abstract</p> <p>Write a concise, jargon-free summary that clearly explains the project's purpose, significance, and expected impact. This is often the first (and sometimes only) section reviewers read, so clarity and accessibility are key. Very relevant for non-scientific stakeholders such as patient, patient partners etc.</p> <p></p> <p>Background/Problem Statement</p> <p>Present the context and significance of the research. What gap does it address? Why is it important now? Support with current literature and statistics to make a compelling case.</p> <p>Pro Tip</p> <p>Articulate better by dividing into sub-sections with titles instead on one big section</p> <p>Preliminary work</p> <p>Demonstrate that the project builds on solid groundwork. Include a table of data, previous publications, or plots from proof-of-concept studies to show feasibility and credibility. These should be indexed in the text as well. </p> <p>Pro Tip</p> <p>Include an Overiew of the research idea, highlight preliminary sections vs. Aims</p> <p>Hypothesis</p> <p>State the central hypothesis or research question. It should be specific, testable, and grounded in the background presented. A well-defined hypothesis guides the aims and methodology.</p> <p>Specific Aims</p> <p>Clearly defined research objectives or aims. Brief summary of the hypothesis or core research question. What the project seeks to accomplish and why it's significant.</p> <p>Methodology</p> <p>Detailed description of the research design, methods, and techniques to be used. Justification for chosen approaches. </p> <p>Feasibility, Risk &amp; Mitigation Strategies</p> <p>Outline potential risks or challenges (technical, ethical, logistical) and explain how they will be mitigated. Highlight available expertise, access to necessary infrastructure, and alternative approaches. For example, mention statistical model limitations, data privacy, clinical data acquisition challenges etc.</p> <p>Project Outcomes and future directions</p> <p>Describe the expected scientific outcomes and broader impact. Indicate how the findings will be disseminated and how they may inform future research or policy. Include any plans for scaling, follow-up studies, or knowledge translation. Include Gantt chart for Timeline and milestones.</p> <p>Pro Tip</p> <p>For Gantt chart, you can enhance visualization by coding dark colors to initial deliverables and light colours for improvements or updates following early studies.</p> <p>Research Data Management &amp; Open Science</p> <p>Detail how data will be collected, stored, shared, and preserved. Include plans for open access publication, data repositories, and compliance with FAIR data principles (Findable, Accessible, Interoperable, Reusable).</p> <p>Note</p> <p>If your proposal includes private data access, include secure storage plans via H4H or GCP. Mention the size of data if known. Adhere to the regulations included in the Personal Information Protection and Electronic Documents Act (PIPEDA), Health Insurance Portability and Accountability Act (HIPAA) and the General Data Protection Regulation (GDPR) for Canada, USA, and Europe, respectively. Also refer to First Nations principles of Ownership, Control, Access, and Possession (OCAP) in Canada and mention if applicable.</p> <p>Expertise, Experience &amp; Resources</p> <p>Most grants include multiple labs. Highlight the strengths of each teams. Include relevant expertise, past accomplishments, and institutional support (labs, equipment, collaborations) that ensure project success.</p>"},{"location":"grants/Writing_a_Strong_Grant_Proposal/#other-sections","title":"Other sections","text":"<p>Sex and/or Gender considerations (SGBA)</p> <p>Discuss how sex and/or gender will be considered in the design, data collection, analysis, and interpretation of results. If SGBA is not applicable, provide a rationale for its exclusion</p> <p>Summary of Progress</p> <p>Often refers to NPI's research progress so far. Please reach out to your NPI as they might have a draft already.</p> <p>Budget</p> <p>Please check grant agency specific requriements for budget. Breakdown the costs, cross the t's dot the i's</p> <ul> <li> <p>Personnel: Salaries, benefits, and stipends for staff and researchers</p> </li> <li> <p>Consumables: Supplies and materials needed for experiments. </p> </li> <li> <p>Non-Consumables: Equipment purchases or rentals</p> </li> <li> <p>Knowledge Translation: Costs for dissemination activities, open access publishing, stakeholder engagement</p> </li> </ul> <p>Peer review information</p> <p>To be discussed with NPI. The lab has a list of PI names and credentials required for this section.</p> <p>Suggested Peer Review Committees: List preferred committees or panels for reviewing your application</p> <p>Reviewers to Exclude for this Application: List any individuals or groups that should not be involved in the review process, with justifications if required</p>"},{"location":"grants/Preparing_for_Submission/","title":"Preparing for Submission","text":"<p>While there are common sections, each grant agency has specific requirements. Before submitting a grant application, ensure you have all necessary documents and have addressed key requirements.</p> <p>Use this guide to navigate each stage of the grant application process, from initial registration to final submission. </p>"},{"location":"grants/Preparing_for_Submission/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Create a folder under BHKLab Manage Google drive. General access is restricted to Benjamin, Soleil and Sisira, hence reach out to Sisira to create folders.</p> </li> <li> <p>Sub folders SHOULD be arranged in the following hierarchy.</p> <pre><code>    Parent folder --&gt; Application, Submitted, Reports\n</code></pre> </li> <li> <p>It is recommended to schedule a meeting with all PIs and lab members involved to outline the proposal.</p> </li> <li> <p>Login to submission portal to check sections and create a google doc to use as a working proposal .</p> </li> </ol>"},{"location":"grants/Preparing_for_Submission/#step-1-registration","title":"Step 1: Registration","text":"<ul> <li> <p>Register on the funding agency's submission portal listed in Identifying_Suitable_Grants.md </p> <ul> <li>In most cases, this has to be done from the PI's account. Ask Benjamin or Sisira</li> </ul> </li> <li> <p>Create or update your profile with current contact information and institutional details</p> <ul> <li>Ask Soleil for Benjamin's updated CV</li> </ul> </li> <li> <p>Obtain necessary identifiers of participants (e.g., CCV ID, ORCID)</p> </li> </ul> <p>Pro Tip</p> <p>Attend webinars detailing the grant submission conducted by grant agencies.</p>"},{"location":"grants/Preparing_for_Submission/#step-2-letter-of-intent-loi-or-registration-if-required","title":"Step 2: Letter of Intent (LOI) or Registration (if required)","text":"<p>Check if the grant agency requires an Expression of Interest (EOI) prior to LOI submission.</p> <ul> <li> <p>Review specific grant requirements to determine if an LOI or preliminary proposal is needed</p> </li> <li> <p>Draft and submit the LOI by the stated deadline</p> </li> <li> <p>NPI review is required before submission</p> </li> <li> <p>Wait for approval or invitation to submit a full proposal</p> </li> </ul>"},{"location":"grants/Preparing_for_Submission/#step-3-internal-coordination-and-approvals","title":"Step 3: Internal Coordination and Approvals","text":"<p>Pro Tip</p> <p>Start this as early as possible to provide enough time for approvals, review etc.</p> <ul> <li>Inform relevant institutional offices about your grant submission (e.g., UHN Research Grants, RFS)</li> </ul> <p>Budgets should be added to BusinessHub  see the UHN Budget Process page</p> <ul> <li> <p>Obtain internal approvals, budgets, and documentation</p> </li> <li> <p>Coordinate with collaborators or co-investigators</p> </li> <li> <p>If your project involves biospecimens and animal models, you will need to obtain certificates from labs that generate the data. For patient data, REB is required</p> </li> <li> <p>Obtain Letters of Support and letters of collaboration </p> </li> </ul>"},{"location":"grants/Preparing_for_Submission/#step-4-develop-full-proposal","title":"Step 4: Develop Full Proposal","text":"<ul> <li> <p>Follow the structure outlined in the Proposal Template section</p> </li> <li> <p>Use BHK lab Miro for figures (Point of contact - Sisira)</p> </li> <li> <p>Gantt charts can be easily created with google sheets CIHR template</p> </li> <li> <p>This template can be adapted to each grants CIHR Budget template</p> </li> <li> <p>Research Data management is a crucial part of all grants, access a template here RDM</p> </li> <li> <p>Some grant websites use specific templates for each sections, please stick to those templates</p> </li> <li> <p>Draft, review, and refine each sections</p> </li> </ul>"},{"location":"grants/Preparing_for_Submission/#step-5-assemble-supporting-documents","title":"Step 5: Assemble Supporting Documents","text":"<ul> <li> <p>Budget and budget justification</p> </li> <li> <p>CVs or biosketches for key personnel</p> </li> <li> <p>Letters of support or commitment</p> </li> <li> <p>Certificates</p> </li> <li> <p>Institutional endorsement or authorization</p> </li> </ul>"},{"location":"grants/Preparing_for_Submission/#step-6-peer-review-final-checks","title":"Step 6: Peer Review &amp; Final Checks","text":"<ul> <li> <p>Request feedback from colleagues, mentors, or grant officers</p> </li> <li> <p>Share with PIs for a final review</p> </li> <li> <p>Check for compliance with guidelines, formatting, and completeness</p> </li> </ul>"},{"location":"grants/Preparing_for_Submission/#step-7-submit-the-proposal","title":"Step 7: Submit the Proposal","text":"<ul> <li> <p>Upload the proposal and all required documents to the submission portal</p> </li> <li> <p>Run checks on the portal if available</p> </li> <li> <p>Submit before the deadline and save confirmation docs to Submitted folder on drive</p> </li> </ul>"},{"location":"grants/Preparing_for_Submission/UHN_budget_process/","title":"UHN Budget Process","text":"<p>Budgets for grants need to be submitted to the UHN Grants Office at least one week before the application deadline.</p>"},{"location":"grants/Preparing_for_Submission/UHN_budget_process/#uhn-grant-application-module-info","title":"UHN Grant Application Module Info","text":"<p>Budgets must be submitted to UHN through their Business Hub application portal. In case you don\u2019t already have access to Business Hub, please see the Delegation section on the SharePoint module, which includes a form to be filled out so Business.Hub@uhn.ca can provide you with access.</p> <p>Once you have access to Business Hub, navigate to the Grant Applications page and click New Grant Application.</p> <ol> <li>Select Full Application</li> <li>Fill out the form with your budget information.     </li> <li>Once you've submitted, you'll receive an email with feedback from the grants office and whether you're approved for submission.</li> </ol>"},{"location":"onboarding_offboarding/Offboarding/","title":"Offboarding Policy","text":"<p>Thank you for your time in the lab. To ensure a smooth transition and back up of your work, please follow the policy detailed below. This policy applies to all individuals leaving BHK lab\u2019s employ. It is meant to ensure that all staff who leave the employ of BHK lab ensure that all relevant intellectual and physical assets purchased with BHK lab funds remain in BHK lab. </p>"},{"location":"onboarding_offboarding/Offboarding/#offboarding-meetings","title":"Offboarding Meetings","text":"<p>Individuals under the employ of BHK lab who either received or provided a notice of termination shall abide by the following offboarding processes. The process shall include the following meetings: </p> <ol> <li> <p>Offboarding Initialization - at least two (2) weeks prior to the last official working day</p> </li> <li> <p>Exit Interview - a final meeting on the day prior to the employee's last official working day or based on availability</p> </li> </ol>"},{"location":"onboarding_offboarding/Offboarding/#offboarding-initialization","title":"Offboarding Initialization","text":"<p>An assigned lab staff member will contact the employee to set this meeting. This meeting will be use to summarize the off-boarding requirements.</p> <ul> <li>A folder will be shared with the employee to add documents discussed during the initial meeting. This includes but is not restricted to a detailed back up of project details such as links to code, data folders and documentation.</li> <li>The Lab Off-boarding Information template will be shared with the employee. Please make a copy of this document in your offboarding report folder.</li> <li> <p>The Exit Interview Form will be shared with the employee. This should be completed just prior to the exit interview.</p> <p>Warning</p> <p>If you expect continued work with the lab for a publication or similar activity, permissions to any of the lab services MUST be requested and marked in this Exit Interview form.</p> </li> </ul>"},{"location":"onboarding_offboarding/Offboarding/#exit-interview","title":"Exit Interview","text":"<p>This meeting will be used to ensure all work items have been appropriately turned over and an exit interview will be conducted.</p> <p>The final documents will be reviewed for completeness and accuracy by the lab member taking over the project or mentor (students). The members will identify any missing items, or items that require clarification by the employee. The terminated employee will develop a progress plan to address any issues that arise in this meeting.</p>"},{"location":"onboarding_offboarding/Offboarding/#offboarding-intellectual-assets","title":"Offboarding Intellectual Assets","text":""},{"location":"onboarding_offboarding/Offboarding/#offboarding-report","title":"Offboarding Report","text":"<p>Members leaving the lab will prepare a single digital parent folder containing all ongoing and completed project work. This folder shall be renamed to the first and last name of the employee leaving BHK lab. The parent folder's contents shall contain: </p> <ol> <li> <p>The Lab Off-boarding Information document listing the following information:</p> <ul> <li> The name and last date of employment of the employee;</li> <li> All ongoing and completed projects that the terminated employee has worked on;</li> <li> Links to the location of all items saved to Github organized by project;</li> <li> Links to the location of all items saved to HPC4Health (H4H) organized by project, with all items saved to H4H adhering to the H4H Data Management Plan;</li> <li> Details about data ownership for each project and name of the lab personnel in charge who takes over your project. All ownership should be transferred to this person-in-charge.</li> </ul> </li> <li> <p>If applicable to individual projects, a single readme file that includes the following:</p> <ul> <li> Data download sources;</li> <li> Comments on data curation or any notable challenges;</li> <li> Any other relevant information.</li> </ul> </li> <li> <p>Any other relevant documents that are not caputred in (1) or (2).</p> </li> </ol> <p>This prepared folder will be shared by the terminated member with the assigned lab staff member, in addition to at least one (1) topic expert involved in each project included in the prepared folder. For short-term interns or volunteers, the parent folder can be shared with respective mentor(s). On receipt of the folder, each recipient shall confirm with the terminated employee the folder\u2019s contents, including clarification for the contents and location of any items not included in the folder. </p> <p>Link this document in your final SOW.</p> <p>Note</p> <p>All files related to your project that are linked in the above documents should be present in your BHKLab Google Drive account and shared with bhklab-admin@googlegroups.com and/or bhklab-members@googlegroups.com with edit access. The same applies for any relevant work documents. This is to ensure uninterrupted access without permission issues later.</p>"},{"location":"onboarding_offboarding/Offboarding/#bhklab-google-drive","title":"BHKLab Google Drive","text":"<p>To ensure continued access to all lab work related documents, we ask that the employee:</p> <ol> <li> <p>Upload all lab work related documents to your BHKLab Google Drive account. This includes any project related documents, presentations, etc. on your local machine. </p> <p>Warning</p> <p>This should not include code or internal datasets. Please store these in the appropriate locations (e.g. GitHub, H4H, etc.).</p> </li> <li> <p>Grant edit access to all contents of your BHKLab Google Drive to bhklab-admin@googlegroups.com. This can be done from the top level of the drive by selecting all contents and clicking the share button.</p> </li> <li> <p>Change the password to their BHKLab Gmail account and share this with the lab coordinator.</p> </li> </ol> <p>If there are private documents you wish to keep private, please move these to your personal storage. </p>"},{"location":"onboarding_offboarding/Offboarding/#github","title":"GitHub","text":""},{"location":"onboarding_offboarding/Offboarding/#project-repositories","title":"Project Repositories","text":"<ol> <li>Transfer any project repositories from your personal GitHub account to the BHKLab GitHub organization(https://github.com/bhklab).</li> <li>Include a <code>README</code> describing the project and any project documentation explaining how to run the code and/or reproduce the results.</li> </ol>"},{"location":"onboarding_offboarding/Offboarding/#open-pull-requests-branches","title":"Open Pull Requests / Branches","text":"<ol> <li>If you have any open pull requests or working branches on any BHKLab project repositories, push the latest local commit you have. <ol> <li>If the branch does not already have an open pull request, create a new pull request.</li> </ol> </li> <li>Leave a comment on the PR describing what stage the branch is at and what next steps need to be taken.</li> <li>Assign the PR to the repo owner, whoever is taking over the project, or your mentor.</li> </ol>"},{"location":"onboarding_offboarding/Offboarding/#project-data","title":"Project Data","text":"<p>For any project data listed in your Offboarding Report, please ensure that:</p> <ol> <li>ALL data paths are included (e.g. srcdata, rawdata, procdata, should all be listed separtely).</li> <li>Indicate for each dataset if it is required to replicate the project. This will help us determine if we can keep the data or if it needs to be removed.</li> <li> <p>Ensure that group access is enabled for all data. Run the following command for the dataset directory:</p> <p><pre><code>chmod -R 775 &lt;DIRECTORY_PATH&gt;\n</code></pre> You can confirm that the data is accessible by running the following command: <pre><code>ls -l \ntotal 2\ndrwxrwxr-x  2 &lt;USERNAME&gt; &lt;USERNAME&gt; 4096 Jan  1 00:00 &lt;DIRECTORY_PATH&gt;\n</code></pre></p> </li> </ol>"},{"location":"onboarding_offboarding/Offboarding/#physical-assets-purchased-by-bhklab","title":"Physical Assets Purchased by BHKLab","text":"<p>Please ensure you return the assets to the lab coordinator in person.</p> <p>If an employee wishes to have possession of any BHK Lab asset purchased with operating funds and/or research funds, they may request from the employer permission to purchase such asset at fair market value.  The employer will determine if it is in the best interests of BHK Lab to sell the asset.</p> <p>If the employer agrees to sell the asset, the employer shall determine fair market value through processes deemed appropriate by the employer. </p>"},{"location":"onboarding_offboarding/Offboarding/#on-your-last-day","title":"On Your Last Day","text":"<p>On your official last day, please ensure that you return your Photo ID card and access card to the PMCRT Security office, located on the first floor of the MARS Discovery District.</p>"},{"location":"onboarding_offboarding/Offboarding/#letters-of-recommendation","title":"Letters of Recommendation","text":"<p>If an employee requires a letter of recommendation, s/he can send an email to Dr. Benjamin Haibe-Kains (benjamin.haibe-kains@uhn.ca) from their non-UHN email with mentors or other topic experts (optional) in cc. If the letter is required in the future, this email chain can be used. Please make sure the purpose of the letter is specified in your email. This is particularly relevant for short term students.</p>"},{"location":"onboarding_offboarding/Offboarding/#consequences-for-non-compliance","title":"Consequences for Non-Compliance","text":"<p>An individual whose employment with BHK Lab ends but who does not return BHK Lab assets in accordance with this policy may be subject to collection agency pursuit and/or legal action. Letters of recommendation or any similar styled letters will not be made out to any employee who fails to return lab assets in compliance with the stated offboarding processes and procedures. </p>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/","title":"Admin Offboarding Instructions","text":"<p>This checklist is for the assigned lab staff running the offboarding process.</p>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#before-the-offboarding-initialization-meeting","title":"Before the Offboarding Initialization Meeting","text":"<ol> <li>Create a folder in Offboarding Reports with the name of the lab member.</li> <li>Share this folder to their BHKLab Gmail (e.g. bhklab.johndoe@gmail.com).</li> <li>Share the Lab Off-boarding Information template with the lab member.</li> <li>Share the Offboarding Policy with the lab member.</li> </ol>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#email-template","title":"Email Template","text":"<p>Send the following email to the lab member to schedule the two meetings: Email Template</p>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#during-the-offboarding-initialization-meeting","title":"During the Offboarding Initialization Meeting","text":"<ol> <li>Walk through the Offboarding Policy with the lab member.</li> <li>Make sure they have access to their Offboarding Report folder and Information template.</li> <li>Send the Exit Interview Form to the lab member via their BHKLab Gmail.<ol> <li>Explain that the Exit Interview form should be completed just prior to the exit interview.</li> </ol> </li> <li>Request that the lab member change the password to their BHKLab Gmail account and share this with the lab coordinator.</li> </ol>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#during-the-exit-interview","title":"During the Exit Interview","text":""},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#uhn-account","title":"UHN Account","text":"<p>The Office coordinator (Soleil Miron) has to make sure that the employee\u2019s UHN email/inbox is inactivated. </p>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#lab-service-access","title":"Lab Service Access","text":"<p>Make sure that access to lab resources are inactivated.</p> <p>Note</p> <p>Check the Exit Interview form to see if any of the following lab resources have been requested to be kept active for the lab member.</p> <p>Service list:</p> <ul> <li> Slack</li> <li> GitHub</li> <li> Google Groups</li> <li> H4H</li> <li> GPU Server</li> <li> Cloud services (GCP, AWS, Azure)</li> <li> Miro</li> <li> Paperpile</li> </ul>"},{"location":"onboarding_offboarding/Offboarding/admin_checklist/#after-the-exit-interview","title":"After the Exit Interview","text":"<p>To be done by assigned lab staff in charge of offboarding:</p> <ol> <li>Update member status in the BHKLab Member Tracking sheet to 'Alumni'</li> <li>Update member status on website</li> <li>Remove the member from the Lab Member Expertise page</li> </ol>"},{"location":"onboarding_offboarding/Onboarding/","title":"Onboarding","text":"<p>Congratulations on your successful interview and welcome to BHK Lab! </p> <p>We\u2019re excited to have you join the team. Before you begin, there are a few important items that we wanted you to be aware of. This document will provide you with an overview of BHK Lab\u2019s processes, procedures, and our standards for maintaining digital files. </p>"},{"location":"onboarding_offboarding/Onboarding/#lab-overview","title":"Lab Overview","text":"<p>Review the Lab Mission Statement to get a sense of what we do and what we are trying to accomplish.</p>"},{"location":"onboarding_offboarding/Onboarding/#uhn-onboarding-package","title":"UHN Onboarding Package","text":"<p>You will be contacted by BHK Lab\u2019s Office Coordinator, Soleil Miron, via email with the instructions for completing your UHN onboarding. Your UHN onboarding must be completed before your start date. The instructions for completing the UHN onboarding will be provided to you in Soleil\u2019s email. Any changes to your work schedule must be approved by Dr. Haibe-Kains and reported by email to Soleil for payroll purposes. Please look for a biweekly Payroll Reporting reminder email from Soleil. </p> <p>For further instruction on how to complete your UHN onboarding, please see the UHN Onboarding page.</p>"},{"location":"onboarding_offboarding/Onboarding/#bhklab-onboarding-package","title":"BHKLab Onboarding Package","text":"<p>Once your UHN onboarding is complete, new employees can begin the BHKLab specific onboarding process. Steps are outlined on the BHKLab Onboarding page.</p>"},{"location":"onboarding_offboarding/Onboarding/#meetings-to-attend","title":"Meetings to Attend","text":"<p>See the Meetings page for an overview of mandatory meetings to attend.</p>"},{"location":"onboarding_offboarding/Onboarding/#mbp-rotation-students","title":"MBP Rotation Students","text":"<p>If you are an MBP student completing a rotation in the BHKLab, please see the MBP Rotation Students page.</p>"},{"location":"onboarding_offboarding/Onboarding/#best-practices-and-templates","title":"Best Practices and Templates","text":"<p>BHK Lab has developed a series of data storage guidelines to ensure that files can be found with ease by all members of the lab. All members, including new employees, are expected to maintain files in agreement with the current lab standards. You can find these around the BHKLab Handbook. We'll highlight a few below:</p> <ul> <li>Summary of Work Instructions</li> <li>Lab Meeting best practices</li> <li>Journal club best practices</li> <li>HPC4Health help</li> <li>R Coding</li> <li>Scientific Software Best Practices</li> </ul>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/","title":"BHKLab Onboarding Policy","text":""},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#bhklab-onboarding-form","title":"BHKLab Onboarding Form","text":"<p>Once you have completed UHN onboarding, you will be directed to the Lab Coordinator responsible for onboarding. You should have received an email with instructions for completing the BHKLab Onboarding Form. This form will help guide you through the onboarding process. When complete, please notify the Lab Coordinator so they can begin setting up your access to lab resources.</p>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#pmcrt-lab-tour","title":"PMCRT Lab Tour","text":""},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#lab-location","title":"Lab Location","text":"<p>The BHKLab is located in room 11-401 of the Princess Margaret Cancer Research Tower (PMCRT) in the MARS Discovery District.</p>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#directions-to-the-lab","title":"Directions to the lab","text":"<ol> <li> <p>Find the elevators nearest to Mercatto on the MARS ground floor . If you are exiting the PMCRT security office, walk up the hallway ramp, through the frosted glass doors, and go straight across to the elevators.</p> </li> <li> <p>Go to the 11th floor of PMCRT. If the button does not work, tap your security card on the black glass below the floor buttons on the left side of the elevator.</p> </li> <li> <p>On the 11th floor, when you cross the security doors, make a right and go down the hallway. Turn left when you reach the next hallway with a sign that reads \"11-401 Main Laboratory, South\". </p> <p></p> </li> <li> <p>Go through security doors and make a left.</p> </li> </ol>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#lab-coordinator-onboarding","title":"Lab Coordinator Onboarding","text":"<p>On the first day in the lab, all new employees will be scheduled for a research onboarding by the Lab Coordinator. During the research onboarding, you will be provided an office tour of the physical and/or digital workplace. The digital office tour will include an overview of our internal research systems including: </p> <ul> <li>BHKLab Google Account</li> <li>Summary of Work (SOW)</li> <li>BHKLab Calendar, and the dates of lab meetings and journal club</li> <li>BHK Lab Slack</li> <li>BHK Lab GitHub (added by supervisor/mentor as this is project specific)</li> <li>Any additional programs/systems specific to the employee\u2019s work duties</li> </ul>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#in-the-physical-labspace-confirm-that-the-following-items-are-set-up","title":"In the physical labspace, confirm that the following items are set up:","text":"<ul> <li> Employee has picked up their UHN Photo ID card from Toronto General Photo ID office (Department is \u201cPrincess Margaret - Research\u201d)</li> <li> Employee has picked up their PMCRT Access card from the PMCRT security office</li> <li> Assigned to a workspace in the lab</li> <li> Ensure the employee has access to a computer/monitor, keyboard, and mouse if available in the Lab Equipment Inventory</li> </ul>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#digitally-confirm-that-the-following-items-are-set-up","title":"Digitally, confirm that the following items are set up:","text":"<ul> <li> Creation of a BHKLab Google account (long-term employees only)</li> <li> Addition of BHKLab Gmail to the \"BHKLab Members\" Google Group - this will be used to grant access to BHKLab Google Drive documents and lab calendar</li> <li> Invitation to BHKLab Slack</li> <li> Invitation to BHKLab GitHub Team</li> <li> Addition of prefered email address to the \"BHKLab\" Google Group - this will be used for lab-wide communication by Soleil</li> <li> Any other resources deemed necessary</li> </ul>"},{"location":"onboarding_offboarding/Onboarding/bhklab_onboarding/#lab-mentorsupervisor-onboarding","title":"Lab Mentor/Supervisor Onboarding","text":"<p>The employees will then be directed to their supervisor/mentor to discuss your project and any other resources you may need. </p> <p>These may include:</p> <ul> <li> Set up for HPC4Health access (if applicable)</li> <li> Any project specific resources deemed necessary</li> </ul>"},{"location":"onboarding_offboarding/Onboarding/lab_member_expertise/","title":"Lab Member Expertise","text":"<p>This document outlines various expertise of lab members. Helpful for new recruits, writing personnel skills for funding, and clear communication of individual roles.</p>"},{"location":"onboarding_offboarding/Onboarding/lab_member_expertise/#expertise-table","title":"Expertise Table","text":"Expertise Names Statistical modeling &amp; analysis Farnoosh Abbas Aghababazadeh Biomarker analysis Farnoosh Abbas Aghababazadeh, Julia Nguyen, Sisira Kadambat Nair, Nikta Feizi, Nasim BondarSahebi RNAseq processing Julia Nguyen, Nasim BondarSahebi Microarray processing Sisira Kadambat Nair ATACseq processing Julia Nguyen circRNA analysis Julia Nguyen, Peter Her Exploratory Data Analysis in R Julia Nguyen, Farnoosh Abbas Aghababazadeh, Kevin Wang, Sisira Kadambat Nair, Nikta Feizi, Michael Tran, Yash Patel, Nasim BondarSahebi Single cell processing TBA Single cell analysis TBA Quantitative imaging Caryn Geady, Katy Scott, Ruiyan Ni, Sejin Kim ML models Katy Scott, Caryn Geady, Ruiyan Ni, James Bannon, Farnoosh Abbas Aghababazadeh, Nabin Bagale, Shaghayegh Reza, Kewei Ni ML analysis Katy Scott, Caryn Geady, James Bannon, Ruiyan Ni, Sejin Kim, Nabin Bagale, Shaghayegh Reza, Kewei Ni Deep learning James Bannon, Katy Scott, Sejin Kim, Ruiyan Ni, Joshua Siraj, Nabin Bagale, Shaghayegh Reza Cancer subtype analysis Foram Vyas, Nikta Feizi R packages Jermiah Joseph Clinical oncology Kevin Wang Full stack web development Matthew Boccalon Immunotherapy Farnoosh Abbas Aghababazadeh, Kevin Wang Python packages Jermiah Joseph, Katy Scott, Sejin Kim Cloud services (GCP) Jermiah Joseph, Matthew Boccalon, Nabin Bagale, Shaghayegh Reza Grant &amp; Award proposals Sisira Kadambat Nair LabOps Sisira Kadambat Nair, Katy Scott Hiring Sisira Kadambat Nair Payroll, grant budgets, meeting room scheduling, purchases Soleil Miron Pipelines (Snakemake) Jermiah Joseph High Performance Computing (HPC) on H4H Jermiah Joseph Version Control (Git &amp; GitHub) Jermiah Joseph"},{"location":"onboarding_offboarding/Onboarding/mbp_rotation/","title":"MBP Rotation Students","text":"<p>If you are a student from the University of Toronto Medical Biophysics program completing a rotation in the BHKLab, there are a few more steps to make your rotation experience as smooth as possible.</p>"},{"location":"onboarding_offboarding/Onboarding/mbp_rotation/#your-project","title":"Your Project","text":"<p>Work with your assigned lab mentor to determine what project you will be working on and what the expectations are for your time in the lab.</p> <p>Focus on elements such as:</p> <ul> <li>Is there existing literature to review?</li> <li>What datasets will you be working with?</li> <li>Are you writing code from scratch or expanding an existing code base?</li> <li>What are the deliverables for your project? Code, documentation, analysis results, etc.</li> </ul> <p>We know your rotation time will fly by, so make sure to keep that timeline in mind when planning out your work.</p>"},{"location":"onboarding_offboarding/Onboarding/mbp_rotation/#presentation-to-the-lab","title":"Presentation to the Lab","text":"<p>In your final week with the lab, you will be presenting the work you have completed during the weekly lab meeting OR at a time that Ben is available that week. If you are not able to attend the lab meeting, you will need to present your work at a time that Ben is available that week.</p> <p>Warning</p> <p>Schedule your presentation with your lab mentor and the lab coordinator in the first week of your rotation so we can ensure that Ben is available and a room may be booked if the presentation is scheduled outside of lab meeting.  For mentors: if the presentation needs to be scheduled outside of lab meeting, please contact the lab coordinator to ensure that Ben is available and a room may be booked.</p> <p>You can review the lab meeting page for guidance on how to present your work, but the best way to prepare is to attend the lab meetings during your rotation to get a sense of what is expected of you.</p>"},{"location":"onboarding_offboarding/Onboarding/uhn_onboarding/","title":"UHN Onboarding Policy","text":""},{"location":"onboarding_offboarding/Onboarding/vpn/","title":"Configuring UHN VPN","text":""},{"location":"onboarding_offboarding/Onboarding/vpn/#quick-introduction-why-do-we-need-a-vpn","title":"Quick introduction: why do we need a VPN?","text":"<p>A Virtual Private Network (VPN) is essential in the workplace to ensure secure and private access to the company network, especially when working remotely or on public Wi-Fi. </p> <p>A VPN encrypts internet traffic, protecting sensitive data from potential cyber threats and unauthorized access. This helps maintain confidentiality, ensures data integrity, and supports secure access to internal resources, safeguarding the organization's digital environment.</p> <p>GlobalProtect is UHN's VPN service for workers. GlobalProtect provides secure, encrypted access to the corporate network, ensuring users can safely connect to company resources from any location, while maintaining data security and compliance with organizational policies.</p>"},{"location":"onboarding_offboarding/Onboarding/vpn/#steps-for-configuring-vpn-on-personal-devices","title":"Steps for configuring VPN on personal devices","text":"<p>Most likely you will need to configure the VPN on your personal device. The person onboarding you or your supervisor will probably tell you so and either request VPN access to IT for you or help you to do it.</p> <p>IT will generally accept the request quickly, and send instructions to your corporate email on the steps to follow to install and configure the VPN.</p> <p>If you are a Windows or Mac user, that's it. The manual is pretty good, simple and straightforward. Follow the steps and you've got this. Easy.</p> <p>If you are on Ubuntu... There's no downloading link or steps. You get stuck on the very first step. Don't worry, you don't have to open a ticket on Helpdesk and wait for them to respond... The next section will make things easier for you.</p>"},{"location":"onboarding_offboarding/Onboarding/vpn/#downloading-globalprotect-software-on-ubuntu","title":"Downloading GlobalProtect software on Ubuntu","text":"<p>After contacting Helpdesk a few times, I finally got an email with the downloading instructions for Ubuntu. Here I leave the email, I think it may be useful.</p> <p>Download the installation file from the link or via the curl command: </p> <pre><code>curl https://roseshare.rose-hulman.edu/portal/s/162637781701644125980.tgz --output PanGPLinux-5.3.0-c32.tgz --ciphers 'DEFAULT:!DH'\n</code></pre> <p>Unzip tar file, by running: tar -xvf PanGPLinux-5.3.0-c32.tgz</p> <p>Install the program:</p> <p>On Ubuntu/Debian, this is done through the command:</p> <pre><code>sudo dpkg \u2013i GlobalProtect_deb-5.3.0.0-32.deb\n</code></pre> <p>On Redhat/CentOS, this is done through the command:</p> <pre><code>sudo yum localinstall GlobalProtect_rpm-5.3.0.0-32.rpm\n</code></pre> <p>To start the program, simply enter in a shell</p> <pre><code>globalprotect\n</code></pre> <p>and then a prompt should display.</p> <p>From the prompt, run </p> <pre><code>connect -portal connect2.uhn.ca\n</code></pre> <p>Login with your email address (username@uhn.ca) as your username and password.</p> <p>Type quit to exit the prompt.</p>"},{"location":"onboarding_offboarding/Onboarding/vpn/#thats-it-just-remember-connecting-and-disconnecting-the-vpn-every-time-you-need-it","title":"That's it - just remember connecting and disconnecting the VPN every time you need it","text":"<p>Now that you have your laptop configured for the VPN, don't forget connecting every time you want to use it, running the following command:</p> <pre><code>globalprotect\n</code></pre> <p>And then running in the prompt:</p> <pre><code>connect -portal connect2.uhn.ca\n</code></pre> <p>When you want to disconnect from the VPN, you have to run</p> <pre><code>globalprotect\n</code></pre> <p>And then in the prompt:</p> <pre><code>disconnect\n</code></pre>"},{"location":"resources/","title":"Essential Lab Resources: Tools, Guides &amp; References","text":"<p>A comprehensive collection of tools, guides, and references to support your lab work. Access learning resources, explore training programs and award opportunities to enhance your skills and advance your career.</p>"},{"location":"resources/Undergraduate_award_opportunities/","title":"Trainee funding opportunities","text":""},{"location":"software_development/","title":"Software Development","text":"<p>All things related to software development.</p>"},{"location":"software_development/Development_Environment/","title":"Development Environment","text":"<p>Think of the development environment as EVERYTHING that you need to develop your project.</p> <p>This includes:</p> <ul> <li> <p>What Shell are you using?</p> <ul> <li><code>Bash</code></li> <li><code>PowerShell</code> for most Windows users</li> <li><code>Windows Subsystem for Linux</code> (WSL)</li> <li><code>Zsh</code> (commonly installed for macOS users) but can be used on Linux!</li> </ul> </li> <li> <p>Integrated Development Environments (IDEs)</p> <ul> <li>VS Code</li> <li>PyCharm</li> <li>Jupyter Notebook</li> <li>etc.</li> </ul> </li> <li>Package Managers<ul> <li>Conda/Mamba</li> <li>Pixi</li> <li>Pip</li> <li>npm</li> </ul> </li> <li>Containerization<ul> <li>Docker</li> <li>Singularity</li> </ul> </li> <li>Version Control</li> <li>etc.</li> </ul>"},{"location":"software_development/Development_Environment/CLI_Tools/","title":"Command Line Interface (CLI) Tools","text":""},{"location":"software_development/Development_Environment/Containerization/","title":"Containerization","text":""},{"location":"software_development/Development_Environment/Integrated_Development_Environments/","title":"Integrated Development Environments (IDEs)","text":""},{"location":"software_development/Development_Environment/Package_Managers/","title":"Package Managers","text":""},{"location":"software_development/Development_Environment/Shells/","title":"Shells","text":""},{"location":"software_development/Development_Environment/Shells/#what-is-a-shell","title":"What is a Shell?","text":"<p>A shell is a user interface that provides access to the operating system's services. Typically, it functions as a command-line interface (CLI), where users can enter commands to perform tasks such as navigating directories, executing programs, and automating processes with scripts.</p>"},{"location":"software_development/Development_Environment/Shells/#types-of-shells","title":"Types of Shells","text":"<p>There are various shells, each offering unique features and catering to different needs. Some of the most commonly used shells include:</p> Shell Name Description Platforms Bash The Bourne Again Shell, commonly used on Unix-based systems. Unix, Linux, macOS Zsh An enhanced shell with additional features, extending the functionality of the Bourne Shell. Unix, Linux, macOS PowerShell Task automation and configuration management framework by Microsoft, cross-platform support. Windows, Linux, macOS"},{"location":"software_development/Development_Environment/Shells/#tldr","title":"TL;DR","text":"<p>Here's a quick comparison of the most popular shells:</p> Shell Best For Key Strengths Bash Simplicity, basic scripting, Unix environments Widely available, easy to use, ideal for general tasks Zsh Customization, advanced features, plugin ecosystem Highly customizable, rich plugin and theme support, advanced completion PowerShell Cross-platform automation, Windows environments Object-oriented, powerful scripting, deep Windows integration"},{"location":"software_development/Development_Environment/Shells/#comparison-table","title":"Comparison Table","text":"<p>Here's a comparison table that highlights the key differences between Bash, PowerShell, and Zsh:</p> Feature Category Bash PowerShell Zsh Features Simplicity Simple and beginner-friendly - - Portability Widely available on Unix-like systems Cross-platform (Windows, Linux, macOS) - Scripting Basic scripting support for automation Advanced scripting with cmdlets and modules Enhanced scripting over Bash Object-Oriented - Works with objects, unlike other text-based shells - Integration - Deep integration with Windows for administrative tasks - Customizability - - Highly customizable with themes and plugins Completion - - Advanced, programmable completion features Plugins - - Extensive plugin support for extended functionality User Experience Default Shell Default on many Linux distributions and macOS - - Prompt Simple, functional, customizable Customizable prompt with rich information display Highly customizable with frameworks like Oh My Zsh Integration with IDEs - Integrated with Visual Studio Code - Themes and Plugins - - Extensive theme and plugin support Ecosystem and Community Documentation Extensive official documentation and community tutorials Comprehensive official docs by Microsoft Good official docs and community resources Community Large and active community with many resources available Growing community among Windows admins and developers Active community with strong focus on customization Modules/Plugins - Rich set of modules for various administrative tasks Vibrant plugin and theme ecosystem (e.g., Oh My Zsh)"},{"location":"software_development/Languages/","title":"Languages","text":"<p>Ideas for a breakdown:</p>"},{"location":"software_development/Languages/#programming-languages","title":"Programming Languages","text":"<ul> <li>R</li> <li>Python</li> <li>JavaScript/Typescript</li> <li>Rust</li> </ul>"},{"location":"software_development/Languages/#scripting-languages","title":"Scripting Languages","text":"<ul> <li>Purpose and Usage</li> <li>Examples<ul> <li>Bash</li> <li>Perl</li> <li>Ruby</li> </ul> </li> </ul>"},{"location":"software_development/Languages/#domain-specific-languages","title":"Domain-Specific Languages","text":"<ul> <li>Definition</li> <li>Examples<ul> <li>SQL</li> <li>HTML</li> </ul> </li> </ul>"},{"location":"software_development/Languages/#compiled-vs-interpreted-languages","title":"Compiled vs. Interpreted Languages","text":"<ul> <li>Definitions</li> <li>Key Differences</li> </ul>"},{"location":"software_development/Languages/#programming-paradigms","title":"Programming Paradigms","text":"<ul> <li>Procedural Programming</li> <li>Object-Oriented Programming</li> <li>Functional Programming</li> </ul>"},{"location":"software_development/Languages/#choosing-a-programming-language","title":"Choosing a Programming Language","text":"<ul> <li>Considerations</li> <li>Language Popularity</li> <li>Community and Support</li> </ul>"},{"location":"software_development/Languages/Javascript_Typescript/","title":"JavaScript/TypeScript","text":""},{"location":"software_development/Languages/Javascript_Typescript/#what-is-javascript","title":"What is JavaScript","text":"<p>JavaScript is primarily known as a high-level (abstracted from complexity) programming language, most notably used in creating dynamic front-end web content. Due to it's versatility it has also been adopted to create APIs and run server side operations in full stack applications. </p>"},{"location":"software_development/Languages/Javascript_Typescript/#why-we-use-javascript","title":"Why We Use JavaScript","text":"<p>JavaScript is the most common choice for the front-end and backend in full stack applications in the lab because of its ease of use, portability, improving performance, and how common it is in the industry. When learning web development you typically will end up using vanilla JavaScript or JavaScript libraries such as React, Vue, or Angular to start, making it a safe option for newcomers and seasoned developers.</p>"},{"location":"software_development/Languages/Javascript_Typescript/#how-to-run-javascript","title":"How to run JavaScript","text":"<p>For the front-end/client portions of JavaScript applications, there are no additional engines/compilers needed to execute code because browsers have built-in JavaScript engines (utilizing JIT) that will execute the code for you. However, when using JavaScript code server side (code execution by your machine) you will need a Node.js runtime environment to be installed on your computer because operating systems don't include them natively. The best way to install Node.js on your system and manage versions is using nvm (Node Version Manager). Every project in the lab was likely developed with a different version of node, so making sure you are utilizing the ones compatible with the code/packages is important to ensure expected functionality.</p>"},{"location":"software_development/Languages/Javascript_Typescript/#what-is-typescript","title":"What is TypeScript","text":"<p>TypeScript is simply a superset language of JavaScript that provides additional functionality such as static typing, interfaces/types, and enums to name a few. The additional functionalities of TypeScript help you avoid errors before they happen (saves you debugging time), makes your code more predictable, and help others understand it easier. The best part about TypeScript is the fact that all JavaScript code is also valid TypeScript code (because TypeScript is a superset of JavaScript). This makes adding TypeScript to your arsenal easier for your next project and also makes incrementally adopting TypeScript into already existing JavaScript projects quite seamless.</p>"},{"location":"software_development/Languages/Markdown/","title":"Markdown","text":"<p>Markdown is extensively used in all kinds of software development projects for creating documentation, blog posts, and other content.</p>"},{"location":"software_development/Languages/Markdown/#why-markdown","title":"Why Markdown?","text":"<p>Markdown is a simple and easy-to-use markup language that only takes 10 minutes to learn the basics of.</p> <p>Its syntax is simple and easy to read, making it a great choice for writing documentation.</p>"},{"location":"software_development/Languages/Markdown/#markdown-tutorials","title":"Markdown Tutorials","text":"<p>Visit this 10 minute Markdown tutorial to learn the basics of Markdown.</p> <p>The Markdown Basic Syntax page is a great reference when you're getting started with Markdown.</p> <p>Keeping the Markdown Guide handy is also recommended, as it can provide quick answers to common questions.</p>"},{"location":"software_development/Languages/Markdown/mkdocs/","title":"MkDocs","text":"<p>MkDocs is a static site generator that uses Markdown files (and many other formats) to create a website.</p> <p>This handbook is built using MkDocs and Material for MkDocs. These tools also have extensive documentation and guides for contributing to a Mkdocs project.</p> <p>Note</p> <p>For a basic tutorial on Markdown, see the Markdown page.</p> <p>Funamentally, any standard Markdown file is valid for MkDocs, however, there are some additional features that can be used to enhance the look and feel of your documentation.</p>"},{"location":"software_development/Languages/Markdown/mkdocs/#material-for-mkdocs","title":"Material for MkDocs","text":"<p>Material for MkDocs is a theme for MkDocs that provides a modern and customizable look and feel.</p> <p>It provides an easy-to-use interface for creating documentation.</p> <p>Visit the Material for MkDocs Formatting page for more information on adding extra flavor to your Markdown files.</p>"},{"location":"software_development/Languages/Markdown/mkdocs/examples/","title":"Tabbed Code/Content Blocks","text":"<p>The <code>tabbed</code> extension allows you to create tabbed code/content blocks.</p> <p>Note</p> <p>This extension is already enabled, you just have to format your markdown to use it.</p> <p>See reference here.</p> Tabbed Code BlocksTabbed Content <p>Click on either <code>C</code> or <code>C++</code> to view the code specific to that language.</p> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <p>The markdown for the above code blocks: <pre><code>=== \"C\"\n\n    ``` c\n    #include &lt;stdio.h&gt;\n\n    int main(void) {\n      printf(\"Hello world!\\n\");\n      return 0;\n    }\n    ```\n\n=== \"C++\"\n\n    ``` c++\n    #include &lt;iostream&gt;\n\n    int main(void) {\n      std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n      return 0;\n    }\n    ```\n</code></pre></p> <p>Click on either <code>Unordered list</code> or <code>Ordered list</code> to view the content specific to that list type.</p> Unordered listOrdered list <ul> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ul> <ol> <li>Sed sagittis eleifend rutrum</li> <li>Donec vitae suscipit est</li> <li>Nulla tempor lobortis orci</li> </ol> <p>The markdown for the above content blocks:</p> <pre><code>=== \"Unordered list\"\n\n    * Sed sagittis eleifend rutrum\n    * Donec vitae suscipit est\n    * Nulla tempor lobortis orci\n\n=== \"Ordered list\"\n\n    1. Sed sagittis eleifend rutrum\n    2. Donec vitae suscipit est\n    3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"software_development/Languages/Python/","title":"Python","text":""},{"location":"software_development/Languages/R/","title":"R","text":""},{"location":"software_development/Languages/R/#what-is-r","title":"What is R?","text":"<p>R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis.</p>"},{"location":"software_development/Languages/R/Tidyverse/","title":"Tidyverse","text":"TL;DR <p>The Tidyverse is a suite of R packages that mesh together with a goal of improving common data science pipeline steps, namely data import, tidying, manipulation, visualisation, and programming.</p> <p>Of the eight core packages, some notable ones include:</p> <ul> <li><code>readr</code>, for data import and export</li> <li><code>dplyr</code>, for data manipulation</li> <li><code>ggplot2</code>, for data visualization</li> </ul> <p>The packages also emphasize the use of the pipe, <code>|&gt;</code> or <code>%&gt;%</code>. When you pipe an object forward, it is treated as the first parameter in the next function. For example, the two lines below are equivalent to one another:</p> <p><pre><code>colnames(read.csv(filename, header = TRUE))\n</code></pre> <pre><code>filename |&gt; read.csv(header = TRUE) |&gt; colnames()\n</code></pre></p>"},{"location":"software_development/Languages/R/Tidyverse/#what-is-the-tidyverse","title":"What is the Tidyverse?","text":"<p>From the Tidyverse website:</p> <p>\"The Tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\"</p> <p>The origins of the Tidyverse began from a paper written by Hadley Wickham in 2014, titled \"Tidy Data\", in which he describes the aforementioned design philosophy. (For those interested, you can read the paper here: 10.18637/jss.v059.i10.) More recent documentation of the underlying principles guiding Tidyverse packages can be found in the tidy tools manifesto as well as the Tidy design principles book.</p> <p>For an introduction on the Tidyverse, take a look at their package page.</p> <p>You can see a list of the eight core packages on their site here, and further details within their respective documentation pages. For a quick visual overview of a specific package, you can also find its respective cheatsheet on this page.</p>"},{"location":"software_development/Languages/R/Tidyverse/#why-use-the-tidyverse","title":"Why use the Tidyverse?","text":"<p>The Tidyverse is an opinionated collection of packages, meaning that while the packages all cohesively follow the same design philosophy, they may not work well with how you prefer to program or for your specific use case. You may choose to use only certain packages from the Tidyverse, or you may choose to only use base R and other alternatives.</p> <p>Some advantages of using the Tidyverse are:</p> <ul> <li>Consistency: All packages in the Tidyverse follow the same design     philosophy, making it easier to learn and use multiple packages. They also     mesh well with one another, making it easier to use multiple packages     together.</li> <li>Piping: Most of the Tidyverse is designed to be used together with pipes.     The <code>|&gt;</code> operator from base R &gt;=4.1 works well for this, or you can use the     <code>%&gt;%</code> pipe from the <code>magrittr</code> package for more advanced piping options.</li> <li>Readability: Often Tidyverse code is more human-readable than more complex     R alternatives, especially when using long pipe chains.</li> </ul> <p>Some disadvantages of using the Tidyverse are:</p> <ul> <li>Learning curve: The Tidyverse has a learning curve, especially if you are     new to R or programming in general. If switching over from base R, there     might also be a learning curve to relearn how to do things you are already     familiar with because of how differently things are designed.</li> <li>Stability: The Tidyverse is constantly evolving, and packages may be     updated or deprecated. While base R tries to emphasize stability across     updates, the Tidyverse packages are actively developed, and updates may     introduce changes that improve functionality but could impact existing code.</li> <li>Compatibility: The Tidyverse is not the only way to do things in R, and as     well, there are countless other packages that may not play nicely with     Tidyverse-oriented data structures or tibbles. In these cases you may have     to convert back and forth between tibbles and data frames, which can be     cumbersome.</li> </ul>"},{"location":"software_development/Languages/R/Tidyverse/#introductory-example","title":"Introductory Example","text":"<p>Say we have a CSV file containing a table, and we want to:</p> <ol> <li>Read the file into R;</li> <li>Perform some manipulations on the data; and</li> <li>Write out the new table to a different CSV file.</li> </ol> <p>First, let's define some common paths for input and output:</p> <pre><code>infile &lt;- \"rawdata/my_df.csv\"\noutfile &lt;- \"procdata/my_df.csv\"\n</code></pre> <p>Using these paths, let's compare the code for what this whole process might look like.</p> Base RTidyverse <pre><code># Read the CSV file\nmy_df &lt;- read.csv(infile)\n\n# Filter to only rows where value &gt; 10\nmy_df_filtered &lt;- my_df[my_df$value &gt; 10, ]\n\n# Select only specific columns\nmy_df_selected &lt;- my_df_filtered[, c(\"id\", \"value\")]\n\n# Write the output out to a new CSV file\nwrite.csv(my_df_selected, outfile, row.names = FALSE)\n</code></pre> <ul> <li>Note: You could also overwrite the <code>my_df</code> variable each time you filter rows and select columns instead of creating new intermediary data frames, especially if you have no need to keep the original or intermediary data.</li> </ul> <pre><code>my_df &lt;- infile |&gt;      # Start with the path, piping forward into the \"pipeline\"\n  read_csv() |&gt;         # From `readr`, reads a csv at the path into a tibble\n  filter(value &gt; 10) |&gt; # From `dplyr`, filters to only rows that match condition\n  select(id, value) |&gt;  # From `dplyr`, selects only specified columns by name\n  write_csv(outfile)    # From `readr`, writes the tibble to a csv file path\n</code></pre> <ul> <li>Note: While technically not required, setting <code>my_df</code> to the pipeline will save the final pipeline result to that variable name. The function <code>write_csv()</code> invisibly returns the same tibble piped into it, thus it is saved as <code>my_df</code>.</li> </ul> <p>Arguably, the human-readability of the code became a bit better, even if you're not necessarily familiar with the Tidyverse. Note that the <code>read.csv()</code> function is different from the <code>read_csv()</code> function, as well as <code>write.csv()</code> and <code>write_csv()</code>. Often base R uses dot notation for their variables and functions, e.g. <code>as.data.frame()</code>, whilst Tidyverse convention is to use snakecase, e.g. <code>as_tibble()</code>.</p>"},{"location":"software_development/Languages/R/Tidyverse/#tidyverse-vs-base-r","title":"Tidyverse vs. Base R","text":"<p>It's important to differentiate the R Tidyverse packages and design from the base R language itself. The R programming language is developed and maintained by the R Core team and R Foundation, whilst the Tidyverse (as well as a multitude of other R programming tools and packages) are developed and maintained by Posit, PBC (formerly RStudio, Inc) on top of the R language.</p> <p>If you're familiar with R, you're almost certainly familiar with the RStudio application, the IDE developed by Posit. Hadley Wickham, the author of the Tidy Data paper, also happens to be the Chief Scientist at Posit. If you're a fan of the Tidyverse, also check out Posit's other useful tools like Positron, Quarto, Shiny, and pak.</p>"},{"location":"software_development/Languages/R/Tidyverse/#additional-resources","title":"Additional Resources","text":""},{"location":"software_development/Languages/R/Tidyverse/#articles","title":"Articles","text":"<ul> <li>Welcome to the Tidyverse     \u2014 A brief paper introducing the Tidyverse, from the package vignette.</li> <li>Tidyverse Wikipedia page.</li> <li>Writing performant code with tidy tools     \u2014 An interesting read on analysing code performance and how to     consider alternatives; especially relevant to package development.</li> </ul>"},{"location":"software_development/Languages/R/Tidyverse/#learning","title":"Learning","text":"<ul> <li>R for Data Science Textbook \u2014 The go-to     textbook for learning R and the Tidyverse, authored by Hadley Wickham, Mine     \u00c7etinkaya-Rundel, and Garrett Grolemund.</li> <li>Swirl \u2014 An interactive learning platform for     R.<ul> <li>Specifically, check out this course     for a quick (and interactive!) taste of working with <code>dplyr</code> and <code>tidyr</code>.</li> </ul> </li> </ul>"},{"location":"software_development/Languages/R/Tidyverse/#packages","title":"Packages","text":"<ul> <li>Tidymodels \u2014 A collection of packages     for modeling and machine learning in R.</li> <li>Pharmaverse \u2014 A connected network of     companies and individuals working to promote collaborative development of     curated open source R packages for clinical reporting usage in pharma.</li> </ul>"},{"location":"software_development/Languages/R/Tidyverse/ggplot2/","title":"Plotting with <code>ggplot2</code>","text":"<p>Page Under Construction</p>"},{"location":"software_development/Languages/R/Tidyverse/ggplot2/#see-also","title":"See Also","text":"<ul> <li>The ggplot2: Elegant Graphics for Data Analysis Textbook - A great resource to understand the underlying framework that <code>ggplot2</code> follows. Authored by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen.</li> </ul>"},{"location":"software_development/Languages/Rust/","title":"Rust","text":""},{"location":"software_development/Remote_Development/Compute_Canada_Cloud/","title":"Introduction To Compute Canada Cloud","text":""},{"location":"software_development/Remote_Development/Compute_Canada_Cloud/#what-is-the-compute-canada-cloud","title":"What is the Compute Canada Cloud?","text":"<ul> <li>Access to a cloud computing environment with a variety of computing resources<ul> <li>CPUs</li> <li>GPUs</li> <li>Memory</li> <li>Storage</li> <li>Networking</li> </ul> </li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/","title":"Google Cloud Artifact Registry","text":"<p>Google Cloud Artifact Registry is a fully-managed service for storing and managing container images, as well as other software artifacts like Maven, npm, and Python packages. It is designed to integrate seamlessly with GCP, providing enhanced security, authentication, and efficiency over external services like Docker Hub.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#why-use-artifact-registry-instead-of-docker-hub","title":"Why Use Artifact Registry Instead of Docker Hub?","text":"Feature Docker Hub Artifact Registry Security Publicly accessible by default. Limited security features unless on paid tiers. Private by default, with IAM-based fine-grained access control and integration with GCP security features. Authentication Separate login credentials required. Uses GCP-managed identities (IAM roles and service accounts). Network Proximity External to GCP, introducing latency. Hosted within GCP, reducing latency and egress costs. Cost Free tier has pull limits. Paid plans for more. Pay only for what you store and access. Integration Limited GCP integration. Full integration with GCP services like Cloud Build, Compute Engine, and Kubernetes Engine."},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#setting-up-and-using-artifact-registry","title":"Setting Up and Using Artifact Registry","text":"<p>Ensure that you have completed How to Use GCP before starting this process.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#enabling-the-artifact-registry-api","title":"Enabling the Artifact Registry API","text":"<pre><code>gcloud services enable artifactregistry.googleapis.com\n</code></pre>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#creating-an-artifact-repository","title":"Creating an Artifact Repository","text":"<pre><code>gcloud artifacts repositories create [REPOSITORY_NAME] \\\n    --repository-format=docker \\\n    --location=[REGION] \\\n    --description=\"Repository for storing Docker images\"\n</code></pre>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#authenticating-docker-with-artifact-registry","title":"Authenticating Docker with Artifact Registry","text":"<p>Run the following command to configure Docker to authenticate with your Artifact Registry:</p> <pre><code>gcloud auth configure-docker [REGION]-docker.pkg.dev\n</code></pre>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#pushing-images-to-artifact-registry","title":"Pushing Images to Artifact Registry","text":"<ol> <li> <p>Tag your Docker image for Artifact Registry:</p> <pre><code>docker tag [IMAGE_NAME] [REGION]-docker.pkg.dev/[PROJECT_ID]/[REPOSITORY_NAME]/[IMAGE_NAME]:[TAG]\n</code></pre> </li> <li> <p>Push the image:</p> <pre><code>docker push [REGION]-docker.pkg.dev/[PROJECT_ID]/[REPOSITORY_NAME]/[IMAGE_NAME]:[TAG]\n</code></pre> </li> </ol>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/artifact_registry/#pulling-images-from-artifact-registry","title":"Pulling Images from Artifact Registry","text":"<pre><code>docker pull [REGION]-docker.pkg.dev/[PROJECT_ID]/[REPOSITORY_NAME]/[IMAGE_NAME]:[TAG]\n</code></pre>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/bigquery/","title":"BigQuery","text":"<p>BigQuery is a powerful SQL-based data warehouse that allows you to process, load, and analyze large datasets efficiently using SQL queries.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/bigquery/#why-use-bigquery","title":"Why Use BigQuery?","text":"<ul> <li>Quickly preprocess and explore large datasets using SQL-like query.</li> <li>Simplifies aggregation, feature extraction, and preparation for ML models.</li> <li>You can directly load data from a GCS bucket into an SQL-based data     warehouse (BigQuery). It supports all types of data \u2014 structured,     semi-structured, and unstructured; including tsv, csv, parquet, avro, xlsx,     and many more.</li> <li>To use BigQuery with a client library, please follow this link     for detailed guide.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/bigquery/#setting-up-and-using-bigquery","title":"Setting Up and Using BigQuery","text":"<p>Ensure that you have completed How to Use GCP before starting this process.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/bigquery/#loading-data-into-bigquery","title":"Loading Data into BigQuery","text":"<ul> <li> <p>From GCS:</p> <pre><code>bq load --source_format=CSV &lt;DATASET_NAME&gt;.&lt;TABLE_NAME&gt; gs://&lt;BUCKET_NAME&gt;/&lt;FILE_NAME&gt;\n</code></pre> </li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/bigquery/#querying-data","title":"Querying Data","text":"<ul> <li>Use BigQuery's web interface or CLI to run SQL queries for data cleaning,     feature engineering, and exploratory analysis.</li> <li> <p>Example:</p> <pre><code>SELECT * FROM `project_id.dataset_name.table_name` LIMIT 10;\n</code></pre> </li> </ul> <p>Follow the instructions on this page to learn more about BigQuery.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/cloud_sql/","title":"Cloud SQL for MySQL, PostgreSQL, and Microsoft SQL Server","text":"<p>Google Cloud SQL is a fully-managed relational database service for MySQL, PostgreSQL, and Microsoft SQL Server. It eliminates the need for database maintenance while offering high availability, scalability, and security. Below is a comprehensive guide to using Cloud SQL effectively for your projects.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/cloud_sql/#why-use-cloud-sql","title":"Why Use Cloud SQL?","text":"<ul> <li>Managed Service: Automated backups, updates, and maintenance.</li> <li>Scalability: Seamless scaling for growing workloads.</li> <li>Security: Built-in encryption, IAM-based access, and network security.</li> <li>Integration: Works seamlessly with GCP services like Compute Engine,     Kubernetes Engine, and BigQuery.</li> <li>Flexibility: Supports popular relational databases: MySQL, PostgreSQL,     and Microsoft SQL Server.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/cloud_sql/#setting-up-and-using-cloud-sql","title":"Setting Up and Using Cloud SQL","text":"<p>Ensure that you have completed How to Use GCP before starting this process.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/cloud_sql/#enabling-the-cloud-sql-api","title":"Enabling the Cloud SQL API","text":"<pre><code>gcloud services enable sqladmin.googleapis.com\n</code></pre>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/cloud_sql/#creating-a-cloud-sql-instance","title":"Creating a Cloud SQL Instance","text":"<ul> <li> <p>Example Using MySQL:</p> <pre><code>gcloud sql instances create [INSTANCE_NAME] \\\n    --database-version=MYSQL_8_0 \\\n    --cpu=[CPU_COUNT] \\\n    --memory=[MEMORY_SIZE] \\\n    --region=[REGION]\n</code></pre> </li> <li> <p>Example using PostgreSQL:</p> <pre><code>gcloud sql instances create [INSTANCE_NAME] \\\n    --database-version=POSTGRES_14 \\\n    --cpu=[CPU_COUNT] \\\n    --memory=[MEMORY_SIZE] \\\n    --region=[REGION]\n</code></pre> </li> <li> <p>Parameters:</p> <ul> <li><code>--cpu</code>: Number of vCPUs (e.g., 2).</li> <li><code>--memory</code>: RAM allocation (e.g., 4GB).</li> <li><code>--region</code>: Choose a region (e.g., <code>us-central1</code>).</li> </ul> </li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/cloud_sql/#configuring-users-and-databases","title":"Configuring Users and Databases","text":"<p>Using the same <code>INSTANCE_NAME</code> as configured in the previous step:</p> <ul> <li> <p>Create a Database with the command below:</p> <pre><code>gcloud sql databases create [DATABASE_NAME] --instance=[INSTANCE_NAME]\n</code></pre> </li> <li> <p>Add a User with the command below:</p> <pre><code>gcloud sql users create [USERNAME] --password=[PASSWORD] --instance=[INSTANCE_NAME]\n</code></pre> </li> </ul> <p>For a detailed guide on using client services, please refer to this link</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/gcs/","title":"Google Cloud Storage (GCS)","text":"<p>GCS is a scalable and secure object storage for data files, datasets, and ML-ready data.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/gcs/#why-use-gcs","title":"Why Use GCS?","text":"<ul> <li>Centralized storage for raw and processed datasets.</li> <li>Facilitates data sharing across team members.</li> <li>Integration with other GCP services like BigQuery and AI/ML tools.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/gcs/#setting-up-and-using-gcs","title":"Setting Up and Using GCS","text":"<p>Ensure that you have completed How to Use GCP before starting this process.</p> <p>Use the GCP console, gcloud CLI, or API to create a bucket:</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/gcs/#creating-a-gcs-bucket-via-cloud-console","title":"Creating a GCS Bucket via Cloud Console","text":"<ul> <li>Follow the instructions in this documentation     to create buckets.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/gcs/#creating-a-gcs-bucket-via-terminal","title":"Creating a GCS Bucket via Terminal","text":"<ul> <li> <p>In your development environment, run the <code>gcloud storage buckets create</code>     command:</p> <pre><code>gcloud storage buckets create gs://&lt;BUCKET_NAME&gt; --location=&lt;BUCKET_LOCATION&gt;\n</code></pre> <p>Where: - <code>&lt;BUCKET_NAME&gt;</code> is the name you want to give your bucket, subject to     naming requirement. For example, <code>my-bucket</code>. - <code>&lt;BUCKET_LOCATION&gt;</code> is the location of your bucket. For example,     <code>us-east1</code>. - If the request is successful, the command returns the following message:</p> <pre><code>Creating gs://BUCKET_NAME/...\n</code></pre> </li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/gcs/#transferring-data-across-gcs","title":"Transferring Data Across GCS","text":"<ul> <li> <p>From Local to GCS:</p> <pre><code>gsutil cp &lt;local_file&gt; gs://&lt;bucket_name&gt;\n</code></pre> </li> <li> <p>From GCS to Local:</p> <pre><code>gsutil cp gs://&lt;bucket_name&gt;/&lt;file_name&gt; &lt;local_destination&gt;\n</code></pre> </li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/","title":"Introduction to Google Cloud Platform (GCP)","text":""},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/#what-is-google-cloud-platform","title":"What is Google Cloud Platform?","text":"<p>Google Cloud Platform is a suite of cloud computing services offered by Google, providing a wide range of infrastructure and application services that can be accessed on-demand. It enables users to build, deploy, and scale applications seamlessly while taking advantage of Google\u2019s powerful and reliable infrastructure.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/#why-use-gcp","title":"Why Use GCP?","text":"<ul> <li>Scalability: Easily scale resources up or down based on workload.</li> <li>Pay-as-You-Go: Only pay for what you use.</li> <li>Integration: Connect seamlessly with open-source and enterprise tools.</li> <li>Global Infrastructure: High-speed global network for faster operations.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/#how-to-use-gcp","title":"How to Use GCP","text":"<p>Prerequisites:</p> <ul> <li>Ensure you have an active Google account.</li> <li>Confirm that your account has been added to the relevant GCP project.</li> </ul> <p>To access and use Google Cloud Platform (GCP), follow these steps:</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/#accessing-gcp-via-the-cloud-console","title":"Accessing GCP via the Cloud Console","text":"<ul> <li>Visit the Google Cloud Console.</li> <li>Explore the dashboard to view, manage, and configure services, projects, and     resources.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/#accessing-gcp-via-terminal","title":"Accessing GCP via Terminal","text":"<p>To interact with GCP directly from your terminal:</p> <ol> <li> <p>Initialize Google Cloud SDK</p> <ul> <li> <p>Install the Google Cloud SDK on your machine by following the official   installation guide, then use   the following command:</p> <pre><code>gcloud init\n</code></pre> </li> <li> <p>Follow the prompts to authenticate, select your project, and configure the   settings.</p> </li> </ul> </li> <li> <p>Authenticate Your Terminal</p> <ul> <li> <p>Run the following command to authenticate:</p> <pre><code>gcloud auth login\n</code></pre> </li> <li> <p>This opens a browser window asking you to log in with your Google account.</p> </li> <li>After login, your terminal will be authenticated, and you\u2019ll see a   confirmation message.</li> </ul> </li> <li> <p>Set the Active Project</p> <ul> <li> <p>Ensure the correct project is set as the active one.</p> <pre><code>gcloud config set project &lt;PROJECT_ID&gt;\n</code></pre> </li> <li> <p>Replace <code>&lt;PROJECT_ID&gt;</code> with your GCP project ID (e.g., <code>bhklabproject-123</code>).</p> </li> <li> <p>Verify the active project:</p> <pre><code>gcloud config list project\n</code></pre> </li> </ul> </li> </ol>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/introduction/#commonly-used-gcp-services","title":"Commonly Used GCP Services","text":"<p>Below are some key Google Cloud Platform (GCP) services that can be used for your project:</p> <ul> <li>Google Cloud Storage (GCS) - Scalable and secure object storage for data files, datasets, and ML-ready data</li> <li>BigQuery - SQL-based data warehouse for processing and analyzing large datasets</li> <li>Cloud SQL - Fully-managed relational database service for MySQL, PostgreSQL, and Microsoft SQL Server</li> <li>Virtual Machines (VMs) - Scalable, on-demand virtual machines for running custom ML experiments</li> <li>Artifact Registry - Fully-managed service for storing and managing container images and software artifacts</li> </ul> <p>Each service page provides detailed information about why to use the service and step-by-step setup instructions.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/virtual_machines/","title":"GCP Virtual Machines (VMs)","text":"<p>A Cloud VM is a scalable, on-demand virtual machine hosted in the cloud. It functions like a physical computer, providing compute power, memory, storage, and network connectivity. Cloud VMs are versatile and can be used for a variety of tasks, from running applications and hosting websites to managing databases and performing intensive data processing.</p> <p>In summary, VMs offer flexible compute instances to run custom ML experiments, manage pipelines, or host applications.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/virtual_machines/#why-use-cloud-vms","title":"Why Use Cloud VMs?","text":"<ul> <li>Ideal for workloads requiring full control over the environment, OS, and     configurations.</li> <li>Provides isolated environments for training ML models.</li> <li>Supports GPU/TPU acceleration for deep learning tasks.</li> <li>Can host containerized ML workflows using Docker.</li> </ul>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/virtual_machines/#setting-up-and-using-gcp-vms","title":"Setting Up and Using GCP VMs","text":"<p>Ensure that you have completed How to Use GCP before starting this process.</p>"},{"location":"software_development/Remote_Development/Google_Cloud_Platform/virtual_machines/#creating-a-gpu-enabled-vm-for-model-training","title":"Creating a GPU-Enabled VM for Model Training","text":"<pre><code>gcloud compute instances create $INSTANCE_NAME \\\n    --zone=$ZONE \\\n    --image-family=$IMAGE_FAMILY \\\n    --image-project=deeplearning-platform-release \\\n    --maintenance-policy=TERMINATE \\\n    --accelerator=\"type=nvidia-tesla-v100,count=1\" \\\n    --metadata=\"install-nvidia-driver=True\"\n</code></pre> <p>Parameters:</p> <ul> <li><code>--image-family</code> must be one of the GPU-specific image types. For more     information, see Choosing an Image.</li> <li><code>--image-project</code> must be <code>deeplearning-platform-release</code>.</li> <li><code>--maintenance-policy</code> must be <code>TERMINATE</code>. For more information, see     GPU Restrictions.</li> <li><code>--accelerator</code> specifies the GPU type to use. Must be specified in the     format <code>--accelerator=\"type=TYPE,count=COUNT\"</code>. Supported values of     <code>TYPE</code> are:<ul> <li><code>nvidia-tesla-v100</code>, (<code>count=1</code> or <code>8</code>)</li> <li><code>nvidia-tesla-p100</code>, (<code>count=1</code>, <code>2</code>, or <code>4</code>)</li> <li><code>nvidia-tesla-p4</code>, (<code>count=1</code>, <code>2</code>, or <code>4</code>)</li> </ul> </li> </ul>"},{"location":"software_development/Remote_Development/High_Performance_Computing_for_Health/","title":"High Performance Computing for Health (HPC4Health / H4H)","text":"<p>Tutorials and resources for HPC4Health can be found here:</p> <p>High Performance Computing for Health (HPC4Health / H4H), Guide by BHKLab</p>"},{"location":"software_development/Remote_Development/Lab_Server/","title":"Lab Server","text":""},{"location":"software_development/Remote_Development/Lab_Server/#accessing-the-lab-server","title":"Accessing the Lab Server","text":"<p>The lab server is accessible in a manner similar to H4H. </p> <p>Complete SSH instructions can be found here.</p>"},{"location":"software_development/Remote_Development/Lab_Server/#tldr-ssh-without-password","title":"TLDR: SSH without password","text":"<p>In your home directory, create a new key with the following command: <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre> Save the key in the default location <code>(~/.ssh/id_rsa)</code> by pressing Enter. Leave the passphrase empty to enable passwordless login.</p> <p>To automatically add your public key to the <code>~/.ssh/authorized_keys</code> file on the container <pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub -p &lt;PORT&gt; &lt;USERNAME&gt;@&lt;HOSTNAME&gt;\n</code></pre> Enter the password to the container when prompted.</p> <p>To create an alias for the server, add the following to your <code>~/.ssh/config</code> file: <pre><code>Host labserver\n    HostName &lt;HOSTNAME&gt;\n    Port &lt;PORT&gt;\n    User &lt;USERNAME&gt;\n    IdentityFile ~/.ssh/id_rsa\n</code></pre></p> <p>You should now be able to SSH into the server without a password. <pre><code>ssh labserver\n</code></pre></p>"},{"location":"software_development/Remote_Development/Lab_Server/#i-cant-see-any-files-in-the-home-directory","title":"I can't see any files in the home directory","text":"<p>This likely means the server was rebooted and the directory needs to be re-mounted. </p> <p>To re-mount the home directory, run the following command:</p> <pre><code>sudo mount -a\n</code></pre> <p>If you are still having issues, please contact Jermiah Joseph or the lab coordinator.</p>"},{"location":"software_development/Remote_Development/Lab_Server/github_access/","title":"GitHub Access","text":"<p>In order to use GitHub on the lab server, you will need to use an SSH key set up in your GitHub account.</p> <p>First check that you have an SSH key set up on your local machine for your GitHub account. If you don't, follow the guide on generating a new SSH key and adding it to the ssh-agent.</p> <p>You can then follow GitHub Docs' guide on using SSH agent forwarding to forward your SSH key to the lab server.</p> <ul> <li>On step 2 under \"Setting up SSH agent forwarding\", add the <code>ForwardAgent yes</code> line under the lab server alias you set up in your <code>~/.ssh/config</code> file.</li> </ul>"},{"location":"software_development/Remote_Development/Lab_Server/github_access/#mac-specific-step-for-ssh-agent-forwarding","title":"Mac Specific Step for SSH Agent Forwarding","text":"<p>If you are setting up SSH agent forwarding on a Mac, there is an extra step that you need to take for your local <code>ssh-agent</code> to \"remember\" the key.</p> <p>After you've set up your SSH key, import the SSH keys into Keychanin using this command: <pre><code>ssh-add --apple-use-keychain YOUR-KEY\n</code></pre></p> <p>This will add the key to your local <code>ssh-agent</code> and allow you to use it for SSH agent forwarding.</p> <p>Read more</p>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/","title":"Common Challenges and Solutions in Code Reviews","text":"<p>Code reviews are an essential part of software development, but they come with their own set of challenges. Understanding these obstacles and addressing them proactively can make the process more effective and enjoyable for everyone involved.</p> <p>Below are some common challenges teams face during code reviews and proposed solutions to overcome them.</p>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#challenges-and-solutions","title":"Challenges and Solutions","text":""},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#time-constraints","title":"Time Constraints","text":"<p>Problem: Developers often feel overwhelmed with their workload, making it difficult to dedicate enough time for thorough code reviews.  </p> <p>Impact: Reviews may be rushed, resulting in overlooked issues and suboptimal feedback.  </p> <p>Solution:  </p> <ul> <li>Encourage small, focused pull requests to make reviews more manageable.  </li> <li>Allocate dedicated time for reviews during the workday to prioritize them effectively.  </li> <li>Use automation tools to handle repetitive checks (e.g., style or formatting issues).  </li> </ul>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#adversarial-dynamics","title":"Adversarial Dynamics","text":"<p>Problem: Code reviews can sometimes feel confrontational, with reviewers focusing on criticizing rather than improving the code.  </p> <p>Impact: Creates tension within the team and discourages collaboration.  </p> <p>Solution:  </p> <ul> <li>Promote a positive mindset by framing feedback as an opportunity for learning and improvement.  </li> <li>Encourage respectful, constructive comments that focus on the code, not the person.  </li> <li>Provide training on effective communication for both authors and reviewers.  </li> </ul>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#large-or-complex-changes","title":"Large or Complex Changes","text":"<p>Problem: Reviews of extensive or overly complex changes can be overwhelming and time-consuming.  </p> <p>Impact: Leads to fatigue, reduced attention to detail, and delays in the review process.  </p> <p>Solution:</p> <ul> <li>Request authors to split large changes into smaller, self-contained pull requests.  </li> <li>Use feature flags or staged development to integrate large changes incrementally.  </li> </ul>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#lack-of-clear-standards","title":"Lack of Clear Standards","text":"<p>Problem: Without a defined set of coding standards, reviews can become subjective and inconsistent.  </p> <p>Impact: Results in confusion and inefficiency, with different reviewers providing conflicting feedback.  </p> <p>Solution:  </p> <ul> <li>Develop and document coding standards for the team, including style, architecture, and testing.  </li> <li>Leverage linters and automated tools to enforce standards consistently.  </li> <li>Regularly review and update standards to align with team goals and best practices.  </li> </ul>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#inadequate-feedback","title":"Inadequate Feedback","text":"<p>Problem: Reviewers may provide vague or unhelpful comments, leaving the author unsure of how to proceed.  </p> <p>Impact: Reduces the effectiveness of the review and prolongs the process.  </p> <p>Solution:  </p> <ul> <li>Ensure feedback is specific, actionable, and concise.  </li> <li>Use examples or links to documentation to clarify points.  </li> <li>Balance feedback by highlighting both strengths and areas for improvement.  </li> </ul>"},{"location":"software_development/Version_Control/code_reviews/challenges_solutions/#conclusion","title":"Conclusion","text":"<p>By addressing these common challenges with thoughtful solutions, teams can transform code reviews into a constructive and efficient process.</p> <p>This not only improves the quality of the codebase but also fosters a collaborative and supportive team environment.</p>"},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/","title":"Conducting a Review","text":""},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/#terminology","title":"Terminology","text":"<ul> <li>Author: The individual who submitted the contribution.</li> <li>Reviewer: The individual reviewing the contribution.</li> <li>Maintainer: The person responsible for merging the contribution after review.</li> </ul>"},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/#understanding-a-review","title":"Understanding a Review","text":"<p>Reviews are discussions around the changes proposed in a PR. They allow for collaborative feedback, ensuring code quality and alignment with project standards.</p> <p>Tip</p> <p>Anyone can review a PR, including those who are not maintainers! If you see a PR from another author, and have suggestions for improvement, feel free to leave a review.</p> <p>For further reading, refer to the Official GitHub Documentation on PR Reviews.</p>"},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/#review-statuses","title":"Review Statuses","text":"<p>When submitting a review, you can select from three statuses:</p> <ol> <li>Comment: Provide general feedback without explicitly approving or requesting changes.</li> <li>Approve: Indicate that the changes are acceptable, and approve merging the PR.</li> <li>Request Changes: Highlight issues that need to be addressed before the PR can be merged.</li> </ol>"},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/#requesting-a-review-for-a-pull-request","title":"Requesting a Review for a Pull Request","text":"<p>After creating a PR, you can request specific individuals or teams to review it.</p> <ul> <li>Only members of the BHK Lab organization can request reviews from other members.</li> </ul> <p>For more information, check the Official GitHub Documentation on Requesting a Pull Request Review.</p>"},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/#adding-to-an-existing-document","title":"Adding to an Existing Document","text":"<p>If a document already exists, you can add to it. Check the bottom of the page for information on current authors.</p>"},{"location":"software_development/Version_Control/code_reviews/conducting_a_review/#conclusion","title":"Conclusion","text":"<p>Effective reviews help ensure that contributions meet project standards, improve code quality, and facilitate knowledge sharing within the team. Whether you're an author, reviewer, or maintainer, understanding the review process is essential to contributing successfully.</p>"},{"location":"software_development/Version_Control/code_reviews/introduction/","title":"Introduction to Code Reviews","text":"<p>Code reviews are a critical practice in software development where developers collaboratively examine each other\u2019s code to identify issues, ensure adherence  to coding standards and improve overall quality before changes are integrated  into the main codebase.</p>"},{"location":"software_development/Version_Control/code_reviews/introduction/#objectives","title":"Objectives","text":"<p>The primary objectives of code reviews are to:</p> <ul> <li> <p>Ensure Code Quality:</p> <ul> <li>Identify and fix bugs early.</li> <li>Maintain consistent coding standards.</li> <li>Improve code readability and maintainability.</li> </ul> </li> <li> <p>Facilitate Knowledge Sharing:</p> <ul> <li>Expose team members to different parts of the codebase.</li> <li>Share insights on best practices and new techniques.</li> <li>Encourage collaboration and mentoring.</li> </ul> </li> <li> <p>Enhance Team Productivity:</p> <ul> <li>Reduce technical debt through proactive feedback.</li> <li>Enable informed decision-making with diverse perspectives.</li> <li>Prevent knowledge silos by decentralizing expertise.</li> </ul> </li> <li> <p>Support Team Collaboration:</p> <ul> <li>Build trust and positive relationships among team members.</li> <li>Encourage open communication and constructive feedback.</li> <li>Foster a culture of continuous improvement.</li> </ul> </li> </ul>"},{"location":"software_development/Version_Control/code_reviews/mindsets/","title":"Mindsets in Code Reviews","text":"<p>A successful code review process depends not just on technical knowledge but also on the right mindset. The mindset impacts how authors and reviewers approach the process and influences the outcomes of a code review. Let's explore the difference between a negative mindset and a positive mindset and their effects.</p>"},{"location":"software_development/Version_Control/code_reviews/mindsets/#negative-mindset","title":"Negative Mindset","text":"<p>A negative mindset can turn code reviews into adversarial or unproductive experiences. This often leads to unnecessary tension and poor outcomes for the team.</p>"},{"location":"software_development/Version_Control/code_reviews/mindsets/#authors-perspective-self-criticism","title":"Author's Perspective (Self-Criticism)","text":"Thought Impact \"They won\u2019t understand my work.\" Resentment toward reviewers and less clarity in code. \"This is just wasting my time.\" Lack of effort in preparing quality code. \"They\u2019re nitpicking my work.\" Defensive behavior and dismissing constructive feedback."},{"location":"software_development/Version_Control/code_reviews/mindsets/#reviewers-thoughts-criticism","title":"Reviewer's Thoughts (Criticism)","text":"Thought Impact \"Another task on my plate.\" Rushed reviews with limited attention to detail. \"This is my code, and they better not ruin it.\" Resistance to change and collaboration. \"Their work is subpar.\" Criticism without constructive guidance."},{"location":"software_development/Version_Control/code_reviews/mindsets/#positive-mindset","title":"Positive Mindset","text":"<p>A positive mindset transforms code reviews into collaborative and enriching experiences. This creates better outcomes for the team and the codebase.</p>"},{"location":"software_development/Version_Control/code_reviews/mindsets/#authors-perspective-self-reflection","title":"Author's Perspective (Self-Reflection)","text":"Thought Impact \"Feedback will make my code better.\" Encourages learning and improvement. \"I should make this easy to review.\" Leads to well-prepared, clear, and concise code. \"I trust my reviewers to help me improve.\" Fosters collaboration and teamwork."},{"location":"software_development/Version_Control/code_reviews/mindsets/#reviewers-thoughts-mentorship","title":"Reviewer's Thoughts (Mentorship)","text":"Thought Impact \"They trust me to help improve their work.\" Motivates thorough and constructive feedback. \"Let\u2019s identify opportunities for learning.\" Builds a culture of mentorship and shared knowledge. \"I can learn from their approach too.\" Promotes an open exchange of ideas and perspectives. <p>By fostering a positive mindset in both authors and reviewers, teams can ensure that code reviews are efficient, productive, and an essential tool for growth and collaboration.</p>"},{"location":"software_development/Version_Control/code_reviews/presentation/","title":"Code Review Presentation","text":"<p>This presentation was presented on November 26th, 2024, and summarizes the docs on code reviews in a slide format.</p>"},{"location":"software_development/Version_Control/git/introduction/","title":"Introduction","text":"<p>Below are the slides presented at the first workshop on Git. Full screen at this link</p> <p>These slides can also be accessed through this link (you may need to request access).</p> <p>The slides cover the following topics:</p> <ul> <li>What is Git?</li> <li>Why use Git?</li> <li>What is a Git repository?<ul> <li>What's inside the <code>.git</code> directory?</li> </ul> </li> <li>Stages of the git workflow<ul> <li>Working directory</li> <li>Staging area</li> <li>Local repository</li> <li>Remote repository (GitHub)</li> </ul> </li> <li>Basic Git commands<ul> <li><code>git add</code></li> <li><code>git commit</code></li> <li><code>git push</code></li> <li><code>git fetch</code></li> <li><code>git merge</code></li> <li><code>git pull</code></li> </ul> </li> </ul> <p>The second workshop on Code Reviews can be found this handbook page.</p>"},{"location":"software_development/Version_Control/git/quick_git/","title":"Quick Git Tips","text":""},{"location":"software_development/Version_Control/git/quick_git/#1-switch-branches-without-losing-changes","title":"1. Switch Branches Without Losing Changes","text":"<p>Problem: Switching branches with uncommitted changes. Solution: Stash the changes and reapply them later:</p> <pre><code>git stash\ngit stash apply\n</code></pre> <p>For more information on stashing, see git's documentation on stashing.</p>"},{"location":"software_development/Version_Control/git/quick_git/#2-view-commit-history-across-branches","title":"2. View Commit History Across Branches","text":"<p>Problem: Viewing a detailed log of commits and branches. Solution: Git's <code>log</code> command comes with many options to visualize commit history in a pretty way:</p> <pre><code>git log --oneline --graph --decorate --all\n</code></pre> <p>In the handbook, we have a dedicated branch that handles the deployment of the website called <code>gh-pages</code>. To avoid seeing this branch in your git log, you can use the following command:</p> <pre><code>git log --exclude=\"*/gh-pages\" --graph --oneline --all\n</code></pre> <p>For more information on the <code>log</code> command, see git's documentation on log.</p>"},{"location":"software_development/Version_Control/git/quick_git/#3-edit-the-last-commit","title":"3. Edit the Last Commit","text":"<p>Problem: You committed changes but realize you forgot something. Solution: Amend the last commit with:</p> <pre><code>git commit --amend\n</code></pre> <p>This doc by Atlassian does a great job explaining different ways to rewrite history in git.</p> <p>For more information on git commits and their options, see git's documentation commits.</p>"},{"location":"software_development/Version_Control/git/quick_git/#4-check-for-merge-conflicts","title":"4. Check for Merge Conflicts","text":"<p>Problem: Identifying conflicts before merging branches. Solution: Use a dry-run merge to check for conflicts:</p> <pre><code>git merge --no-commit --no-ff &lt;branch&gt;\n</code></pre>"},{"location":"software_development/Version_Control/git/quick_git/#5-simplify-commands-with-aliases","title":"5. Simplify Commands with Aliases","text":"<p>Problem: Repeatedly typing long Git commands. Solution: Create shortcuts for common commands:</p> <pre><code>git config --global alias.co checkout\ngit config --global alias.st status\n</code></pre> <p>This allows you to shorten commands like <code>git checkout</code> to <code>git co</code>.</p> <pre><code>git co &lt;branch&gt; \n</code></pre> <p>You can even add common options to your aliases. For example, to always use the <code>-m</code> flag when committing, you can set up an alias like this:</p> <pre><code>git config --global alias.cm 'commit -m'\n</code></pre> <p>Now to write a commit message, you can use:</p> <pre><code>git cm \"Your commit message here\"\n</code></pre> <p>You can see all the aliases you have set up by running:</p> <pre><code>git config --global --get-regexp alias\n</code></pre>"},{"location":"software_development/Version_Control/git/quick_git/#6-remove-local-branches-that-have-been-deleted-remotely","title":"6. Remove local branches that have been deleted remotely","text":"<p>Problem: You or another lab member have deleted a branch on the remote repository, but it still shows up in your local repository. Solution: Use the following command to remove local branches that have been deleted remotely:</p> <pre><code>git fetch --prune\n</code></pre> <p>This command will remove all local branches that have been deleted on the remote repository.</p>"}]}